{"traceEvents": [{"ph": "M", "pid": 30032, "tid": 30032, "name": "process_name", "args": {"name": "ComputeOnGPU-2"}}, {"ph": "M", "pid": 30032, "tid": 30032, "name": "thread_name", "args": {"name": "MainThread"}}, {"pid": 30032, "tid": 30032, "ts": 18406925940030.668, "dur": 1.264, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941654.504, "dur": 158.456, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941873.598, "dur": 4.32, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941882.82, "dur": 0.52, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941898.81, "dur": 1.272, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941897.688, "dur": 2.724, "name": "_acquireLock (/root/miniconda3/lib/python3.8/logging/__init__.py:218)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941902.2, "dur": 0.92, "name": "disable (/root/miniconda3/lib/python3.8/logging/__init__.py:1276)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941904.13, "dur": 0.832, "name": "getEffectiveLevel (/root/miniconda3/lib/python3.8/logging/__init__.py:1675)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941907.445, "dur": 0.428, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941906.855, "dur": 1.16, "name": "_releaseLock (/root/miniconda3/lib/python3.8/logging/__init__.py:227)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941889.68, "dur": 18.868, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941915.688, "dur": 0.696, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941913.516, "dur": 2.992, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941917.973, "dur": 0.468, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941922.87, "dur": 0.132, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941922.258, "dur": 0.952, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941923.652, "dur": 0.092, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941924.4, "dur": 0.064, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941924.297, "dur": 0.232, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941912.434, "dur": 13.832, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941933.223, "dur": 0.74, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941937.03, "dur": 0.476, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941935.934, "dur": 1.836, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941939.848, "dur": 0.072, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941940.836, "dur": 0.532, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941940.28, "dur": 1.372, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941942.14, "dur": 0.644, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941939.51, "dur": 4.176, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941945.164, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941945.41, "dur": 0.088, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941947.617, "dur": 0.28, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941948.13, "dur": 0.152, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941947.24, "dur": 2.344, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941944.668, "dur": 5.108, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941957.64, "dur": 0.208, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941959.543, "dur": 0.064, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941959.1, "dur": 1.54, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941964.07, "dur": 0.96, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941966.28, "dur": 1.816, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941970.38, "dur": 0.508, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941972.703, "dur": 0.444, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941973.812, "dur": 0.372, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941974.35, "dur": 1.476, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941932.2, "dur": 43.964, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941928.152, "dur": 48.88, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941979.574, "dur": 1.464, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941985.344, "dur": 0.416, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941989.723, "dur": 0.34, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941988.984, "dur": 1.196, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941995.965, "dur": 1.264, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942000.695, "dur": 1.752, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941999.773, "dur": 2.832, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941998.15, "dur": 4.58, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942004.727, "dur": 11.624, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942017.367, "dur": 4.64, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942003.945, "dur": 22.752, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942029.566, "dur": 3.336, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942028.67, "dur": 4.384, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942028.066, "dur": 5.124, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941995.066, "dur": 38.708, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941992.008, "dur": 41.936, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942036.812, "dur": 19.008, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942057.633, "dur": 0.184, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942057.36, "dur": 0.536, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942058.473, "dur": 0.4, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942059.113, "dur": 0.488, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942060.574, "dur": 0.14, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942060.168, "dur": 0.7, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942056.99, "dur": 4.044, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941990.84, "dur": 70.4, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942061.76, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942061.62, "dur": 0.288, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941984.89, "dur": 77.172, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941981.734, "dur": 81.112, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941978.36, "dur": 84.64, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941910.684, "dur": 152.444, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941888.09, "dur": 176.316, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925941880.062, "dur": 184.76, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942070.824, "dur": 33.26, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942107.18, "dur": 418.94, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925942526.773, "dur": 580.572, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925943423.246, "dur": 0.768, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925943431.543, "dur": 0.256, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925943430.48, "dur": 1.528, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925943432.98, "dur": 1.584, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925943435.527, "dur": 1.96, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925943429.01, "dur": 36788.716, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980226.51, "dur": 0.492, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980230.375, "dur": 6.112, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980238.652, "dur": 0.28, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980241.473, "dur": 1.116, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980245.32, "dur": 0.416, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980244.7, "dur": 1.176, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980246.984, "dur": 0.476, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980254.824, "dur": 0.176, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980254.5, "dur": 0.652, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980255.617, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980256.23, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980256.13, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980244.242, "dur": 13.34, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980260.65, "dur": 0.144, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980262.855, "dur": 0.26, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980262.234, "dur": 1.192, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980264.78, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980265.508, "dur": 0.444, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980265.105, "dur": 1.008, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980266.49, "dur": 0.604, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980264.543, "dur": 3.296, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980269.008, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980269.207, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980270.79, "dur": 0.196, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980271.2, "dur": 0.156, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980270.598, "dur": 1.964, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980268.832, "dur": 3.94, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980276.973, "dur": 0.188, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980278.5, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980278.2, "dur": 0.792, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980279.56, "dur": 0.64, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980281.01, "dur": 0.448, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980282.223, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980283.574, "dur": 0.376, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980284.4, "dur": 0.24, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980284.81, "dur": 1.036, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980260.344, "dur": 25.768, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980258.746, "dur": 28.128, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980288.08, "dur": 0.768, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980290.82, "dur": 0.22, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980292.0, "dur": 0.608, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980291.523, "dur": 1.228, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980294.777, "dur": 0.96, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980297.523, "dur": 0.804, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980296.81, "dur": 1.696, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980296.33, "dur": 2.296, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980299.902, "dur": 6.304, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980306.71, "dur": 3.716, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980299.223, "dur": 13.652, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980314.8, "dur": 2.448, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980314.4, "dur": 2.996, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980313.844, "dur": 3.68, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980294.344, "dur": 23.6, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980293.504, "dur": 26.596, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980321.36, "dur": 10.572, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980333.273, "dur": 0.18, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980333.03, "dur": 0.516, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980334.047, "dur": 0.268, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980334.566, "dur": 0.544, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980335.848, "dur": 0.116, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980335.645, "dur": 0.424, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980332.73, "dur": 3.488, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980293.113, "dur": 43.284, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980336.863, "dur": 0.096, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980336.73, "dur": 0.292, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980290.49, "dur": 46.68, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980289.23, "dur": 48.604, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980287.586, "dur": 50.436, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980243.395, "dur": 94.776, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980240.656, "dur": 98.588, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980237.53, "dur": 101.996, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925980516.39, "dur": 241.636, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981194.03, "dur": 1.352, "name": "all_out_nbrs_csr (/root/Project/TCRGraph/src/type/CSRGraph.py:148)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981191.47, "dur": 4.24, "name": "all_in_nbrs_csr (/root/Project/TCRGraph/src/type/CSCGraph.py:82)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981188.207, "dur": 7.584, "name": "all_in_nbrs_csr (/root/Project/TCRGraph/src/type/CSRCGraph.py:87)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981184.406, "dur": 11.464, "name": "all_in_nbrs_csr (/root/Project/TCRGraph/src/type/Subgraph.py:93)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981181.82, "dur": 14.524, "name": "gather_nbrs (/root/Project/TCRGraph/src/demo/PageRank.py:80)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981201.895, "dur": 13151.14, "name": "orig_to_sub (/root/Project/TCRGraph/src/type/Subgraph.py:25)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925994359.32, "dur": 2.012, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925994358.34, "dur": 4.208, "name": "num_vertices (/root/Project/TCRGraph/src/type/CSRGraph.py:60)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925995784.797, "dur": 188.324, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925994356.51, "dur": 5082.38, "name": "out_degree (/root/Project/TCRGraph/src/type/CSRGraph.py:81)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925994354.43, "dur": 5085.18, "name": "out_degree (/root/Project/TCRGraph/src/type/CSRCGraph.py:66)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981200.855, "dur": 18240.52, "name": "out_degree (/root/Project/TCRGraph/src/type/Subgraph.py:58)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925999444.816, "dur": 3.552, "name": "device (/root/Project/TCRGraph/src/framework/GASProgram.py:122)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925999448.742, "dur": 7.396, "name": "Tensor.to", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925999461.71, "dur": 1.328, "name": "torch._C._has_torch_function", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925999464.734, "dur": 0.544, "name": "torch._C._has_torch_function_variadic", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925999467.145, "dur": 1511.62, "name": "Tensor.reciprocal", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925999464.0, "dur": 2561.792, "name": "__rdiv__ (/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:606)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925999461.004, "dur": 2565.312, "name": "wrapped (/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:26)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406925981199.297, "dur": 33724.82, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014947.004, "dur": 1.112, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014951.574, "dur": 33.388, "name": "torch._C._jit_get_operation", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014991.2, "dur": 0.708, "name": "_get_builtin_table (/root/miniconda3/lib/python3.8/site-packages/torch/jit/_builtins.py:128)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014992.316, "dur": 0.412, "name": "builtins.id", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014989.96, "dur": 8.344, "name": "_register_builtin (/root/miniconda3/lib/python3.8/site-packages/torch/jit/_builtins.py:158)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926015001.145, "dur": 0.472, "name": "builtins.setattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014945.35, "dur": 56.4, "name": "__getattr__ (/root/miniconda3/lib/python3.8/site-packages/torch/_ops.py:159)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926015002.2, "dur": 2696.6, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014929.566, "dur": 2772.524, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014928.33, "dur": 2774.208, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926014926.496, "dur": 2776.364, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926018411.08, "dur": 89.264, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926017704.113, "dur": 2221.552, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926019939.145, "dur": 0.56, "name": "all_out_nbrs_csr (/root/Project/TCRGraph/src/type/CSRGraph.py:148)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926019938.016, "dur": 1.848, "name": "all_out_nbrs_csr (/root/Project/TCRGraph/src/type/CSRCGraph.py:78)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926019935.312, "dur": 4.672, "name": "all_out_nbrs_csr (/root/Project/TCRGraph/src/type/Subgraph.py:87)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926019933.496, "dur": 6.848, "name": "scatter_nbrs (/root/Project/TCRGraph/src/demo/PageRank.py:87)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926019947.848, "dur": 0.864, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926019945.48, "dur": 3.404, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020025.85, "dur": 39.448, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020089.65, "dur": 1.972, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020093.38, "dur": 0.268, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020095.977, "dur": 0.944, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020099.207, "dur": 0.488, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020098.785, "dur": 1.004, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020100.84, "dur": 0.264, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020103.445, "dur": 0.168, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020103.06, "dur": 0.64, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020104.117, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020104.793, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020104.684, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020098.395, "dur": 7.492, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020108.383, "dur": 0.484, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020110.5, "dur": 0.32, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020110.027, "dur": 1.06, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020112.87, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020113.64, "dur": 0.264, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020113.195, "dur": 0.864, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020114.434, "dur": 0.592, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020112.64, "dur": 3.172, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020116.84, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020117.113, "dur": 0.092, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020118.535, "dur": 0.208, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020118.977, "dur": 0.152, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020118.336, "dur": 1.976, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020116.652, "dur": 3.872, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020124.395, "dur": 0.188, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020125.44, "dur": 0.064, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020125.176, "dur": 0.732, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020126.508, "dur": 0.548, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020127.816, "dur": 0.44, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020129.043, "dur": 0.196, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020129.855, "dur": 0.236, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020130.547, "dur": 0.244, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020134.566, "dur": 1.196, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020107.86, "dur": 28.128, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020106.797, "dur": 29.956, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020137.87, "dur": 0.688, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020140.23, "dur": 0.248, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020141.31, "dur": 0.58, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020140.895, "dur": 1.136, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020143.78, "dur": 0.868, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020146.21, "dur": 0.864, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020145.58, "dur": 1.696, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020145.168, "dur": 2.232, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020148.375, "dur": 5.376, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020154.207, "dur": 3.552, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020147.96, "dur": 12.128, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020161.773, "dur": 2.436, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020161.367, "dur": 3.004, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020161.008, "dur": 3.504, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020143.4, "dur": 21.552, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020142.777, "dur": 22.332, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020166.336, "dur": 10.672, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020178.16, "dur": 0.24, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020177.902, "dur": 0.608, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020178.973, "dur": 0.276, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020179.496, "dur": 0.496, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020180.68, "dur": 0.144, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020180.48, "dur": 0.46, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020177.67, "dur": 3.392, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020142.36, "dur": 38.864, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020181.67, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020181.543, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020139.934, "dur": 42.028, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020138.902, "dur": 43.688, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020137.38, "dur": 45.36, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020097.688, "dur": 85.204, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020095.375, "dur": 88.52, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020092.414, "dur": 91.76, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020185.24, "dur": 6.992, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020192.996, "dur": 92.324, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020285.57, "dur": 240.86, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020533.56, "dur": 0.272, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020538.312, "dur": 0.148, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020537.715, "dur": 0.9, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020539.39, "dur": 1.024, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020540.875, "dur": 0.592, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926020536.887, "dur": 36657.364, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057200.55, "dur": 0.208, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057202.535, "dur": 4.944, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057211.67, "dur": 0.232, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057213.938, "dur": 0.74, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057216.695, "dur": 0.352, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057216.31, "dur": 0.864, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057218.16, "dur": 0.244, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057220.242, "dur": 0.124, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057219.91, "dur": 0.528, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057220.86, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057221.45, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057221.344, "dur": 0.192, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057216.016, "dur": 6.832, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057224.867, "dur": 0.132, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057226.188, "dur": 0.212, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057225.92, "dur": 0.68, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057227.715, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057228.37, "dur": 0.304, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057228.02, "dur": 0.772, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057229.168, "dur": 0.556, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057227.49, "dur": 3.028, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057231.43, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057231.664, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057232.945, "dur": 0.196, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057233.336, "dur": 0.136, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057232.76, "dur": 1.872, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057231.24, "dur": 3.576, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057237.83, "dur": 0.188, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057238.695, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057238.465, "dur": 0.688, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057239.6, "dur": 0.436, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057240.63, "dur": 0.324, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057241.586, "dur": 0.172, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057242.344, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057242.902, "dur": 0.188, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057243.266, "dur": 1.188, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057224.562, "dur": 20.1, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057223.734, "dur": 21.576, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057246.29, "dur": 0.556, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057248.355, "dur": 0.184, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057249.16, "dur": 0.564, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057248.867, "dur": 1.012, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057251.316, "dur": 0.724, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057253.19, "dur": 0.712, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057252.78, "dur": 1.312, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057252.465, "dur": 1.752, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057255.055, "dur": 4.72, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057260.207, "dur": 3.292, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057254.66, "dur": 12.588, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057268.805, "dur": 2.12, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057268.434, "dur": 2.648, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057268.152, "dur": 3.064, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057251.04, "dur": 20.636, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057250.516, "dur": 21.312, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057273.004, "dur": 9.06, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057283.023, "dur": 0.176, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057282.8, "dur": 0.468, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057283.688, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057284.137, "dur": 0.452, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057285.305, "dur": 0.156, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057285.09, "dur": 0.464, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057282.586, "dur": 3.096, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057250.188, "dur": 35.64, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057286.285, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057286.152, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057248.12, "dur": 38.444, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057247.156, "dur": 39.992, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057245.887, "dur": 41.42, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057215.367, "dur": 72.064, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057213.336, "dur": 75.0, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057211.062, "dur": 77.544, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057423.844, "dur": 156.776, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926057751.53, "dur": 13064.2, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926070822.895, "dur": 2660.696, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926070819.777, "dur": 2664.04, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926070818.926, "dur": 2665.208, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926070817.492, "dur": 2666.884, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926074138.85, "dur": 68.932, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926073487.04, "dur": 2146.912, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075639.145, "dur": 0.448, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075637.566, "dur": 2.2, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075712.863, "dur": 38.884, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075772.51, "dur": 1.896, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075775.97, "dur": 0.256, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075778.39, "dur": 0.784, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075781.4, "dur": 0.388, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075780.92, "dur": 0.968, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075782.867, "dur": 0.256, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075784.99, "dur": 0.144, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075784.664, "dur": 0.564, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075785.656, "dur": 0.076, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075786.273, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075786.16, "dur": 0.2, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075780.594, "dur": 6.74, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075789.527, "dur": 0.412, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075795.285, "dur": 0.236, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075794.9, "dur": 0.836, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075797.027, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075797.758, "dur": 0.248, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075797.375, "dur": 0.776, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075798.535, "dur": 0.536, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075796.797, "dur": 3.012, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075800.605, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075800.81, "dur": 0.104, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075801.86, "dur": 0.212, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075802.28, "dur": 0.156, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075801.688, "dur": 1.856, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075800.414, "dur": 3.34, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075807.043, "dur": 0.184, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075807.96, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075807.7, "dur": 0.756, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075808.875, "dur": 0.544, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075810.055, "dur": 0.22, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075810.934, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075811.73, "dur": 0.2, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075812.336, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075812.676, "dur": 1.32, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075789.15, "dur": 25.06, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075788.145, "dur": 26.732, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075815.88, "dur": 0.548, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075817.992, "dur": 0.192, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075818.957, "dur": 0.532, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075818.566, "dur": 1.072, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075821.137, "dur": 0.76, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075823.105, "dur": 0.768, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075822.727, "dur": 1.308, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075822.355, "dur": 1.808, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075824.992, "dur": 4.8, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075830.293, "dur": 3.34, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075824.61, "dur": 11.104, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075837.207, "dur": 2.192, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075836.875, "dur": 2.672, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075836.574, "dur": 3.112, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075820.86, "dur": 19.272, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075820.246, "dur": 20.036, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075841.375, "dur": 9.26, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075851.6, "dur": 0.204, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075851.367, "dur": 0.552, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075852.254, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075852.773, "dur": 0.444, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075853.88, "dur": 0.148, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075853.676, "dur": 2.832, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075851.14, "dur": 5.508, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075819.96, "dur": 36.88, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075857.336, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075857.19, "dur": 0.304, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075817.754, "dur": 39.88, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075816.758, "dur": 41.516, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075815.41, "dur": 43.024, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075779.94, "dur": 78.66, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075777.812, "dur": 81.756, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075775.137, "dur": 84.704, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075860.945, "dur": 6.516, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075868.14, "dur": 89.664, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926075958.047, "dur": 237.256, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926076201.492, "dur": 0.264, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926076205.33, "dur": 0.16, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926076204.85, "dur": 0.78, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926076206.504, "dur": 0.976, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926076207.9, "dur": 0.612, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926076204.11, "dur": 36616.664, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112826.684, "dur": 0.228, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112828.766, "dur": 4.476, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112834.4, "dur": 0.2, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112836.49, "dur": 0.66, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112839.13, "dur": 0.368, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112838.742, "dur": 0.872, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112840.562, "dur": 0.26, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112842.5, "dur": 0.128, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112842.152, "dur": 0.552, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112843.105, "dur": 0.088, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112843.684, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112843.566, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112838.426, "dur": 6.272, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112846.535, "dur": 0.12, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112847.87, "dur": 0.204, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112847.55, "dur": 0.784, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112849.207, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112849.797, "dur": 0.288, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112849.504, "dur": 0.712, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112850.52, "dur": 0.5, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112849.04, "dur": 2.836, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112852.605, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112852.863, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112853.87, "dur": 0.204, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112854.285, "dur": 0.164, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112853.707, "dur": 1.904, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112852.426, "dur": 3.364, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112861.945, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112862.824, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112862.586, "dur": 0.668, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112863.65, "dur": 0.46, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112864.72, "dur": 0.268, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112865.59, "dur": 0.176, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112866.387, "dur": 0.2, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112866.95, "dur": 0.188, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112867.305, "dur": 0.992, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112846.324, "dur": 22.16, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112845.445, "dur": 23.668, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112870.09, "dur": 0.424, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112871.996, "dur": 0.164, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112872.875, "dur": 0.48, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112872.508, "dur": 0.972, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112874.87, "dur": 0.712, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112876.78, "dur": 0.596, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112876.395, "dur": 1.14, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112876.066, "dur": 1.58, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112878.477, "dur": 4.644, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112883.53, "dur": 2.74, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112878.09, "dur": 10.0, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112889.492, "dur": 2.212, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112889.176, "dur": 2.692, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112888.92, "dur": 3.072, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112874.594, "dur": 17.8, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112874.05, "dur": 18.476, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112893.594, "dur": 8.332, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112902.887, "dur": 0.224, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112902.66, "dur": 0.54, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112903.53, "dur": 0.22, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112903.977, "dur": 0.452, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112904.99, "dur": 0.12, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112904.812, "dur": 0.412, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112902.434, "dur": 2.92, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112873.76, "dur": 31.76, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112905.99, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112905.855, "dur": 0.272, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112871.766, "dur": 34.504, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112870.867, "dur": 35.976, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112869.62, "dur": 37.384, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112837.824, "dur": 69.34, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112835.99, "dur": 72.028, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926112833.926, "dur": 74.336, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926113041.11, "dur": 148.284, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926113358.805, "dur": 13099.108, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926126466.844, "dur": 2644.804, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926126464.484, "dur": 2647.42, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926126463.617, "dur": 2648.592, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926126462.746, "dur": 2649.668, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926129756.32, "dur": 65.352, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926129114.64, "dur": 2117.448, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131236.703, "dur": 0.496, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131235.438, "dur": 1.9, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131309.434, "dur": 38.584, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131368.44, "dur": 1.756, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131371.71, "dur": 0.252, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131374.047, "dur": 0.872, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131377.11, "dur": 0.368, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131376.715, "dur": 0.868, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131378.508, "dur": 0.272, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131380.633, "dur": 0.136, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131380.312, "dur": 0.552, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131381.258, "dur": 0.096, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131381.92, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131381.793, "dur": 0.216, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131376.344, "dur": 6.544, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131385.08, "dur": 0.412, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131386.977, "dur": 0.228, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131386.62, "dur": 0.812, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131388.586, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131389.406, "dur": 0.232, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131389.055, "dur": 0.72, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131390.105, "dur": 0.6, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131388.406, "dur": 3.048, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131392.137, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131392.367, "dur": 0.104, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131393.35, "dur": 0.216, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131393.754, "dur": 0.144, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131393.184, "dur": 1.824, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131391.953, "dur": 3.244, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131398.17, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131399.09, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131398.85, "dur": 0.716, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131399.99, "dur": 0.388, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131400.977, "dur": 0.216, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131401.88, "dur": 0.18, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131402.727, "dur": 0.16, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131403.28, "dur": 0.16, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131403.598, "dur": 1.104, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131384.668, "dur": 20.224, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131383.71, "dur": 21.864, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131406.543, "dur": 0.544, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131411.934, "dur": 0.196, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131412.92, "dur": 0.512, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131412.496, "dur": 1.1, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131415.13, "dur": 0.7, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131416.95, "dur": 0.804, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131416.58, "dur": 1.324, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131416.27, "dur": 1.752, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131418.848, "dur": 4.8, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131424.09, "dur": 3.684, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131418.504, "dur": 11.156, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131431.12, "dur": 2.192, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131430.777, "dur": 2.696, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131430.46, "dur": 3.14, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131414.83, "dur": 19.192, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131414.23, "dur": 19.948, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131435.195, "dur": 9.004, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131445.227, "dur": 0.22, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131444.92, "dur": 0.624, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131445.94, "dur": 0.196, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131446.363, "dur": 0.464, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131447.42, "dur": 0.144, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131447.21, "dur": 0.476, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131444.695, "dur": 3.128, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131413.934, "dur": 34.04, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131448.44, "dur": 0.08, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131448.312, "dur": 0.288, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131411.703, "dur": 37.044, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131410.594, "dur": 38.756, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131406.098, "dur": 43.44, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131375.67, "dur": 74.016, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131373.53, "dur": 77.076, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131370.902, "dur": 79.992, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131451.887, "dur": 6.036, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131458.574, "dur": 88.624, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131547.457, "dur": 235.92, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131789.496, "dur": 0.268, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131792.55, "dur": 0.18, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131792.145, "dur": 0.74, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131793.336, "dur": 0.584, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131794.273, "dur": 0.564, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926131791.594, "dur": 36434.7, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168232.473, "dur": 0.244, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168234.367, "dur": 4.376, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168239.97, "dur": 0.216, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168242.254, "dur": 0.748, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168244.895, "dur": 0.388, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168244.53, "dur": 0.856, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168252.07, "dur": 0.256, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168253.91, "dur": 0.132, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168253.637, "dur": 0.484, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168254.492, "dur": 0.072, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168255.07, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168254.957, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168244.19, "dur": 11.824, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168257.95, "dur": 0.128, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168259.28, "dur": 0.184, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168258.98, "dur": 0.64, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168260.527, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168261.23, "dur": 0.34, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168260.848, "dur": 0.856, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168261.977, "dur": 0.472, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168260.37, "dur": 2.728, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168263.8, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168264.023, "dur": 0.1, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168264.992, "dur": 0.204, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168265.367, "dur": 0.168, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168264.824, "dur": 1.688, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168263.625, "dur": 3.008, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168269.266, "dur": 0.188, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168270.137, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168269.92, "dur": 0.672, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168271.01, "dur": 0.388, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168271.996, "dur": 0.304, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168272.89, "dur": 0.148, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168273.855, "dur": 0.16, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168274.387, "dur": 0.16, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168274.703, "dur": 0.912, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168257.707, "dur": 18.06, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168256.863, "dur": 19.516, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168277.32, "dur": 0.5, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168279.39, "dur": 0.18, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168280.215, "dur": 0.4, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168279.887, "dur": 0.896, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168282.19, "dur": 0.68, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168283.934, "dur": 0.668, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168283.617, "dur": 1.152, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168283.305, "dur": 1.58, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168285.695, "dur": 4.608, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168290.727, "dur": 2.74, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168285.367, "dur": 9.968, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168296.67, "dur": 2.048, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168296.348, "dur": 2.532, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168296.09, "dur": 2.928, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168281.93, "dur": 19.784, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168281.36, "dur": 20.512, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168302.78, "dur": 8.396, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168312.133, "dur": 0.228, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168311.926, "dur": 0.528, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168312.8, "dur": 0.232, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168313.27, "dur": 0.464, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168314.39, "dur": 0.136, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168314.17, "dur": 0.468, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168311.695, "dur": 3.08, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168281.098, "dur": 33.856, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168315.49, "dur": 0.092, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168315.33, "dur": 0.312, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168279.145, "dur": 36.648, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168278.125, "dur": 38.236, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168276.92, "dur": 39.584, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168243.574, "dur": 73.076, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168241.707, "dur": 75.876, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168239.434, "dur": 78.392, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168446.902, "dur": 132.072, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926168750.543, "dur": 13065.212, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926181821.074, "dur": 2346.576, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926181818.887, "dur": 2348.976, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926181818.18, "dur": 2350.012, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926181817.336, "dur": 2351.104, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926184812.266, "dur": 65.456, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926184170.875, "dur": 2103.464, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186279.04, "dur": 0.44, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186277.723, "dur": 1.944, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186345.72, "dur": 35.444, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186401.07, "dur": 1.816, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186404.383, "dur": 0.232, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186406.754, "dur": 0.872, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186409.832, "dur": 0.352, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186409.414, "dur": 0.884, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186411.312, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186413.453, "dur": 0.14, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186413.16, "dur": 0.5, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186414.06, "dur": 0.092, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186414.637, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186414.516, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186409.09, "dur": 6.472, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186417.785, "dur": 0.368, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186419.57, "dur": 0.244, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186419.273, "dur": 0.744, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186421.152, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186421.87, "dur": 0.232, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186421.49, "dur": 4.3, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186426.074, "dur": 0.552, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186420.977, "dur": 6.34, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186428.168, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186428.4, "dur": 0.1, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186429.32, "dur": 0.216, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186429.7, "dur": 0.124, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186429.137, "dur": 1.74, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186427.984, "dur": 3.056, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186434.03, "dur": 0.184, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186434.965, "dur": 0.084, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186434.703, "dur": 0.728, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186435.824, "dur": 0.46, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186436.93, "dur": 0.208, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186437.805, "dur": 0.18, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186438.598, "dur": 0.2, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186439.215, "dur": 0.212, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186439.598, "dur": 1.18, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186417.402, "dur": 23.58, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186416.395, "dur": 25.264, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186442.617, "dur": 0.504, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186444.754, "dur": 0.184, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186445.734, "dur": 0.544, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186445.305, "dur": 1.104, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186447.812, "dur": 0.676, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186449.56, "dur": 0.776, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186449.21, "dur": 1.292, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186448.88, "dur": 1.752, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186451.473, "dur": 4.876, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186456.832, "dur": 3.448, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186451.13, "dur": 11.032, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186463.566, "dur": 2.14, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186463.2, "dur": 2.664, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186462.914, "dur": 3.08, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186447.53, "dur": 18.916, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186446.99, "dur": 19.604, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186467.754, "dur": 9.192, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186477.91, "dur": 0.204, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186477.7, "dur": 0.512, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186478.56, "dur": 0.224, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186479.035, "dur": 0.464, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186480.055, "dur": 0.152, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186479.836, "dur": 0.492, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186477.48, "dur": 2.98, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186446.7, "dur": 33.916, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186481.066, "dur": 0.092, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186480.92, "dur": 2.312, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186444.504, "dur": 38.884, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186443.473, "dur": 40.528, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186442.176, "dur": 41.996, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186408.42, "dur": 75.9, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186406.234, "dur": 79.024, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186403.61, "dur": 81.956, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186486.535, "dur": 5.988, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186493.266, "dur": 84.844, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186578.355, "dur": 237.252, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186821.543, "dur": 0.284, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186824.715, "dur": 0.156, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186824.324, "dur": 0.684, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186825.426, "dur": 0.644, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186826.46, "dur": 0.572, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926186823.81, "dur": 36452.964, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223283.207, "dur": 0.312, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223285.434, "dur": 4.668, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223291.56, "dur": 0.22, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223293.805, "dur": 0.7, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223296.6, "dur": 0.44, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223296.188, "dur": 0.964, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223298.13, "dur": 0.24, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223300.12, "dur": 0.148, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223299.84, "dur": 0.516, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223300.793, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223301.39, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223301.27, "dur": 0.228, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223295.88, "dur": 6.484, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223304.387, "dur": 0.132, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223305.78, "dur": 0.172, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223305.473, "dur": 0.644, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223307.086, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223307.77, "dur": 0.292, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223307.426, "dur": 0.748, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223308.46, "dur": 0.508, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223306.938, "dur": 2.78, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223310.44, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223310.65, "dur": 0.104, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223311.53, "dur": 0.22, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223311.953, "dur": 0.148, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223311.367, "dur": 1.816, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223310.266, "dur": 3.112, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223316.14, "dur": 0.176, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223317.027, "dur": 0.076, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223316.797, "dur": 0.696, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223317.887, "dur": 0.368, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223322.215, "dur": 0.288, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223323.117, "dur": 0.18, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223324.117, "dur": 0.16, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223324.625, "dur": 0.184, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223324.96, "dur": 0.824, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223304.17, "dur": 21.812, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223303.266, "dur": 23.36, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223327.6, "dur": 0.556, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223329.734, "dur": 0.184, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223330.67, "dur": 0.46, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223330.29, "dur": 0.964, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223332.688, "dur": 0.74, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223334.54, "dur": 0.748, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223334.188, "dur": 1.256, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223333.895, "dur": 1.664, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223336.37, "dur": 4.612, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223341.445, "dur": 2.644, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223336.047, "dur": 9.96, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223347.477, "dur": 2.228, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223347.15, "dur": 2.716, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223346.83, "dur": 3.152, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223332.43, "dur": 17.98, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223331.85, "dur": 18.704, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223351.477, "dur": 8.152, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223360.63, "dur": 0.212, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223360.414, "dur": 0.536, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223361.37, "dur": 0.196, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223361.8, "dur": 0.48, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223362.93, "dur": 0.124, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223362.74, "dur": 0.412, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223360.16, "dur": 3.12, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223331.57, "dur": 31.864, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223363.902, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223363.754, "dur": 0.304, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223329.484, "dur": 34.708, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223328.51, "dur": 36.264, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223327.184, "dur": 37.764, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223295.254, "dur": 69.836, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223293.242, "dur": 72.76, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223290.953, "dur": 75.324, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223498.098, "dur": 132.372, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926223802.02, "dur": 13088.692, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926236895.88, "dur": 2340.24, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926236893.945, "dur": 2342.448, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926236893.344, "dur": 2343.368, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926236892.496, "dur": 2344.472, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926239886.566, "dur": 65.756, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926239242.785, "dur": 2106.128, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241353.39, "dur": 0.424, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241352.16, "dur": 1.828, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241415.305, "dur": 35.5, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241470.51, "dur": 1.916, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241473.8, "dur": 0.288, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241476.33, "dur": 0.904, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241479.48, "dur": 0.38, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241479.04, "dur": 0.916, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241480.92, "dur": 0.28, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241483.023, "dur": 0.156, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241482.71, "dur": 0.536, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241483.66, "dur": 0.092, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241484.312, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241484.18, "dur": 0.228, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241478.65, "dur": 6.64, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241487.492, "dur": 0.436, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241489.277, "dur": 0.2, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241488.938, "dur": 0.732, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241490.805, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241491.504, "dur": 0.232, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241491.1, "dur": 0.788, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241492.22, "dur": 0.548, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241490.637, "dur": 2.94, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241494.305, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241494.555, "dur": 0.1, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241495.473, "dur": 0.244, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241495.91, "dur": 0.172, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241495.29, "dur": 1.92, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241494.13, "dur": 3.292, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241500.426, "dur": 0.168, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241501.324, "dur": 0.08, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241501.098, "dur": 0.704, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241502.207, "dur": 0.496, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241503.32, "dur": 0.248, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241504.305, "dur": 0.188, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241505.137, "dur": 0.192, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241505.71, "dur": 0.204, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241506.09, "dur": 1.168, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241487.08, "dur": 20.388, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241486.168, "dur": 21.912, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241509.008, "dur": 0.556, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241511.184, "dur": 0.192, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241512.195, "dur": 0.492, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241511.773, "dur": 1.072, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241514.344, "dur": 0.76, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241519.92, "dur": 0.768, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241519.543, "dur": 1.32, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241519.13, "dur": 1.844, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241521.785, "dur": 4.6, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241526.8, "dur": 3.544, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241521.4, "dur": 10.856, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241533.707, "dur": 2.136, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241533.336, "dur": 2.672, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241533.062, "dur": 3.064, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241514.047, "dur": 22.532, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241513.457, "dur": 23.284, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241537.81, "dur": 8.728, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241547.54, "dur": 0.236, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241547.297, "dur": 0.552, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241548.234, "dur": 0.22, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241548.72, "dur": 0.472, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241549.81, "dur": 0.172, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241549.605, "dur": 0.48, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241547.047, "dur": 3.188, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241513.156, "dur": 37.244, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241550.875, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241550.734, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241510.92, "dur": 40.252, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241509.895, "dur": 41.916, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241508.605, "dur": 43.364, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241477.977, "dur": 74.136, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241475.742, "dur": 77.3, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241473.17, "dur": 80.14, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241554.254, "dur": 6.156, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241561.117, "dur": 84.7, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241646.09, "dur": 237.156, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241889.098, "dur": 0.252, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241892.12, "dur": 0.168, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241891.72, "dur": 0.7, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241892.855, "dur": 0.552, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241893.816, "dur": 0.516, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926241891.246, "dur": 36507.768, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278404.617, "dur": 0.284, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278406.39, "dur": 4.328, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278411.89, "dur": 0.212, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278413.93, "dur": 0.68, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278416.625, "dur": 0.38, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278416.24, "dur": 0.88, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278417.938, "dur": 0.276, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278419.77, "dur": 0.132, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278419.484, "dur": 0.484, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278423.844, "dur": 0.076, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278424.473, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278424.355, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278415.926, "dur": 9.492, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278427.383, "dur": 0.136, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278428.668, "dur": 0.188, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278428.414, "dur": 0.644, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278430.0, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278430.617, "dur": 0.288, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278430.32, "dur": 0.728, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278431.33, "dur": 0.468, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278429.848, "dur": 2.704, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278433.273, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278433.51, "dur": 0.104, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278434.406, "dur": 0.176, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278434.78, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278434.24, "dur": 1.776, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278433.09, "dur": 3.12, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278438.934, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278439.844, "dur": 0.064, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278439.59, "dur": 0.708, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278440.734, "dur": 0.416, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278441.734, "dur": 0.268, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278442.64, "dur": 0.176, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278443.46, "dur": 0.168, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278444.027, "dur": 0.188, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278444.375, "dur": 1.016, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278427.137, "dur": 18.472, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278426.293, "dur": 19.932, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278447.223, "dur": 0.504, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278449.215, "dur": 0.176, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278450.04, "dur": 0.496, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278449.727, "dur": 0.912, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278451.977, "dur": 0.596, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278453.695, "dur": 0.564, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278453.336, "dur": 1.092, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278452.98, "dur": 1.556, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278455.26, "dur": 4.42, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278460.094, "dur": 2.668, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278454.93, "dur": 9.62, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278465.8, "dur": 2.088, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278465.492, "dur": 2.548, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278465.234, "dur": 2.924, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278451.676, "dur": 16.88, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278451.227, "dur": 17.464, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278469.58, "dur": 8.648, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278479.184, "dur": 0.168, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278478.957, "dur": 2.708, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278482.04, "dur": 0.264, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278482.535, "dur": 0.448, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278483.625, "dur": 0.112, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278483.406, "dur": 0.432, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278478.703, "dur": 5.264, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278450.965, "dur": 33.208, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278484.633, "dur": 0.092, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278484.5, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278448.984, "dur": 35.944, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278448.066, "dur": 37.464, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278446.78, "dur": 38.92, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278415.29, "dur": 70.544, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278413.465, "dur": 73.328, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278411.42, "dur": 75.62, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278615.953, "dur": 131.608, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926278918.76, "dur": 13070.736, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926291994.195, "dur": 2328.62, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926291992.46, "dur": 2330.564, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926291991.855, "dur": 2331.516, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926291991.04, "dur": 2332.592, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926294969.734, "dur": 65.384, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926294325.91, "dur": 2109.22, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296439.758, "dur": 0.472, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296438.453, "dur": 1.916, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296501.152, "dur": 35.752, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296556.727, "dur": 1.8, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296560.027, "dur": 0.28, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296562.45, "dur": 0.836, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296565.5, "dur": 0.372, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296565.09, "dur": 0.892, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296566.96, "dur": 0.26, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296569.117, "dur": 0.132, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296568.81, "dur": 0.512, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296569.754, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296570.344, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296570.234, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296564.742, "dur": 6.612, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296573.594, "dur": 0.384, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296575.41, "dur": 0.22, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296575.105, "dur": 0.72, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296577.0, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296577.746, "dur": 0.22, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296577.348, "dur": 0.788, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296578.46, "dur": 0.532, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296576.83, "dur": 2.94, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296584.254, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296584.5, "dur": 0.084, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296585.445, "dur": 0.216, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296585.84, "dur": 0.128, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296585.23, "dur": 1.86, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296584.074, "dur": 3.212, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296590.426, "dur": 0.184, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296591.305, "dur": 0.088, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296591.062, "dur": 0.756, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296592.223, "dur": 0.456, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296593.29, "dur": 0.24, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296594.195, "dur": 0.212, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296595.094, "dur": 0.2, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296595.715, "dur": 0.2, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296596.094, "dur": 1.192, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296573.184, "dur": 24.292, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296572.215, "dur": 26.0, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296599.23, "dur": 0.552, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296601.35, "dur": 0.2, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296602.344, "dur": 0.524, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296601.973, "dur": 1.052, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296604.562, "dur": 0.756, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296606.48, "dur": 0.68, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296606.125, "dur": 1.22, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296605.766, "dur": 1.704, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296608.336, "dur": 4.656, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296613.395, "dur": 3.524, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296608.02, "dur": 10.876, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296620.28, "dur": 2.076, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296619.945, "dur": 2.56, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296619.668, "dur": 2.98, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296604.24, "dur": 18.868, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296603.695, "dur": 19.564, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296624.246, "dur": 9.608, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296634.844, "dur": 0.244, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296634.574, "dur": 0.62, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296635.574, "dur": 0.248, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296636.07, "dur": 0.432, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296637.08, "dur": 0.14, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296636.88, "dur": 0.464, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296634.363, "dur": 3.12, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296603.4, "dur": 34.248, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296638.152, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296638.008, "dur": 0.296, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296601.117, "dur": 37.34, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296600.156, "dur": 38.92, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296598.758, "dur": 40.472, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296564.055, "dur": 77.304, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296561.906, "dur": 80.472, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296559.2, "dur": 83.436, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296643.56, "dur": 6.044, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296650.26, "dur": 85.108, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296735.605, "dur": 236.852, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296978.4, "dur": 0.3, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296981.48, "dur": 0.172, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296981.07, "dur": 0.732, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296982.254, "dur": 0.636, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296983.23, "dur": 0.576, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926296980.574, "dur": 36439.728, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333426.164, "dur": 0.248, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333428.047, "dur": 4.308, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333433.57, "dur": 0.216, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333435.656, "dur": 0.672, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333438.324, "dur": 0.348, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333437.945, "dur": 0.84, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333439.785, "dur": 0.272, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333441.652, "dur": 0.132, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333441.36, "dur": 0.52, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333442.29, "dur": 0.072, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333442.832, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333442.723, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333437.625, "dur": 6.2, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333445.684, "dur": 0.116, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333447.016, "dur": 0.172, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333446.72, "dur": 0.632, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333448.215, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333448.85, "dur": 0.268, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333448.56, "dur": 0.688, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333449.566, "dur": 0.48, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333448.07, "dur": 2.676, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333451.438, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333451.664, "dur": 0.088, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333452.51, "dur": 0.192, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333452.875, "dur": 0.148, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333452.348, "dur": 1.732, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333451.266, "dur": 2.972, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333456.85, "dur": 0.188, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333457.758, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333457.504, "dur": 0.704, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333458.617, "dur": 0.368, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333459.61, "dur": 0.292, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333460.484, "dur": 0.176, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333461.285, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333461.87, "dur": 0.168, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333465.258, "dur": 0.98, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333445.45, "dur": 21.008, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333444.633, "dur": 22.456, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333468.03, "dur": 0.52, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333470.03, "dur": 0.164, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333470.832, "dur": 0.448, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333470.535, "dur": 0.896, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333472.848, "dur": 0.692, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333474.62, "dur": 0.676, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333474.277, "dur": 1.176, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333473.957, "dur": 1.62, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333476.24, "dur": 4.376, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333481.02, "dur": 2.772, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333475.938, "dur": 9.632, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333486.867, "dur": 2.02, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333486.56, "dur": 2.476, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333486.3, "dur": 2.868, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333472.562, "dur": 17.02, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333472.0, "dur": 17.736, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333490.777, "dur": 8.196, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333499.992, "dur": 0.176, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333499.777, "dur": 0.48, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333500.664, "dur": 0.256, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333501.133, "dur": 0.476, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333502.156, "dur": 0.12, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333501.945, "dur": 0.436, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333499.51, "dur": 2.996, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333471.72, "dur": 30.968, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333503.16, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333503.023, "dur": 0.288, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333469.797, "dur": 33.656, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333468.863, "dur": 35.176, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333467.633, "dur": 36.584, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333437.03, "dur": 67.324, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333435.094, "dur": 70.176, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333433.062, "dur": 72.476, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333634.336, "dur": 131.888, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926333937.598, "dur": 13102.352, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926347045.04, "dur": 2324.204, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926347043.137, "dur": 2326.296, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926347042.53, "dur": 2327.212, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926347041.727, "dur": 2328.276, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926350013.965, "dur": 66.148, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926349372.477, "dur": 2099.908, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351477.074, "dur": 0.408, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351475.734, "dur": 1.876, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351542.812, "dur": 35.372, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351597.926, "dur": 1.836, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351601.32, "dur": 0.276, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351603.637, "dur": 0.78, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351606.535, "dur": 0.348, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351606.12, "dur": 0.844, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351607.984, "dur": 0.248, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351610.098, "dur": 0.168, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351609.785, "dur": 0.552, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351610.74, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351611.387, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351611.28, "dur": 0.22, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351605.78, "dur": 6.488, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351614.414, "dur": 0.392, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351616.15, "dur": 0.248, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351615.824, "dur": 0.78, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351617.73, "dur": 0.06, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351618.45, "dur": 0.228, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351618.055, "dur": 0.76, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351619.098, "dur": 0.576, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351617.543, "dur": 2.84, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351621.105, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351621.336, "dur": 0.072, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351622.215, "dur": 0.244, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351622.668, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351622.047, "dur": 1.952, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351620.92, "dur": 3.268, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351627.133, "dur": 0.196, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351628.152, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351627.895, "dur": 0.764, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351629.09, "dur": 0.496, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351630.215, "dur": 0.28, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351631.13, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351631.914, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351632.562, "dur": 0.196, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351632.93, "dur": 1.04, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351614.016, "dur": 20.152, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351613.113, "dur": 21.72, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351635.86, "dur": 0.564, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351637.95, "dur": 0.184, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351638.902, "dur": 0.476, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351638.508, "dur": 1.032, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351641.055, "dur": 0.768, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351642.934, "dur": 0.716, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351642.598, "dur": 1.228, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351642.27, "dur": 1.664, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351644.73, "dur": 4.74, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351653.07, "dur": 3.764, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351644.41, "dur": 14.556, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351660.344, "dur": 2.208, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351659.98, "dur": 2.724, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351659.715, "dur": 3.116, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351640.754, "dur": 22.492, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351640.176, "dur": 23.216, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351664.55, "dur": 9.368, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351674.93, "dur": 0.232, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351674.652, "dur": 0.624, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351675.68, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351676.168, "dur": 0.496, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351677.305, "dur": 0.184, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351677.09, "dur": 0.524, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351674.438, "dur": 3.304, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351639.87, "dur": 38.024, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351678.336, "dur": 0.096, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351678.21, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351637.71, "dur": 40.916, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351636.758, "dur": 42.488, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351635.387, "dur": 44.024, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351605.156, "dur": 74.408, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351603.15, "dur": 77.364, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351600.473, "dur": 80.32, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351681.793, "dur": 5.848, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351688.305, "dur": 84.628, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926351773.184, "dur": 237.468, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926352016.336, "dur": 0.276, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926352019.312, "dur": 0.148, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926352018.91, "dur": 0.7, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926352020.08, "dur": 0.584, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926352021.047, "dur": 0.54, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926352018.414, "dur": 36436.792, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388460.92, "dur": 0.24, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388462.742, "dur": 4.2, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388468.047, "dur": 0.188, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388470.04, "dur": 0.704, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388472.727, "dur": 0.344, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388472.336, "dur": 0.848, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388474.152, "dur": 0.208, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388475.97, "dur": 0.136, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388475.72, "dur": 0.472, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388476.645, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388477.223, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388477.12, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388472.0, "dur": 6.2, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388483.574, "dur": 0.12, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388484.926, "dur": 0.18, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388484.594, "dur": 0.724, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388486.223, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388486.914, "dur": 0.304, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388486.594, "dur": 0.768, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388487.67, "dur": 0.444, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388486.05, "dur": 2.788, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388489.61, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388489.848, "dur": 0.072, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388490.71, "dur": 0.192, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388491.074, "dur": 0.148, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388490.55, "dur": 1.764, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388489.43, "dur": 3.084, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388495.297, "dur": 0.176, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388496.164, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388495.93, "dur": 0.668, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388496.965, "dur": 0.444, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388498.008, "dur": 0.308, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388498.914, "dur": 0.18, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388499.82, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388500.453, "dur": 0.168, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388500.742, "dur": 0.8, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388483.33, "dur": 18.384, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388482.383, "dur": 19.932, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388503.258, "dur": 0.548, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388505.258, "dur": 0.168, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388506.086, "dur": 0.468, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388505.76, "dur": 0.932, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388507.984, "dur": 0.644, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388509.68, "dur": 0.628, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388509.32, "dur": 1.16, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388509.016, "dur": 1.572, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388511.305, "dur": 4.644, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388516.363, "dur": 2.652, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388511.04, "dur": 9.744, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388522.137, "dur": 1.904, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388521.82, "dur": 2.356, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388521.56, "dur": 2.74, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388507.7, "dur": 16.984, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388507.24, "dur": 17.584, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388525.773, "dur": 8.116, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388534.81, "dur": 0.16, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388534.6, "dur": 0.472, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388535.426, "dur": 0.216, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388535.848, "dur": 0.432, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388536.88, "dur": 0.136, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388536.645, "dur": 11.352, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388534.414, "dur": 13.732, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388507.008, "dur": 41.356, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388548.863, "dur": 0.096, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388548.723, "dur": 0.296, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388505.04, "dur": 44.112, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388504.13, "dur": 45.612, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388502.87, "dur": 47.024, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388471.414, "dur": 78.624, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388469.48, "dur": 81.48, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388467.535, "dur": 83.764, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388680.76, "dur": 132.332, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926388984.715, "dur": 13078.128, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926402067.496, "dur": 2320.284, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926402065.758, "dur": 2322.232, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926402065.14, "dur": 2323.18, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926402064.344, "dur": 2324.208, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926405037.84, "dur": 65.66, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926404390.863, "dur": 2114.312, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406510.258, "dur": 0.464, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406508.92, "dur": 1.976, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406572.03, "dur": 35.416, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406627.965, "dur": 1.788, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406631.2, "dur": 0.308, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406633.613, "dur": 0.8, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406636.645, "dur": 0.38, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406636.203, "dur": 0.9, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406638.043, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406640.023, "dur": 0.136, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406639.71, "dur": 0.516, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406640.65, "dur": 0.092, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406641.258, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406641.13, "dur": 0.228, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406635.844, "dur": 6.392, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406644.49, "dur": 0.4, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406646.277, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406645.95, "dur": 0.724, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406647.777, "dur": 0.068, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406648.504, "dur": 0.248, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406648.145, "dur": 0.744, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406649.184, "dur": 0.58, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406647.605, "dur": 2.868, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406651.203, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406651.414, "dur": 0.1, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406652.32, "dur": 0.2, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406652.703, "dur": 0.136, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406652.156, "dur": 5.576, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406651.02, "dur": 6.876, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406660.91, "dur": 0.204, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406661.832, "dur": 0.08, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406661.594, "dur": 0.7, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406662.7, "dur": 0.436, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406663.773, "dur": 0.304, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406664.664, "dur": 0.164, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406665.43, "dur": 0.164, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406666.023, "dur": 0.192, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406666.35, "dur": 1.056, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406644.086, "dur": 23.512, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406643.113, "dur": 25.144, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406669.28, "dur": 0.544, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406671.375, "dur": 0.196, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406672.312, "dur": 0.44, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406671.906, "dur": 0.996, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406674.324, "dur": 0.728, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406676.156, "dur": 0.728, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406675.816, "dur": 1.236, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406675.496, "dur": 1.668, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406677.88, "dur": 4.724, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406683.07, "dur": 3.52, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406677.61, "dur": 10.876, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406689.895, "dur": 2.024, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406689.566, "dur": 2.488, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406689.293, "dur": 2.88, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406674.05, "dur": 18.556, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406673.504, "dur": 19.252, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406693.82, "dur": 9.36, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406704.2, "dur": 0.224, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406703.94, "dur": 0.604, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406704.89, "dur": 0.256, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406705.402, "dur": 0.452, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406706.45, "dur": 0.156, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406706.223, "dur": 0.496, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406703.707, "dur": 3.148, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406673.19, "dur": 33.812, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406707.477, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406707.34, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406671.156, "dur": 36.612, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406670.152, "dur": 38.216, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406668.816, "dur": 39.7, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406635.18, "dur": 73.468, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406633.035, "dur": 76.556, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406630.39, "dur": 79.488, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406710.84, "dur": 6.0, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406719.87, "dur": 85.384, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926406805.508, "dur": 237.268, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926407048.586, "dur": 0.284, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926407051.496, "dur": 0.148, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926407051.117, "dur": 0.66, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926407052.176, "dur": 0.584, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926407053.12, "dur": 0.616, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926407050.637, "dur": 36591.688, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443648.055, "dur": 0.224, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443649.793, "dur": 4.232, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443655.24, "dur": 0.192, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443657.34, "dur": 0.72, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443660.047, "dur": 0.352, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443659.664, "dur": 0.836, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443661.42, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443663.33, "dur": 0.116, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443663.03, "dur": 0.48, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443663.914, "dur": 0.076, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443664.496, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443664.375, "dur": 0.228, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443659.35, "dur": 6.148, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443667.4, "dur": 0.124, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443668.684, "dur": 0.188, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443668.39, "dur": 0.708, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443669.96, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443670.58, "dur": 0.26, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443670.277, "dur": 0.708, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443671.23, "dur": 0.456, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443669.81, "dur": 2.584, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443673.105, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443673.34, "dur": 0.092, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443674.188, "dur": 0.212, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443674.625, "dur": 0.168, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443674.05, "dur": 1.784, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443672.93, "dur": 3.064, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443678.633, "dur": 0.152, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443679.516, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443679.23, "dur": 0.736, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443680.344, "dur": 0.336, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443681.33, "dur": 0.252, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443682.19, "dur": 0.192, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443683.137, "dur": 0.16, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443683.7, "dur": 0.188, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443684.043, "dur": 0.924, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443667.18, "dur": 17.976, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443666.36, "dur": 19.392, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443689.676, "dur": 0.5, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443691.77, "dur": 0.176, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443692.617, "dur": 0.408, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443692.297, "dur": 0.844, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443694.426, "dur": 0.648, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443696.086, "dur": 0.564, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443695.805, "dur": 1.02, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443695.48, "dur": 1.464, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443697.742, "dur": 4.44, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443702.633, "dur": 2.592, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443697.434, "dur": 9.688, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443708.562, "dur": 2.148, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443708.195, "dur": 2.656, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443707.945, "dur": 3.04, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443694.184, "dur": 17.224, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443693.734, "dur": 17.824, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443712.383, "dur": 8.128, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443721.547, "dur": 0.256, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443721.28, "dur": 0.608, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443722.23, "dur": 0.224, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443722.703, "dur": 0.392, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443723.664, "dur": 0.128, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443723.43, "dur": 0.452, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443721.066, "dur": 2.96, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443693.44, "dur": 30.736, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443724.63, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443724.492, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443691.555, "dur": 33.364, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443690.504, "dur": 34.992, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443689.273, "dur": 36.392, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443658.742, "dur": 67.048, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443656.8, "dur": 69.864, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443654.703, "dur": 72.236, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926443855.855, "dur": 132.388, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926444159.09, "dur": 13102.624, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926457266.68, "dur": 2329.272, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926457264.844, "dur": 2331.308, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926457264.234, "dur": 2332.228, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926457263.43, "dur": 2333.276, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926460240.56, "dur": 65.66, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926459599.13, "dur": 2097.056, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461700.727, "dur": 0.396, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461699.375, "dur": 1.884, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461761.902, "dur": 35.112, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461817.08, "dur": 1.804, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461820.363, "dur": 0.308, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461822.715, "dur": 0.808, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461829.37, "dur": 0.36, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461828.953, "dur": 0.888, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461830.773, "dur": 0.28, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461832.86, "dur": 0.172, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461832.543, "dur": 0.556, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461833.527, "dur": 0.1, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461834.152, "dur": 0.064, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461834.043, "dur": 0.224, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461828.61, "dur": 6.532, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461837.383, "dur": 0.424, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461839.223, "dur": 0.24, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461838.902, "dur": 0.764, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461840.715, "dur": 0.088, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461841.51, "dur": 0.24, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461841.086, "dur": 0.816, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461842.215, "dur": 0.548, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461840.543, "dur": 2.936, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461844.188, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461844.383, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461845.305, "dur": 0.232, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461845.715, "dur": 0.132, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461845.113, "dur": 1.848, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461844.008, "dur": 3.116, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461850.0, "dur": 0.2, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461850.883, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461850.645, "dur": 0.764, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461851.83, "dur": 0.416, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461852.883, "dur": 0.236, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461853.734, "dur": 0.164, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461854.47, "dur": 0.16, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461854.99, "dur": 0.16, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461855.3, "dur": 1.048, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461837.0, "dur": 19.564, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461836.008, "dur": 21.24, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461858.22, "dur": 0.516, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461860.367, "dur": 0.164, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461861.312, "dur": 0.492, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461860.906, "dur": 1.06, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461863.367, "dur": 0.72, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461865.22, "dur": 0.692, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461864.926, "dur": 1.18, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461864.574, "dur": 1.64, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461867.016, "dur": 4.652, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461872.137, "dur": 3.684, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461866.652, "dur": 11.104, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461879.184, "dur": 2.168, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461878.848, "dur": 4.72, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461878.566, "dur": 5.16, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461863.074, "dur": 21.148, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461862.57, "dur": 21.804, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461885.55, "dur": 11.012, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461897.547, "dur": 0.212, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461897.312, "dur": 0.576, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461898.28, "dur": 0.204, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461898.723, "dur": 0.436, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461899.723, "dur": 0.144, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461899.516, "dur": 0.456, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461897.066, "dur": 3.024, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461862.28, "dur": 37.972, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461900.777, "dur": 0.08, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461900.65, "dur": 0.268, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461860.152, "dur": 40.904, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461859.09, "dur": 42.56, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461857.76, "dur": 44.06, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461827.96, "dur": 74.024, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461822.2, "dur": 80.636, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461819.56, "dur": 83.596, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461904.137, "dur": 6.088, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461910.85, "dur": 84.508, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926461995.57, "dur": 237.348, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926462238.79, "dur": 0.3, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926462241.836, "dur": 0.132, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926462241.434, "dur": 0.676, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926462242.527, "dur": 0.612, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926462243.527, "dur": 0.584, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926462240.93, "dur": 36535.2, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498783.324, "dur": 0.452, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498786.008, "dur": 4.836, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498792.703, "dur": 0.28, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498795.29, "dur": 0.82, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498798.29, "dur": 0.356, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498797.883, "dur": 0.884, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498799.777, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498802.066, "dur": 0.144, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498801.746, "dur": 0.612, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498802.797, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498803.457, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498803.35, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498797.54, "dur": 7.04, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498806.785, "dur": 0.148, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498808.64, "dur": 0.208, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498808.344, "dur": 0.696, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498810.04, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498814.555, "dur": 0.416, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498814.145, "dur": 1.036, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498815.465, "dur": 0.584, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498809.848, "dur": 6.944, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498817.586, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498817.785, "dur": 0.124, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498818.81, "dur": 0.22, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498819.23, "dur": 0.148, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498818.594, "dur": 1.992, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498817.395, "dur": 3.388, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498823.836, "dur": 0.184, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498824.78, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498824.52, "dur": 0.8, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498825.83, "dur": 0.444, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498826.887, "dur": 0.296, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498827.832, "dur": 0.18, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498828.906, "dur": 0.148, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498829.426, "dur": 0.192, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498829.81, "dur": 1.064, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498806.547, "dur": 24.528, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498805.51, "dur": 26.252, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498832.848, "dur": 0.648, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498835.19, "dur": 0.156, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498836.14, "dur": 0.508, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498835.754, "dur": 1.092, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498838.35, "dur": 0.72, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498840.184, "dur": 0.712, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498839.83, "dur": 1.232, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498839.504, "dur": 1.664, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498842.055, "dur": 4.9, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498847.367, "dur": 2.784, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498841.64, "dur": 10.492, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498853.69, "dur": 2.268, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498853.29, "dur": 2.808, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498852.984, "dur": 3.24, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498838.055, "dur": 18.644, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498837.51, "dur": 19.34, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498857.83, "dur": 9.42, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498868.3, "dur": 0.192, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498868.07, "dur": 0.536, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498868.96, "dur": 0.204, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498869.402, "dur": 0.428, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498870.4, "dur": 0.12, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498870.22, "dur": 0.404, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498867.81, "dur": 2.964, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498837.188, "dur": 33.748, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498871.39, "dur": 0.072, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498871.26, "dur": 2.428, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498834.945, "dur": 38.892, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498833.887, "dur": 40.56, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498832.406, "dur": 42.208, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498796.832, "dur": 77.936, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498794.72, "dur": 81.108, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926498791.992, "dur": 84.116, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926499012.254, "dur": 134.708, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926499319.555, "dur": 13063.472, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926512388.13, "dur": 2308.168, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926512386.195, "dur": 2310.304, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926512385.57, "dur": 2311.336, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926512384.64, "dur": 2312.548, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926515346.344, "dur": 65.58, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926514699.566, "dur": 2113.768, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516818.047, "dur": 0.504, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516816.785, "dur": 1.928, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516880.035, "dur": 35.532, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516936.21, "dur": 1.836, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516939.6, "dur": 0.26, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516942.098, "dur": 0.872, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516945.184, "dur": 0.372, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516944.734, "dur": 0.932, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516946.688, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516948.87, "dur": 0.16, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516948.496, "dur": 0.656, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516949.566, "dur": 0.088, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516950.203, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516950.086, "dur": 0.24, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516944.367, "dur": 6.856, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516953.496, "dur": 0.46, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516955.434, "dur": 0.212, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516955.074, "dur": 0.756, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516957.04, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516957.79, "dur": 0.224, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516957.406, "dur": 0.76, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516958.504, "dur": 0.592, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516956.863, "dur": 2.968, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516960.59, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516960.836, "dur": 0.068, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516961.72, "dur": 0.248, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516962.152, "dur": 0.176, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516961.56, "dur": 1.864, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516960.426, "dur": 3.184, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516966.69, "dur": 0.188, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516967.605, "dur": 0.064, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516967.367, "dur": 4.348, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516972.176, "dur": 0.472, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516973.273, "dur": 0.248, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516974.234, "dur": 0.188, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516975.098, "dur": 0.136, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516975.664, "dur": 0.172, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516976.01, "dur": 1.152, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516953.098, "dur": 24.288, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516952.15, "dur": 25.908, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516979.09, "dur": 0.532, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516981.223, "dur": 0.176, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516982.215, "dur": 0.496, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516981.79, "dur": 1.036, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516984.32, "dur": 0.784, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516986.215, "dur": 0.756, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516985.84, "dur": 1.312, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516985.52, "dur": 1.756, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516988.215, "dur": 4.956, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516993.594, "dur": 3.64, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516987.82, "dur": 11.396, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517000.78, "dur": 2.252, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517000.367, "dur": 2.8, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517000.05, "dur": 3.252, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516984.02, "dur": 19.716, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516983.465, "dur": 20.424, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517005.008, "dur": 9.272, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517015.242, "dur": 0.212, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517015.027, "dur": 0.516, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517015.895, "dur": 0.224, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517016.387, "dur": 0.428, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517017.426, "dur": 0.148, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517017.23, "dur": 0.432, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517014.793, "dur": 3.008, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516983.145, "dur": 34.824, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517018.43, "dur": 0.096, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517018.293, "dur": 0.292, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516980.984, "dur": 37.744, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516979.94, "dur": 39.376, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516978.625, "dur": 40.856, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516943.69, "dur": 75.944, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516941.5, "dur": 79.088, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926516938.8, "dur": 82.092, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517021.902, "dur": 5.988, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517028.586, "dur": 85.876, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517114.72, "dur": 237.584, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517358.223, "dur": 0.264, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517361.246, "dur": 0.148, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517360.81, "dur": 3.964, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517365.258, "dur": 0.672, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517366.31, "dur": 0.76, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926517360.33, "dur": 36429.012, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553795.28, "dur": 0.216, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553797.05, "dur": 4.572, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553803.008, "dur": 0.216, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553805.17, "dur": 0.744, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553807.953, "dur": 0.384, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553807.504, "dur": 0.968, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553809.34, "dur": 0.26, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553811.28, "dur": 0.128, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553810.92, "dur": 0.56, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553811.914, "dur": 0.076, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553812.504, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553812.395, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553807.203, "dur": 6.292, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553815.438, "dur": 0.14, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553816.863, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553816.51, "dur": 0.76, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553818.145, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553818.84, "dur": 0.288, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553818.46, "dur": 0.796, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553819.53, "dur": 0.484, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553817.99, "dur": 2.784, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553821.53, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553821.76, "dur": 0.12, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553822.63, "dur": 0.184, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553823.0, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553822.46, "dur": 1.728, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553821.35, "dur": 3.004, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553827.043, "dur": 0.168, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553827.9, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553827.64, "dur": 0.756, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553828.797, "dur": 0.472, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553829.848, "dur": 0.292, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553830.74, "dur": 0.168, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553831.566, "dur": 0.148, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553832.133, "dur": 0.144, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553832.438, "dur": 0.9, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553815.195, "dur": 18.348, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553814.324, "dur": 19.828, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553835.16, "dur": 0.504, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553837.24, "dur": 0.16, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553838.04, "dur": 0.46, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553837.7, "dur": 0.94, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553842.656, "dur": 0.72, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553844.453, "dur": 0.652, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553844.12, "dur": 1.16, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553843.797, "dur": 1.608, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553846.29, "dur": 4.472, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553851.168, "dur": 2.576, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553845.93, "dur": 9.66, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553856.95, "dur": 2.14, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553856.63, "dur": 2.596, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553856.35, "dur": 3.0, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553842.367, "dur": 17.448, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553841.832, "dur": 18.136, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553860.926, "dur": 8.496, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553870.43, "dur": 0.236, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553870.203, "dur": 0.564, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553871.145, "dur": 0.196, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553871.574, "dur": 0.452, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553872.67, "dur": 0.12, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553872.44, "dur": 0.448, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553869.984, "dur": 3.048, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553841.562, "dur": 31.632, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553873.62, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553873.49, "dur": 0.276, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553837.01, "dur": 36.904, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553835.996, "dur": 38.46, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553834.727, "dur": 39.912, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553806.605, "dur": 68.188, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553804.645, "dur": 71.052, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926553802.348, "dur": 73.596, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926554005.52, "dur": 131.672, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926554309.01, "dur": 13093.088, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926567407.586, "dur": 2329.192, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926567405.65, "dur": 2331.38, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926567405.016, "dur": 2332.324, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926567404.19, "dur": 2333.364, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926570381.812, "dur": 66.244, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926569740.0, "dur": 2099.932, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571844.543, "dur": 0.44, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571843.176, "dur": 2.0, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571906.348, "dur": 35.94, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571962.617, "dur": 1.904, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571966.094, "dur": 0.284, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571968.516, "dur": 0.848, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571971.6, "dur": 0.388, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571971.16, "dur": 0.948, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571973.09, "dur": 0.264, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571975.27, "dur": 0.152, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571974.965, "dur": 5.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571980.633, "dur": 0.088, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571981.375, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571981.24, "dur": 0.24, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571970.824, "dur": 11.568, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571984.688, "dur": 0.408, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571986.56, "dur": 0.224, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571986.246, "dur": 0.72, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571988.152, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571988.88, "dur": 0.244, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571988.465, "dur": 0.784, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571989.535, "dur": 0.608, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571987.977, "dur": 2.928, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571991.703, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571991.91, "dur": 0.12, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571992.793, "dur": 0.196, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571993.168, "dur": 0.152, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571992.64, "dur": 1.764, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571991.527, "dur": 3.064, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571997.53, "dur": 0.184, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571998.42, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571998.18, "dur": 0.704, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571999.332, "dur": 0.38, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572000.355, "dur": 0.228, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572001.223, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572002.004, "dur": 0.16, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572002.594, "dur": 0.192, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572002.945, "dur": 0.996, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571984.266, "dur": 19.912, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571983.266, "dur": 21.552, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572005.84, "dur": 0.536, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572007.965, "dur": 0.164, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572008.87, "dur": 0.568, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572008.492, "dur": 1.064, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572011.062, "dur": 0.712, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572012.96, "dur": 0.776, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572012.55, "dur": 1.356, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572012.184, "dur": 1.832, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572014.83, "dur": 4.692, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572019.945, "dur": 3.952, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572014.445, "dur": 11.468, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572027.66, "dur": 2.188, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572027.09, "dur": 2.904, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572026.766, "dur": 3.352, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572010.746, "dur": 19.764, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572010.195, "dur": 20.464, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572033.65, "dur": 9.228, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572043.855, "dur": 0.216, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572043.605, "dur": 0.572, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572044.55, "dur": 0.24, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572045.047, "dur": 0.424, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572046.066, "dur": 0.148, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572045.824, "dur": 0.528, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572043.37, "dur": 3.116, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572009.887, "dur": 36.772, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572047.113, "dur": 0.096, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572046.984, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572007.72, "dur": 39.696, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572006.7, "dur": 41.336, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572005.406, "dur": 42.792, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571970.152, "dur": 78.188, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571967.93, "dur": 81.312, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926571965.26, "dur": 84.232, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572050.434, "dur": 5.948, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572057.03, "dur": 86.088, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572143.344, "dur": 237.22, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572386.477, "dur": 0.28, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572389.504, "dur": 0.148, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572389.105, "dur": 0.684, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572390.19, "dur": 0.564, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572391.113, "dur": 0.552, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926572388.625, "dur": 36345.504, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608741.93, "dur": 0.576, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608745.293, "dur": 5.764, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608753.457, "dur": 0.296, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608756.156, "dur": 0.768, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608759.984, "dur": 0.38, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608759.33, "dur": 1.196, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608761.766, "dur": 0.364, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608764.96, "dur": 0.184, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608764.66, "dur": 0.572, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608765.664, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608766.332, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608766.21, "dur": 0.224, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608758.508, "dur": 9.372, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608770.266, "dur": 0.132, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608771.88, "dur": 0.22, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608771.56, "dur": 0.756, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608773.53, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608774.547, "dur": 0.432, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608774.0, "dur": 1.108, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608775.453, "dur": 0.652, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608773.32, "dur": 3.748, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608782.117, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608782.336, "dur": 0.104, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608783.34, "dur": 0.212, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608783.754, "dur": 0.152, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608783.145, "dur": 1.952, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608781.92, "dur": 3.368, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608788.855, "dur": 0.2, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608790.223, "dur": 0.064, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608789.875, "dur": 0.86, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608791.285, "dur": 0.792, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608792.758, "dur": 0.388, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608793.887, "dur": 0.164, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608794.895, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608795.543, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608795.92, "dur": 1.252, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608770.02, "dur": 27.372, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608768.926, "dur": 29.192, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608799.33, "dur": 0.744, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608801.855, "dur": 0.232, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608802.906, "dur": 0.524, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608802.516, "dur": 1.092, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608805.23, "dur": 0.872, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608807.6, "dur": 0.788, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608807.086, "dur": 1.496, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608806.58, "dur": 2.116, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608809.707, "dur": 5.592, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608815.777, "dur": 3.208, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608809.29, "dur": 12.12, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608823.08, "dur": 2.552, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608822.617, "dur": 3.156, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608822.31, "dur": 3.596, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608804.926, "dur": 21.42, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608804.297, "dur": 22.196, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608827.664, "dur": 9.808, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608838.523, "dur": 0.188, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608838.254, "dur": 0.548, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608839.215, "dur": 0.268, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608839.742, "dur": 0.44, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608840.957, "dur": 0.164, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608840.746, "dur": 0.476, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608838.016, "dur": 3.364, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608803.973, "dur": 37.58, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608842.004, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608841.87, "dur": 0.268, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608801.617, "dur": 40.668, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608800.48, "dur": 42.472, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608798.81, "dur": 46.276, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608757.71, "dur": 87.52, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608755.58, "dur": 90.668, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608752.41, "dur": 94.12, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926608988.19, "dur": 139.192, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926609301.098, "dur": 13093.712, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926622439.387, "dur": 2542.444, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926622418.637, "dur": 2563.692, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926622415.51, "dur": 2567.36, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926622404.594, "dur": 2578.704, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926625650.613, "dur": 68.212, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926624986.96, "dur": 2136.34, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627129.625, "dur": 0.648, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627127.594, "dur": 2.864, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627193.67, "dur": 39.904, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627257.215, "dur": 2.436, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627261.36, "dur": 0.344, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627264.047, "dur": 0.828, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627267.633, "dur": 0.352, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627267.027, "dur": 1.072, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627269.188, "dur": 0.328, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627272.016, "dur": 0.152, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627271.695, "dur": 0.564, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627272.703, "dur": 0.088, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627273.38, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627273.266, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627266.5, "dur": 8.296, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627277.457, "dur": 0.484, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627279.496, "dur": 0.216, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627279.145, "dur": 0.792, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627281.28, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627282.11, "dur": 0.272, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627281.676, "dur": 0.94, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627282.945, "dur": 0.564, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627281.047, "dur": 3.248, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627285.164, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627285.414, "dur": 0.092, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627286.402, "dur": 0.22, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627286.81, "dur": 0.172, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627286.24, "dur": 1.868, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627284.977, "dur": 3.364, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627291.617, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627292.723, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627292.473, "dur": 0.776, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627293.8, "dur": 0.6, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627295.207, "dur": 0.372, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627296.45, "dur": 0.192, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627304.566, "dur": 0.204, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627305.227, "dur": 0.216, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627305.64, "dur": 1.284, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627276.96, "dur": 30.176, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627275.844, "dur": 32.032, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627309.21, "dur": 0.544, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627311.54, "dur": 0.232, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627312.617, "dur": 0.536, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627312.223, "dur": 1.064, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627315.01, "dur": 0.888, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627317.17, "dur": 0.932, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627316.76, "dur": 1.516, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627316.332, "dur": 2.056, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627319.297, "dur": 5.324, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627325.117, "dur": 3.94, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627318.902, "dur": 12.36, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627332.984, "dur": 2.56, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627332.61, "dur": 3.08, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627332.285, "dur": 3.532, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627314.7, "dur": 21.572, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627314.043, "dur": 22.376, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627337.707, "dur": 10.028, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627348.727, "dur": 0.208, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627348.52, "dur": 0.508, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627349.492, "dur": 0.316, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627350.043, "dur": 0.428, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627351.105, "dur": 0.168, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627350.92, "dur": 0.456, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627348.28, "dur": 3.228, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627313.64, "dur": 38.032, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627352.125, "dur": 0.116, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627351.992, "dur": 0.304, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627311.312, "dur": 41.128, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627310.145, "dur": 42.932, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627308.65, "dur": 44.616, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627265.72, "dur": 87.712, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627263.484, "dur": 90.972, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627260.406, "dur": 94.408, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627356.13, "dur": 6.548, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627363.312, "dur": 88.38, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627451.94, "dur": 239.036, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627697.324, "dur": 0.288, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627700.97, "dur": 0.176, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627700.434, "dur": 0.872, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627701.777, "dur": 0.9, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627703.016, "dur": 0.648, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926627699.81, "dur": 36463.28, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664171.668, "dur": 0.492, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664174.926, "dur": 6.032, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664183.203, "dur": 0.348, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664185.84, "dur": 0.876, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664189.293, "dur": 0.476, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664188.8, "dur": 1.084, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664190.95, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664193.836, "dur": 0.188, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664193.55, "dur": 0.564, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664194.508, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664195.105, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664195.0, "dur": 0.196, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664188.297, "dur": 8.092, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664198.656, "dur": 0.128, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664200.496, "dur": 0.228, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664200.11, "dur": 0.792, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664202.03, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664202.86, "dur": 0.368, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664202.336, "dur": 1.088, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664203.695, "dur": 0.544, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664201.766, "dur": 3.352, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664205.984, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664206.203, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664207.28, "dur": 0.216, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664207.695, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664207.113, "dur": 1.844, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664205.797, "dur": 3.384, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664212.336, "dur": 0.192, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664213.57, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664213.258, "dur": 0.752, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664214.477, "dur": 0.552, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664215.785, "dur": 0.62, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664217.08, "dur": 0.172, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664218.01, "dur": 0.192, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664218.59, "dur": 0.196, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664218.977, "dur": 1.116, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664198.414, "dur": 21.872, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664197.305, "dur": 23.612, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664222.016, "dur": 0.632, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664224.363, "dur": 0.372, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664225.664, "dur": 0.448, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664225.26, "dur": 1.004, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664227.688, "dur": 0.716, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664229.656, "dur": 0.7, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664229.234, "dur": 1.3, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664228.832, "dur": 1.832, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664235.14, "dur": 5.436, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664241.03, "dur": 3.072, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664234.758, "dur": 11.412, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664247.656, "dur": 2.38, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664247.3, "dur": 2.884, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664247.023, "dur": 3.3, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664227.39, "dur": 23.36, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664226.9, "dur": 24.012, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664252.004, "dur": 9.508, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664262.477, "dur": 0.176, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664262.26, "dur": 0.476, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664263.113, "dur": 0.212, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664263.574, "dur": 0.476, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664264.617, "dur": 0.128, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664264.41, "dur": 0.432, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664262.004, "dur": 2.988, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664226.62, "dur": 38.52, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664265.59, "dur": 0.08, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664265.46, "dur": 0.268, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664224.12, "dur": 41.752, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664223.03, "dur": 43.42, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664221.52, "dur": 45.088, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664187.535, "dur": 79.224, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664185.3, "dur": 82.36, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664182.184, "dur": 85.724, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664406.848, "dur": 139.396, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926664718.668, "dur": 13102.352, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926677827.83, "dur": 2343.796, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926677824.95, "dur": 2346.968, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926677824.168, "dur": 2348.208, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926677823.055, "dur": 2349.704, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926680831.055, "dur": 67.976, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926680176.586, "dur": 2117.38, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682299.277, "dur": 0.58, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682297.51, "dur": 2.532, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682363.203, "dur": 39.388, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682425.44, "dur": 1.964, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682429.246, "dur": 0.296, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682431.844, "dur": 0.892, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682435.363, "dur": 0.488, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682434.73, "dur": 1.228, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682436.9, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682439.312, "dur": 0.16, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682439.03, "dur": 0.528, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682439.965, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682440.605, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682440.49, "dur": 0.216, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682434.32, "dur": 12.296, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682449.086, "dur": 0.484, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682451.363, "dur": 0.236, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682450.98, "dur": 0.852, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682452.953, "dur": 0.072, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682453.77, "dur": 0.264, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682453.348, "dur": 0.884, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682454.543, "dur": 0.54, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682452.77, "dur": 3.048, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682456.555, "dur": 0.064, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682456.824, "dur": 0.092, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682457.84, "dur": 0.208, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682458.234, "dur": 0.144, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682457.656, "dur": 1.864, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682456.38, "dur": 3.332, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682462.82, "dur": 0.212, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682464.023, "dur": 0.076, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682463.77, "dur": 0.732, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682464.965, "dur": 0.548, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682466.14, "dur": 0.244, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682467.04, "dur": 0.18, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682467.94, "dur": 0.192, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682468.543, "dur": 0.18, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682468.902, "dur": 1.1, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682448.61, "dur": 21.608, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682447.617, "dur": 23.324, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682472.08, "dur": 0.576, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682474.223, "dur": 0.236, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682475.223, "dur": 0.512, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682474.848, "dur": 1.024, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682477.35, "dur": 0.748, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682479.36, "dur": 0.732, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682479.0, "dur": 1.264, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682478.566, "dur": 1.812, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682481.23, "dur": 5.048, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682486.76, "dur": 3.948, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682480.867, "dur": 12.248, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682494.594, "dur": 2.228, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682494.23, "dur": 2.728, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682493.93, "dur": 3.168, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682477.06, "dur": 20.508, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682476.527, "dur": 21.184, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682498.895, "dur": 9.764, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682509.63, "dur": 0.204, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682509.37, "dur": 0.564, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682510.305, "dur": 0.208, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682513.02, "dur": 0.596, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682514.223, "dur": 0.144, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682514.008, "dur": 0.476, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682509.14, "dur": 5.476, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682476.215, "dur": 38.564, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682515.242, "dur": 0.08, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682515.105, "dur": 0.288, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682473.98, "dur": 41.556, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682472.996, "dur": 43.184, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682471.53, "dur": 44.804, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682433.55, "dur": 82.94, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682431.246, "dur": 86.196, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682428.16, "dur": 89.588, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682519.03, "dur": 6.604, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682526.34, "dur": 88.964, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682615.56, "dur": 240.12, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682861.926, "dur": 0.292, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682865.566, "dur": 0.164, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682865.027, "dur": 0.836, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682866.36, "dur": 1.212, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682867.938, "dur": 0.656, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926682864.355, "dur": 36434.904, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719305.758, "dur": 0.24, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719308.01, "dur": 4.456, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719313.914, "dur": 0.268, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719316.016, "dur": 0.736, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719318.953, "dur": 0.352, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719318.523, "dur": 0.892, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719320.336, "dur": 0.32, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719322.56, "dur": 0.128, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719322.273, "dur": 0.492, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719323.227, "dur": 0.088, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719323.863, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719323.723, "dur": 0.228, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719318.195, "dur": 6.636, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719326.773, "dur": 0.14, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719328.07, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719327.797, "dur": 0.684, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719329.383, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719330.066, "dur": 0.352, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719329.695, "dur": 0.864, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719330.844, "dur": 0.5, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719329.234, "dur": 2.892, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719332.883, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719333.113, "dur": 0.072, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719334.06, "dur": 0.196, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719334.457, "dur": 0.144, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719333.88, "dur": 5.116, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719332.707, "dur": 6.508, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719342.31, "dur": 0.176, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719343.367, "dur": 0.064, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719343.13, "dur": 0.736, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719344.293, "dur": 0.476, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719345.406, "dur": 0.328, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719346.348, "dur": 0.172, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719347.2, "dur": 0.2, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719347.777, "dur": 0.168, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719348.113, "dur": 0.872, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719326.547, "dur": 22.644, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719325.727, "dur": 24.104, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719350.86, "dur": 0.552, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719353.02, "dur": 0.24, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719354.02, "dur": 0.42, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719353.684, "dur": 0.88, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719355.984, "dur": 0.7, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719357.92, "dur": 0.676, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719357.53, "dur": 1.248, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719357.145, "dur": 1.764, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719359.71, "dur": 4.556, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719364.7, "dur": 2.828, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719359.344, "dur": 10.152, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719370.934, "dur": 2.196, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719370.6, "dur": 2.684, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719370.28, "dur": 3.144, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719355.695, "dur": 18.176, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719355.2, "dur": 18.832, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719374.977, "dur": 8.504, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719384.535, "dur": 0.204, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719384.32, "dur": 0.536, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719385.24, "dur": 0.228, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719385.703, "dur": 0.46, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719386.81, "dur": 0.12, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719386.586, "dur": 0.436, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719384.07, "dur": 3.072, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719354.902, "dur": 32.404, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719387.78, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719387.652, "dur": 0.276, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719352.777, "dur": 35.292, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719351.754, "dur": 36.884, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719350.375, "dur": 38.432, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719317.49, "dur": 71.472, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719315.574, "dur": 74.3, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719313.312, "dur": 76.872, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719524.48, "dur": 136.568, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926719833.086, "dur": 13072.332, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926732911.2, "dur": 2318.96, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926732908.895, "dur": 2321.528, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926732908.2, "dur": 2322.548, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926732907.11, "dur": 2323.888, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926735880.105, "dur": 68.024, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926735233.434, "dur": 2114.728, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737353.414, "dur": 0.432, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737351.805, "dur": 2.204, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737414.89, "dur": 36.784, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737472.67, "dur": 1.824, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737475.89, "dur": 0.312, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737478.316, "dur": 0.868, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737481.5, "dur": 0.38, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737481.047, "dur": 0.912, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737482.91, "dur": 0.296, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737485.188, "dur": 0.168, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737484.88, "dur": 0.544, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737485.83, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737486.46, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737486.316, "dur": 0.248, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737480.715, "dur": 6.78, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737489.734, "dur": 0.38, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737491.55, "dur": 0.22, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737491.18, "dur": 0.812, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737493.184, "dur": 0.068, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737493.97, "dur": 0.244, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737493.594, "dur": 0.76, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737494.676, "dur": 0.592, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737493.004, "dur": 2.968, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737496.688, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737496.887, "dur": 0.112, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737497.816, "dur": 0.176, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737498.18, "dur": 0.128, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737497.637, "dur": 1.772, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737496.504, "dur": 3.096, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737502.65, "dur": 0.176, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737503.52, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737503.28, "dur": 0.732, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737504.4, "dur": 0.532, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737505.566, "dur": 0.304, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737506.49, "dur": 0.18, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737507.207, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737507.82, "dur": 0.204, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737508.195, "dur": 1.184, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737489.336, "dur": 20.244, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737488.367, "dur": 25.912, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737515.336, "dur": 0.64, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737517.543, "dur": 0.176, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737518.457, "dur": 0.512, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737518.066, "dur": 1.044, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737520.625, "dur": 0.808, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737522.703, "dur": 0.776, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737522.33, "dur": 1.324, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737521.953, "dur": 1.824, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737524.652, "dur": 4.892, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737529.953, "dur": 3.344, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737524.29, "dur": 11.144, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737536.92, "dur": 2.096, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737536.58, "dur": 2.592, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737536.293, "dur": 2.996, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737520.32, "dur": 19.428, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737519.754, "dur": 20.14, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737540.99, "dur": 9.196, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737551.137, "dur": 0.204, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737550.91, "dur": 0.56, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737551.832, "dur": 0.212, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737552.29, "dur": 0.444, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737553.332, "dur": 0.116, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737553.113, "dur": 0.432, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737550.68, "dur": 3.004, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737519.445, "dur": 34.388, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737554.273, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737554.145, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737517.305, "dur": 37.264, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737516.305, "dur": 38.896, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737514.832, "dur": 40.536, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737479.96, "dur": 75.556, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737477.76, "dur": 78.728, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737475.227, "dur": 81.524, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737557.848, "dur": 6.424, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737565.008, "dur": 85.744, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737650.992, "dur": 238.92, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737895.957, "dur": 0.316, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737899.207, "dur": 0.14, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737898.81, "dur": 0.672, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737899.836, "dur": 0.684, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737900.91, "dur": 0.584, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926737898.168, "dur": 36574.424, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774478.52, "dur": 0.232, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774480.426, "dur": 4.316, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774486.06, "dur": 0.228, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774491.504, "dur": 0.728, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774494.293, "dur": 0.336, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774493.887, "dur": 0.832, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774495.617, "dur": 0.22, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774497.504, "dur": 0.16, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774497.215, "dur": 0.516, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774498.137, "dur": 0.072, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774498.727, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774498.62, "dur": 0.196, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774493.566, "dur": 6.124, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774501.598, "dur": 0.116, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774502.953, "dur": 0.192, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774502.598, "dur": 0.764, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774504.266, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774504.902, "dur": 0.336, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774504.594, "dur": 0.776, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774505.656, "dur": 0.472, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774504.11, "dur": 2.756, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774507.625, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774507.81, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774508.723, "dur": 0.168, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774509.098, "dur": 0.144, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774508.527, "dur": 1.784, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774507.44, "dur": 3.04, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774513.184, "dur": 0.164, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774514.043, "dur": 0.08, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774513.81, "dur": 0.72, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774514.95, "dur": 0.472, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774516.023, "dur": 0.252, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774516.895, "dur": 0.164, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774517.664, "dur": 0.2, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774518.223, "dur": 0.184, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774518.55, "dur": 1.008, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774501.375, "dur": 18.384, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774500.53, "dur": 19.856, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774521.395, "dur": 0.54, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774523.383, "dur": 0.168, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774524.176, "dur": 0.424, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774523.86, "dur": 0.876, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774526.11, "dur": 0.688, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774527.848, "dur": 0.592, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774527.527, "dur": 1.072, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774527.21, "dur": 1.508, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774529.523, "dur": 4.236, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774534.19, "dur": 2.544, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774529.145, "dur": 9.348, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774539.824, "dur": 2.088, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774539.527, "dur": 4.34, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774539.254, "dur": 4.776, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774525.836, "dur": 18.648, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774525.31, "dur": 19.316, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774545.54, "dur": 8.904, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774555.355, "dur": 0.18, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774555.113, "dur": 0.528, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774555.996, "dur": 0.204, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774556.406, "dur": 0.432, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774557.45, "dur": 0.136, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774557.215, "dur": 0.48, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774554.91, "dur": 2.92, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774525.027, "dur": 32.96, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774558.48, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774558.336, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774523.137, "dur": 35.628, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774522.24, "dur": 37.064, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774520.92, "dur": 38.568, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774492.93, "dur": 66.716, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774491.016, "dur": 69.472, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774485.543, "dur": 75.24, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774690.355, "dur": 132.516, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926774994.68, "dur": 13100.864, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926788101.01, "dur": 2327.396, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926788099.113, "dur": 2329.536, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926788098.44, "dur": 2330.512, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926788097.508, "dur": 2331.7, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926791073.27, "dur": 65.62, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926790431.5, "dur": 2098.432, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792534.44, "dur": 0.416, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792533.066, "dur": 1.904, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792595.52, "dur": 35.816, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792651.33, "dur": 1.88, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792654.77, "dur": 0.24, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792657.145, "dur": 0.8, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792660.06, "dur": 0.344, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792659.656, "dur": 0.84, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792661.41, "dur": 0.224, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792663.535, "dur": 0.132, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792663.27, "dur": 0.468, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792664.164, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792664.76, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792664.656, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792659.32, "dur": 6.428, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792668.11, "dur": 0.372, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792669.883, "dur": 0.236, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792669.562, "dur": 5.104, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792675.832, "dur": 0.064, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792676.566, "dur": 0.236, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792676.184, "dur": 0.76, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792677.266, "dur": 0.544, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792675.656, "dur": 2.876, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792679.273, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792679.465, "dur": 0.088, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792680.367, "dur": 0.248, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792680.81, "dur": 0.12, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792680.2, "dur": 1.856, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792679.094, "dur": 3.144, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792685.242, "dur": 0.196, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792686.137, "dur": 0.064, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792685.88, "dur": 0.736, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792687.055, "dur": 0.432, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792688.133, "dur": 0.276, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792689.03, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792689.793, "dur": 0.2, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792690.383, "dur": 0.184, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792690.727, "dur": 1.048, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792667.695, "dur": 24.296, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792666.574, "dur": 26.048, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792693.695, "dur": 0.6, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792695.88, "dur": 0.188, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792696.832, "dur": 0.504, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792696.426, "dur": 1.04, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792698.938, "dur": 0.74, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792700.785, "dur": 0.792, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792700.453, "dur": 1.296, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792700.105, "dur": 1.756, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792702.617, "dur": 4.808, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792707.844, "dur": 3.656, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792702.26, "dur": 11.176, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792714.875, "dur": 2.144, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792714.55, "dur": 2.616, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792714.273, "dur": 3.032, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792698.645, "dur": 19.1, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792698.113, "dur": 19.772, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792718.984, "dur": 8.968, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792728.97, "dur": 0.212, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792728.707, "dur": 0.556, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792729.61, "dur": 0.232, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792730.07, "dur": 0.412, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792731.04, "dur": 0.148, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792730.836, "dur": 0.44, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792728.49, "dur": 2.936, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792697.793, "dur": 35.88, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792734.14, "dur": 0.08, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792734.008, "dur": 0.276, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792695.64, "dur": 38.784, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792694.63, "dur": 40.408, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792693.184, "dur": 42.016, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792658.68, "dur": 76.656, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792656.574, "dur": 79.696, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792653.92, "dur": 82.624, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792737.56, "dur": 6.176, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792744.414, "dur": 86.324, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926792831.03, "dur": 237.448, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926793074.8, "dur": 0.268, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926793077.902, "dur": 0.14, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926793077.453, "dur": 0.736, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926793078.617, "dur": 0.656, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926793079.67, "dur": 0.592, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926793076.848, "dur": 36464.824, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829548.023, "dur": 0.204, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829549.77, "dur": 4.14, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829555.23, "dur": 0.216, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829557.2, "dur": 0.576, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829559.734, "dur": 0.364, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829559.344, "dur": 0.848, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829561.08, "dur": 0.228, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829562.84, "dur": 0.12, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829562.566, "dur": 0.456, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829563.477, "dur": 0.072, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829564.07, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829563.957, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829559.05, "dur": 5.996, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829566.883, "dur": 0.14, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829568.207, "dur": 0.168, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829567.93, "dur": 0.64, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829569.465, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829570.105, "dur": 0.3, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829569.777, "dur": 0.768, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829570.816, "dur": 0.46, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829569.312, "dur": 2.672, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829572.754, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829572.95, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829573.836, "dur": 0.24, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829574.266, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829573.656, "dur": 1.796, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829572.594, "dur": 3.008, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829578.266, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829582.215, "dur": 0.08, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829581.953, "dur": 0.736, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829583.098, "dur": 0.468, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829584.152, "dur": 0.276, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829585.04, "dur": 0.156, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829585.98, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829586.504, "dur": 0.208, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829586.902, "dur": 0.936, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829566.664, "dur": 21.384, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829565.863, "dur": 22.776, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829589.617, "dur": 0.484, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829591.637, "dur": 0.16, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829592.44, "dur": 0.44, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829592.14, "dur": 0.848, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829594.32, "dur": 0.712, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829596.125, "dur": 0.604, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829595.78, "dur": 1.14, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829595.445, "dur": 1.592, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829597.742, "dur": 4.636, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829602.8, "dur": 2.6, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829597.406, "dur": 9.824, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829608.6, "dur": 1.956, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829608.27, "dur": 2.42, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829607.99, "dur": 2.82, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829594.06, "dur": 17.164, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829593.594, "dur": 17.78, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829612.36, "dur": 8.12, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829621.4, "dur": 0.188, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829621.168, "dur": 0.52, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829622.062, "dur": 0.2, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829622.496, "dur": 0.42, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829623.445, "dur": 0.148, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829623.23, "dur": 0.444, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829620.945, "dur": 2.856, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829593.312, "dur": 30.64, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829624.41, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829624.277, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829591.414, "dur": 33.284, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829590.41, "dur": 34.868, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829589.15, "dur": 36.292, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829558.41, "dur": 67.156, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829556.734, "dur": 69.724, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829554.68, "dur": 72.036, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926829756.59, "dur": 132.012, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926830060.4, "dur": 13068.56, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926843133.816, "dur": 2320.5, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926843131.91, "dur": 2322.592, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926843131.223, "dur": 2327.336, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926843130.45, "dur": 2328.356, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926846108.145, "dur": 65.568, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926845460.992, "dur": 2114.844, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847580.727, "dur": 0.416, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847579.26, "dur": 2.004, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847642.586, "dur": 36.108, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847698.83, "dur": 1.944, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847702.41, "dur": 0.312, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847704.777, "dur": 0.9, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847707.902, "dur": 0.384, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847707.47, "dur": 0.932, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847709.414, "dur": 0.232, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847711.438, "dur": 0.148, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847711.137, "dur": 0.52, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847712.07, "dur": 0.076, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847712.69, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847712.58, "dur": 0.22, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847707.137, "dur": 6.58, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847715.855, "dur": 0.52, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847717.824, "dur": 0.232, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847717.53, "dur": 0.716, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847719.387, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847720.055, "dur": 0.22, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847719.71, "dur": 0.72, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847720.707, "dur": 0.568, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847719.22, "dur": 2.86, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847722.78, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847722.973, "dur": 0.116, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847723.934, "dur": 0.184, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847724.305, "dur": 0.136, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847723.72, "dur": 1.756, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847722.61, "dur": 3.048, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847728.67, "dur": 0.196, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847729.547, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847729.312, "dur": 0.696, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847730.445, "dur": 0.468, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847731.54, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847732.39, "dur": 0.168, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847733.11, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847733.703, "dur": 0.184, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847734.07, "dur": 1.004, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847715.445, "dur": 19.844, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847714.56, "dur": 21.284, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847736.83, "dur": 0.516, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847738.875, "dur": 0.18, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847739.797, "dur": 0.508, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847739.4, "dur": 4.436, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847745.305, "dur": 0.852, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847747.41, "dur": 0.788, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847747.0, "dur": 1.38, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847746.63, "dur": 1.868, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847749.223, "dur": 4.768, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847754.465, "dur": 3.56, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847748.91, "dur": 10.952, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847761.234, "dur": 2.04, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847760.92, "dur": 2.5, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847760.645, "dur": 2.904, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847745.016, "dur": 18.956, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847744.48, "dur": 19.648, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847765.152, "dur": 8.756, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847774.848, "dur": 0.252, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847774.625, "dur": 0.6, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847775.566, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847776.016, "dur": 0.508, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847777.08, "dur": 0.152, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847776.902, "dur": 0.44, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847774.402, "dur": 3.072, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847744.17, "dur": 33.472, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847778.113, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847777.977, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847738.625, "dur": 39.776, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847737.668, "dur": 41.316, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847736.35, "dur": 42.796, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847706.445, "dur": 72.844, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847704.23, "dur": 75.984, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847701.54, "dur": 78.912, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847781.33, "dur": 5.928, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847787.965, "dur": 85.452, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926847873.68, "dur": 237.676, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926848117.215, "dur": 0.32, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926848120.37, "dur": 0.168, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926848119.953, "dur": 0.72, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926848121.117, "dur": 0.568, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926848122.01, "dur": 0.568, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926848119.42, "dur": 36451.804, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884577.074, "dur": 0.244, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884578.934, "dur": 4.288, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884584.42, "dur": 0.188, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884586.473, "dur": 0.688, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884589.246, "dur": 0.384, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884588.754, "dur": 1.008, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884590.652, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884598.727, "dur": 0.148, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884598.434, "dur": 0.52, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884599.395, "dur": 0.108, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884599.992, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884599.883, "dur": 0.2, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884588.4, "dur": 12.54, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884602.94, "dur": 0.124, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884604.316, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884604.01, "dur": 0.684, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884605.566, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884606.215, "dur": 0.272, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884605.87, "dur": 0.76, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884606.906, "dur": 0.432, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884605.406, "dur": 2.636, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884608.746, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884608.938, "dur": 0.072, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884609.79, "dur": 0.172, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884610.156, "dur": 0.156, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884609.625, "dur": 1.724, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884608.566, "dur": 2.956, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884614.188, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884615.08, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884614.832, "dur": 0.724, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884615.945, "dur": 0.448, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884617.008, "dur": 0.32, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884618.074, "dur": 0.228, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884619.098, "dur": 0.176, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884619.656, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884620.023, "dur": 0.976, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884602.7, "dur": 18.492, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884601.816, "dur": 20.016, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884622.734, "dur": 0.516, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884624.727, "dur": 0.176, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884625.535, "dur": 0.432, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884625.215, "dur": 0.888, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884627.51, "dur": 0.656, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884629.277, "dur": 0.64, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884628.895, "dur": 1.192, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884628.6, "dur": 1.608, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884630.902, "dur": 4.46, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884635.82, "dur": 2.692, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884630.59, "dur": 9.692, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884641.68, "dur": 1.984, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884641.355, "dur": 2.452, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884641.05, "dur": 2.884, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884627.246, "dur": 17.056, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884626.707, "dur": 17.752, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884647.555, "dur": 8.108, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884656.65, "dur": 0.22, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884656.39, "dur": 0.568, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884657.324, "dur": 0.212, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884657.754, "dur": 0.46, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884658.777, "dur": 0.136, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884658.566, "dur": 0.448, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884656.156, "dur": 3.008, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884626.453, "dur": 32.884, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884659.754, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884659.625, "dur": 0.296, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884624.496, "dur": 35.568, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884623.562, "dur": 37.076, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884622.332, "dur": 38.48, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884587.785, "dur": 73.168, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884585.992, "dur": 75.92, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884583.94, "dur": 78.24, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926884792.168, "dur": 132.528, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926885096.074, "dur": 13089.492, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926898190.61, "dur": 2347.0, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926898188.83, "dur": 2349.036, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926898188.145, "dur": 2350.032, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926898187.344, "dur": 2351.096, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926901179.434, "dur": 65.644, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926900540.727, "dur": 2098.368, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902644.137, "dur": 0.408, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902642.4, "dur": 2.308, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902706.094, "dur": 35.948, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902762.297, "dur": 1.82, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902765.6, "dur": 0.24, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902767.977, "dur": 0.856, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902771.016, "dur": 0.384, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902770.633, "dur": 0.88, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902772.562, "dur": 0.244, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902774.605, "dur": 0.188, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902774.297, "dur": 0.564, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902775.29, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902775.902, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902775.79, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902770.254, "dur": 6.656, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902779.035, "dur": 0.38, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902780.86, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902780.496, "dur": 0.76, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902782.44, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902783.184, "dur": 0.256, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902782.74, "dur": 0.844, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902787.45, "dur": 0.564, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902782.27, "dur": 6.528, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902789.65, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902789.867, "dur": 0.116, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902790.797, "dur": 0.208, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902791.223, "dur": 0.164, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902790.617, "dur": 1.932, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902789.402, "dur": 3.36, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902795.742, "dur": 0.208, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902796.65, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902796.41, "dur": 0.684, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902797.48, "dur": 0.504, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902798.637, "dur": 0.34, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902799.684, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902800.453, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902801.074, "dur": 0.208, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902801.457, "dur": 1.032, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902778.64, "dur": 24.056, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902777.695, "dur": 25.644, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902804.395, "dur": 0.568, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902806.633, "dur": 0.184, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902807.594, "dur": 0.488, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902807.21, "dur": 1.052, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902809.734, "dur": 0.692, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902811.527, "dur": 0.74, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902811.16, "dur": 1.288, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902810.832, "dur": 1.728, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902813.36, "dur": 4.708, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902818.45, "dur": 3.52, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902813.03, "dur": 11.004, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902825.51, "dur": 2.08, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902825.14, "dur": 2.596, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902824.8, "dur": 3.08, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902809.445, "dur": 18.904, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902808.887, "dur": 19.608, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902829.56, "dur": 8.972, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902839.504, "dur": 0.16, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902839.297, "dur": 0.488, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902840.184, "dur": 0.224, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902840.64, "dur": 0.48, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902841.71, "dur": 0.168, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902841.527, "dur": 0.476, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902839.066, "dur": 3.056, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902808.6, "dur": 33.696, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902842.797, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902842.668, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902806.39, "dur": 36.696, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902805.344, "dur": 40.52, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902803.92, "dur": 42.104, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902769.61, "dur": 76.54, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902767.46, "dur": 79.588, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902764.88, "dur": 82.468, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902848.23, "dur": 5.988, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902854.855, "dur": 85.048, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926902940.125, "dur": 236.928, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926903182.977, "dur": 0.268, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926903185.91, "dur": 0.172, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926903185.5, "dur": 0.74, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926903186.7, "dur": 0.628, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926903187.668, "dur": 0.54, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926903185.027, "dur": 36403.796, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939595.086, "dur": 0.224, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939596.86, "dur": 4.392, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939602.625, "dur": 0.228, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939604.68, "dur": 0.684, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939607.344, "dur": 0.364, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939606.95, "dur": 0.888, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939608.773, "dur": 0.228, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939610.566, "dur": 0.132, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939610.3, "dur": 0.472, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939611.184, "dur": 0.076, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939611.77, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939611.664, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939606.617, "dur": 6.184, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939614.77, "dur": 0.116, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939616.105, "dur": 0.192, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939615.777, "dur": 0.74, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939617.47, "dur": 0.072, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939618.156, "dur": 0.272, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939617.816, "dur": 0.752, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939618.848, "dur": 0.436, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939617.316, "dur": 2.764, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939620.785, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939620.977, "dur": 0.124, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939621.895, "dur": 0.2, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939622.293, "dur": 0.128, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939621.723, "dur": 1.816, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939620.6, "dur": 3.124, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939626.44, "dur": 0.184, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939627.316, "dur": 0.076, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939627.105, "dur": 0.72, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939628.254, "dur": 0.456, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939629.305, "dur": 0.284, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939633.547, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939634.29, "dur": 0.18, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939634.89, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939635.234, "dur": 0.916, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939614.52, "dur": 21.836, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939613.633, "dur": 23.348, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939637.938, "dur": 0.528, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939639.973, "dur": 0.168, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939640.76, "dur": 0.48, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939640.445, "dur": 0.92, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939642.76, "dur": 0.724, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939644.547, "dur": 0.612, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939644.195, "dur": 1.128, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939643.867, "dur": 1.572, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939646.168, "dur": 4.576, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939651.19, "dur": 2.544, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939645.875, "dur": 9.728, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939657.016, "dur": 1.948, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939656.656, "dur": 2.468, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939656.39, "dur": 2.864, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939642.48, "dur": 17.228, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939641.977, "dur": 17.876, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939660.82, "dur": 7.996, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939669.723, "dur": 0.2, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939669.5, "dur": 0.516, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939670.37, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939670.824, "dur": 0.432, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939671.82, "dur": 0.104, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939671.63, "dur": 0.388, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939669.3, "dur": 2.864, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939641.7, "dur": 30.632, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939672.766, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939672.633, "dur": 0.3, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939639.758, "dur": 33.312, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939638.777, "dur": 34.876, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939637.51, "dur": 36.3, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939606.04, "dur": 67.912, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939604.19, "dur": 70.64, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939602.062, "dur": 73.02, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926939805.6, "dur": 131.908, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926940108.387, "dur": 13073.004, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926953186.11, "dur": 2329.24, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926953184.26, "dur": 2331.336, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926953183.645, "dur": 2332.296, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926953182.887, "dur": 2333.312, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926956162.52, "dur": 65.216, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926955518.5, "dur": 2107.672, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957634.695, "dur": 0.404, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957633.38, "dur": 1.872, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957696.48, "dur": 35.7, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957752.312, "dur": 1.852, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957755.605, "dur": 0.244, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957758.016, "dur": 0.852, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957761.133, "dur": 0.372, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957760.703, "dur": 0.888, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957762.598, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957764.64, "dur": 0.148, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957764.344, "dur": 0.512, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957765.254, "dur": 0.108, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957765.86, "dur": 0.06, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957765.754, "dur": 0.216, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957760.344, "dur": 6.524, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957769.16, "dur": 0.416, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957770.926, "dur": 0.24, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957770.625, "dur": 0.736, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957772.56, "dur": 0.06, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957773.285, "dur": 0.24, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957772.92, "dur": 0.728, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957773.938, "dur": 0.568, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957772.39, "dur": 2.84, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957775.99, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957776.215, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957777.105, "dur": 0.2, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957777.47, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957776.953, "dur": 1.724, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957775.8, "dur": 3.08, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957781.9, "dur": 0.204, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957782.773, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957782.53, "dur": 0.748, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957783.734, "dur": 0.436, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957784.758, "dur": 0.26, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957785.688, "dur": 0.188, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957786.49, "dur": 0.18, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957787.09, "dur": 0.168, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957787.434, "dur": 1.12, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957768.754, "dur": 20.008, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957767.805, "dur": 21.612, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957790.43, "dur": 0.484, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957792.49, "dur": 0.176, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957793.375, "dur": 0.488, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957793.004, "dur": 1.012, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957795.367, "dur": 0.784, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957797.29, "dur": 0.768, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957796.92, "dur": 4.888, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957796.56, "dur": 5.376, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957802.72, "dur": 4.896, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957808.08, "dur": 3.488, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957802.45, "dur": 11.112, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957815.03, "dur": 2.172, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957814.67, "dur": 2.684, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957814.375, "dur": 3.108, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957795.09, "dur": 22.856, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957794.633, "dur": 23.46, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957819.23, "dur": 8.88, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957829.09, "dur": 0.256, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957828.87, "dur": 0.584, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957829.848, "dur": 0.228, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957830.33, "dur": 0.452, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957831.46, "dur": 0.14, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957831.24, "dur": 0.464, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957828.625, "dur": 3.22, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957794.344, "dur": 37.656, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957832.477, "dur": 0.092, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957832.34, "dur": 0.296, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957792.258, "dur": 40.536, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957791.266, "dur": 42.168, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957789.98, "dur": 43.62, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957759.668, "dur": 74.084, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957757.45, "dur": 77.244, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957754.844, "dur": 80.14, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957835.93, "dur": 5.672, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957842.312, "dur": 84.24, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926957926.8, "dur": 237.304, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926958169.996, "dur": 0.26, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926958172.965, "dur": 0.14, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926958172.55, "dur": 0.692, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926958173.688, "dur": 0.692, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926958174.742, "dur": 0.492, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926958172.043, "dur": 36429.976, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994607.996, "dur": 0.252, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994609.88, "dur": 4.16, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994615.367, "dur": 0.184, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994617.332, "dur": 0.756, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994620.008, "dur": 0.388, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994619.61, "dur": 0.912, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994621.406, "dur": 0.204, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994623.1, "dur": 0.108, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994622.785, "dur": 0.5, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994623.695, "dur": 0.072, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994624.344, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994624.24, "dur": 3.572, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994619.305, "dur": 9.428, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994630.902, "dur": 0.108, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994632.203, "dur": 0.2, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994631.9, "dur": 0.736, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994633.645, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994634.332, "dur": 0.336, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994633.996, "dur": 0.78, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994635.08, "dur": 0.46, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994633.473, "dur": 2.8, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994637.004, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994637.2, "dur": 0.128, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994638.13, "dur": 0.172, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994638.47, "dur": 0.124, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994637.97, "dur": 1.664, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994636.83, "dur": 3.0, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994642.52, "dur": 0.176, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994643.363, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994643.152, "dur": 0.66, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994644.23, "dur": 0.392, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994645.215, "dur": 0.3, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994646.086, "dur": 0.156, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994646.98, "dur": 0.184, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994647.57, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994647.926, "dur": 0.9, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994630.67, "dur": 18.36, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994629.695, "dur": 19.908, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994650.527, "dur": 0.472, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994652.484, "dur": 0.2, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994653.348, "dur": 0.428, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994653.086, "dur": 0.848, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994655.406, "dur": 0.832, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994657.33, "dur": 0.628, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994656.945, "dur": 1.184, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994656.637, "dur": 1.616, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994658.91, "dur": 4.436, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994663.76, "dur": 2.524, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994658.62, "dur": 9.452, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994669.543, "dur": 2.044, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994669.203, "dur": 2.54, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994668.914, "dur": 2.968, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994655.1, "dur": 17.204, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994654.62, "dur": 17.828, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994673.44, "dur": 9.012, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994683.35, "dur": 0.16, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994683.137, "dur": 0.472, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994686.113, "dur": 0.24, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994686.55, "dur": 0.492, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994687.613, "dur": 0.124, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994687.434, "dur": 0.42, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994682.938, "dur": 5.044, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994654.26, "dur": 33.904, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994688.598, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994688.457, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994652.24, "dur": 36.636, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994651.305, "dur": 38.172, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994650.13, "dur": 39.512, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994618.742, "dur": 71.036, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994616.81, "dur": 73.86, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994614.832, "dur": 76.112, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926994820.504, "dur": 132.176, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406926995123.85, "dur": 13097.08, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927008226.33, "dur": 2331.02, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927008224.566, "dur": 2333.008, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927008223.797, "dur": 2334.084, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927008222.95, "dur": 2335.188, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927011204.316, "dur": 65.6, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927010560.543, "dur": 2103.032, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012668.09, "dur": 0.444, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012666.867, "dur": 1.804, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012729.39, "dur": 35.1, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012784.465, "dur": 1.936, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012787.89, "dur": 0.276, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012790.273, "dur": 0.824, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012793.32, "dur": 0.34, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012792.88, "dur": 0.88, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012794.746, "dur": 0.236, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012796.91, "dur": 0.192, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012796.594, "dur": 0.576, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012797.56, "dur": 0.084, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012798.164, "dur": 0.056, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012798.043, "dur": 0.228, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012792.527, "dur": 6.624, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012801.28, "dur": 0.348, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012803.0, "dur": 0.228, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012802.68, "dur": 0.792, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012804.625, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012805.305, "dur": 0.228, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012804.926, "dur": 0.756, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012805.99, "dur": 0.544, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012804.45, "dur": 2.86, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012808.055, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012808.297, "dur": 0.104, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012813.4, "dur": 0.26, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012813.84, "dur": 0.172, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012813.215, "dur": 1.928, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012807.87, "dur": 7.448, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012818.39, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012819.23, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012819.008, "dur": 0.696, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012820.164, "dur": 0.464, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012821.215, "dur": 0.232, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012822.117, "dur": 0.216, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012822.93, "dur": 0.188, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012823.543, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012823.88, "dur": 1.124, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012800.863, "dur": 24.368, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012799.945, "dur": 25.944, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012826.89, "dur": 0.484, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012828.863, "dur": 0.18, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012829.78, "dur": 0.5, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012829.414, "dur": 1.032, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012831.957, "dur": 0.724, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012833.86, "dur": 0.764, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012833.47, "dur": 1.328, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012833.09, "dur": 1.824, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012835.7, "dur": 4.716, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012840.895, "dur": 3.796, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012835.344, "dur": 11.368, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012848.086, "dur": 2.112, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012847.742, "dur": 2.592, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012847.473, "dur": 2.976, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012831.64, "dur": 19.256, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012831.08, "dur": 19.968, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012852.13, "dur": 10.064, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012863.12, "dur": 0.172, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012862.887, "dur": 0.496, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012863.73, "dur": 0.268, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012864.23, "dur": 0.44, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012865.227, "dur": 0.156, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012865.047, "dur": 0.448, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012862.67, "dur": 2.96, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012830.785, "dur": 35.004, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012866.254, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012866.12, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012828.633, "dur": 37.908, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012827.688, "dur": 39.424, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012826.434, "dur": 40.856, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012791.91, "dur": 75.528, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012789.758, "dur": 78.664, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012787.113, "dur": 83.968, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012872.05, "dur": 5.844, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012878.535, "dur": 84.524, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927012963.29, "dur": 237.292, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927013206.406, "dur": 0.26, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927013209.383, "dur": 0.176, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927013208.97, "dur": 0.724, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927013210.152, "dur": 0.692, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927013211.18, "dur": 0.552, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927013208.48, "dur": 36443.556, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049658.605, "dur": 0.264, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049660.754, "dur": 4.624, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049666.984, "dur": 0.256, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049669.29, "dur": 0.732, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049672.09, "dur": 0.36, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049671.7, "dur": 0.864, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049673.586, "dur": 0.248, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049675.543, "dur": 0.14, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049675.27, "dur": 0.492, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049676.184, "dur": 0.072, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049676.742, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049676.637, "dur": 0.204, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049671.344, "dur": 6.432, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049679.8, "dur": 0.104, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049681.156, "dur": 0.228, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049680.805, "dur": 0.804, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049682.6, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049683.324, "dur": 0.316, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049682.93, "dur": 0.864, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049684.105, "dur": 0.548, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049682.426, "dur": 2.924, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049686.234, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049686.44, "dur": 0.084, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049687.33, "dur": 0.184, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049687.71, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049687.16, "dur": 1.744, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049686.066, "dur": 3.008, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049691.81, "dur": 0.184, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049692.656, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049692.43, "dur": 0.708, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049693.777, "dur": 0.448, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049694.824, "dur": 0.248, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049695.72, "dur": 0.156, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049696.633, "dur": 0.204, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049697.293, "dur": 0.184, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049697.64, "dur": 0.768, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049679.555, "dur": 22.724, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049678.6, "dur": 24.352, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049704.0, "dur": 0.556, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049706.043, "dur": 0.172, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049706.848, "dur": 0.464, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049706.49, "dur": 0.928, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049708.965, "dur": 0.684, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049710.8, "dur": 0.68, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049710.445, "dur": 1.188, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049710.07, "dur": 1.668, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049712.484, "dur": 4.576, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049717.527, "dur": 2.928, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049712.13, "dur": 10.148, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049723.723, "dur": 1.992, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049723.414, "dur": 2.44, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049723.094, "dur": 2.888, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049708.65, "dur": 17.776, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049707.992, "dur": 18.576, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049727.51, "dur": 8.572, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049736.984, "dur": 0.228, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049736.77, "dur": 0.54, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049737.656, "dur": 0.24, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049738.145, "dur": 0.476, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049739.184, "dur": 0.116, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049738.97, "dur": 0.44, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049736.535, "dur": 3.012, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049707.703, "dur": 32.0, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049740.16, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049740.023, "dur": 0.288, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049705.832, "dur": 34.612, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049704.87, "dur": 36.18, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049703.56, "dur": 37.644, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049670.703, "dur": 70.64, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049668.76, "dur": 73.544, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049666.36, "dur": 76.216, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927049875.6, "dur": 133.424, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927050181.03, "dur": 13067.848, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927063254.613, "dur": 2311.468, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927063252.65, "dur": 2313.708, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927063251.793, "dur": 2314.944, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927063250.848, "dur": 2316.16, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927066214.49, "dur": 65.936, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927065569.426, "dur": 2117.88, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067692.215, "dur": 0.456, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067690.883, "dur": 1.952, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067754.363, "dur": 37.228, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067812.754, "dur": 1.916, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067820.195, "dur": 0.26, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067822.727, "dur": 0.844, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067825.855, "dur": 0.392, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067825.426, "dur": 0.928, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067827.28, "dur": 0.264, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067829.406, "dur": 0.164, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067829.098, "dur": 0.568, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067830.066, "dur": 0.076, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067830.684, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067830.566, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067825.1, "dur": 6.532, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067833.87, "dur": 0.376, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067835.57, "dur": 0.228, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067835.27, "dur": 0.724, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067837.12, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067837.875, "dur": 0.252, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067837.45, "dur": 0.824, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067838.61, "dur": 0.584, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067836.94, "dur": 2.964, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067840.61, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067840.832, "dur": 0.1, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067841.734, "dur": 0.2, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067842.105, "dur": 0.128, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067841.547, "dur": 1.692, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067840.44, "dur": 3.0, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067846.45, "dur": 0.176, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067847.36, "dur": 0.08, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067847.11, "dur": 0.788, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067848.676, "dur": 0.524, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067849.785, "dur": 0.232, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067850.63, "dur": 0.188, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067851.43, "dur": 0.204, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067852.047, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067852.39, "dur": 1.148, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067833.46, "dur": 20.292, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067832.504, "dur": 21.92, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067855.516, "dur": 0.564, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067857.53, "dur": 0.176, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067858.457, "dur": 0.532, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067858.047, "dur": 1.088, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067860.727, "dur": 0.82, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067862.777, "dur": 0.772, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067862.426, "dur": 1.296, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067861.977, "dur": 1.872, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067864.617, "dur": 4.784, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067869.785, "dur": 3.508, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067864.344, "dur": 12.976, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067878.676, "dur": 2.028, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067878.344, "dur": 2.512, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067878.04, "dur": 2.936, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067860.438, "dur": 20.948, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067859.773, "dur": 21.764, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067882.688, "dur": 9.716, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067893.4, "dur": 0.24, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067893.125, "dur": 0.596, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067894.133, "dur": 0.26, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067894.637, "dur": 0.396, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067895.617, "dur": 0.144, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067895.406, "dur": 0.452, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067892.902, "dur": 3.096, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067859.47, "dur": 36.684, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067896.61, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067896.465, "dur": 0.296, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067857.312, "dur": 39.588, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067856.42, "dur": 41.116, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067855.043, "dur": 42.652, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067824.414, "dur": 73.436, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067822.168, "dur": 76.592, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067819.37, "dur": 79.66, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067900.02, "dur": 6.34, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067907.027, "dur": 85.356, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927067992.645, "dur": 237.364, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927068235.934, "dur": 0.284, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927068239.05, "dur": 0.136, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927068238.656, "dur": 0.668, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927068239.754, "dur": 0.636, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927068240.71, "dur": 0.576, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927068238.19, "dur": 36460.012, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104704.344, "dur": 0.24, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104706.113, "dur": 4.444, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104712.074, "dur": 0.204, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104714.152, "dur": 0.784, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104716.816, "dur": 0.36, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104716.438, "dur": 0.82, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104718.15, "dur": 0.232, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104719.87, "dur": 0.12, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104719.605, "dur": 0.46, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104720.45, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104721.05, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104720.95, "dur": 0.2, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104716.137, "dur": 5.88, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104723.938, "dur": 0.136, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104725.152, "dur": 0.18, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104724.85, "dur": 4.356, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104730.09, "dur": 0.072, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104730.72, "dur": 0.32, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104730.39, "dur": 0.76, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104731.44, "dur": 0.476, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104729.938, "dur": 2.708, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104733.383, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104733.594, "dur": 0.072, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104734.47, "dur": 0.204, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104734.85, "dur": 0.156, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104734.33, "dur": 1.796, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104733.22, "dur": 3.084, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104739.016, "dur": 0.208, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104739.93, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104739.695, "dur": 0.712, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104740.848, "dur": 0.352, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104741.81, "dur": 0.248, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104742.688, "dur": 0.168, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104743.617, "dur": 0.16, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104744.18, "dur": 0.172, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104744.53, "dur": 0.872, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104723.7, "dur": 21.912, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104722.855, "dur": 23.348, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104747.266, "dur": 0.548, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104749.34, "dur": 0.2, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104750.18, "dur": 0.456, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104749.863, "dur": 0.904, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104752.45, "dur": 0.668, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104754.246, "dur": 0.608, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104753.867, "dur": 1.152, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104753.504, "dur": 1.62, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104755.887, "dur": 4.516, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104760.81, "dur": 2.532, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104755.547, "dur": 9.544, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104766.367, "dur": 1.96, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104766.086, "dur": 2.404, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104765.832, "dur": 2.768, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104752.203, "dur": 16.752, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104751.355, "dur": 17.744, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104769.95, "dur": 8.316, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104779.2, "dur": 0.208, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104778.977, "dur": 0.524, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104779.887, "dur": 0.22, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104780.32, "dur": 0.424, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104781.285, "dur": 0.124, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104781.08, "dur": 0.42, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104778.758, "dur": 7.884, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104751.098, "dur": 35.744, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104787.33, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104787.176, "dur": 0.3, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104749.1, "dur": 38.524, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104748.152, "dur": 40.04, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104746.824, "dur": 41.532, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104715.562, "dur": 72.936, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104713.65, "dur": 75.764, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104711.496, "dur": 78.172, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927104920.93, "dur": 133.004, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927105225.52, "dur": 13099.796, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927118330.66, "dur": 2329.32, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927118328.68, "dur": 2331.548, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927118327.957, "dur": 2332.572, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927118327.164, "dur": 2333.628, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927121303.312, "dur": 65.536, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927120663.113, "dur": 2098.448, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122766.402, "dur": 0.428, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122765.1, "dur": 1.876, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122829.586, "dur": 35.972, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122885.703, "dur": 1.9, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122889.04, "dur": 0.324, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122891.39, "dur": 0.8, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122894.336, "dur": 0.368, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122893.926, "dur": 0.852, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122895.773, "dur": 0.256, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122897.96, "dur": 0.144, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122897.64, "dur": 0.552, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122898.61, "dur": 0.092, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122899.21, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122899.105, "dur": 0.22, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122893.586, "dur": 6.62, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122902.504, "dur": 0.336, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122904.176, "dur": 0.232, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122903.848, "dur": 0.776, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122905.8, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122906.453, "dur": 0.228, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122906.098, "dur": 0.724, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122907.137, "dur": 0.544, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122905.62, "dur": 2.756, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122909.18, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122909.4, "dur": 0.084, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122910.332, "dur": 0.236, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122910.77, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122910.137, "dur": 1.912, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122908.992, "dur": 3.232, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122918.953, "dur": 0.172, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122919.86, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122919.617, "dur": 0.704, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122920.816, "dur": 0.512, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122921.992, "dur": 0.308, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122922.92, "dur": 0.168, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122923.684, "dur": 0.188, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122924.215, "dur": 0.196, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122924.586, "dur": 1.108, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122902.105, "dur": 23.796, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122901.09, "dur": 25.472, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122927.656, "dur": 0.512, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122929.695, "dur": 0.188, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122930.71, "dur": 0.504, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122930.305, "dur": 1.056, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122932.938, "dur": 0.708, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122934.816, "dur": 0.772, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122934.453, "dur": 1.324, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122934.08, "dur": 1.808, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122936.77, "dur": 4.928, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122942.113, "dur": 3.728, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122936.387, "dur": 11.444, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122949.188, "dur": 2.164, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122948.875, "dur": 2.632, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122948.605, "dur": 3.04, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122932.64, "dur": 19.452, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122932.043, "dur": 20.192, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122953.316, "dur": 9.292, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122963.586, "dur": 0.192, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122963.316, "dur": 0.536, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122964.188, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122964.664, "dur": 0.448, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122965.7, "dur": 0.136, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122965.496, "dur": 0.448, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122963.094, "dur": 2.984, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122931.76, "dur": 34.48, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122966.69, "dur": 0.096, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122966.56, "dur": 0.292, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122929.45, "dur": 37.568, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122928.504, "dur": 39.112, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122927.14, "dur": 40.636, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122892.95, "dur": 74.98, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122890.848, "dur": 77.98, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122888.312, "dur": 80.76, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122970.113, "dur": 5.944, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927122976.766, "dur": 84.904, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927123064.867, "dur": 237.312, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927123308.137, "dur": 0.224, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927123311.09, "dur": 0.152, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927123310.68, "dur": 0.708, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927123311.863, "dur": 0.596, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927123312.81, "dur": 0.6, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927123310.215, "dur": 36266.424, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159582.594, "dur": 0.212, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159584.477, "dur": 4.328, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159589.984, "dur": 0.18, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159591.973, "dur": 0.684, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159594.906, "dur": 0.36, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159594.477, "dur": 0.9, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159596.29, "dur": 0.24, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159598.13, "dur": 0.144, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159597.85, "dur": 0.488, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159598.766, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159599.375, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159599.258, "dur": 0.216, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159594.17, "dur": 6.268, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159602.305, "dur": 0.132, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159603.55, "dur": 0.152, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159603.273, "dur": 0.592, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159604.85, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159605.457, "dur": 0.336, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159605.16, "dur": 0.764, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159606.266, "dur": 0.504, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159604.645, "dur": 2.812, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159608.188, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159608.406, "dur": 0.12, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159609.305, "dur": 0.184, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159609.684, "dur": 0.144, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159609.133, "dur": 1.748, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159608.016, "dur": 3.052, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159613.816, "dur": 0.196, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159614.742, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159614.516, "dur": 0.664, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159615.652, "dur": 0.444, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159616.688, "dur": 0.264, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159617.55, "dur": 0.184, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159618.336, "dur": 0.192, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159618.87, "dur": 0.188, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159619.258, "dur": 0.896, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159602.07, "dur": 18.336, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159601.29, "dur": 19.708, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159622.062, "dur": 0.46, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159623.984, "dur": 0.168, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159627.984, "dur": 0.4, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159627.652, "dur": 0.868, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159629.895, "dur": 0.688, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159631.66, "dur": 0.596, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159631.297, "dur": 1.132, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159631.004, "dur": 1.524, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159633.254, "dur": 4.516, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159638.168, "dur": 2.72, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159632.93, "dur": 9.716, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159643.957, "dur": 2.092, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159643.625, "dur": 2.564, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159643.367, "dur": 2.944, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159629.61, "dur": 17.128, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159629.094, "dur": 17.792, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159647.715, "dur": 8.548, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159657.215, "dur": 0.224, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159656.996, "dur": 0.548, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159657.895, "dur": 0.192, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159658.31, "dur": 0.436, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159659.363, "dur": 0.132, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159659.15, "dur": 0.436, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159656.77, "dur": 2.944, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159628.84, "dur": 31.028, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159660.344, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159660.207, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159623.754, "dur": 36.904, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159622.832, "dur": 38.46, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159621.67, "dur": 39.788, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159593.645, "dur": 67.972, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159591.484, "dur": 70.988, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159589.55, "dur": 73.184, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927159792.973, "dur": 132.108, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927160095.633, "dur": 13105.184, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927173209.04, "dur": 2327.184, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927173206.293, "dur": 2330.196, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927173205.297, "dur": 2331.56, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927173204.0, "dur": 2333.12, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927176198.03, "dur": 67.384, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927175539.777, "dur": 2130.952, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177676.156, "dur": 0.744, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177674.707, "dur": 2.372, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177738.945, "dur": 38.504, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177800.64, "dur": 2.248, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177804.547, "dur": 0.324, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177807.234, "dur": 0.876, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177810.527, "dur": 0.372, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177810.023, "dur": 5.604, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177816.863, "dur": 0.256, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177819.76, "dur": 0.156, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177819.355, "dur": 0.652, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177820.457, "dur": 0.1, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177821.09, "dur": 0.064, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177820.97, "dur": 0.248, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177809.67, "dur": 12.548, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177824.848, "dur": 0.448, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177826.77, "dur": 0.204, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177826.414, "dur": 0.784, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177828.43, "dur": 0.072, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177829.258, "dur": 0.224, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177828.9, "dur": 0.716, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177830.01, "dur": 0.836, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177828.242, "dur": 3.392, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177832.5, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177832.72, "dur": 0.092, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177833.875, "dur": 0.22, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177834.29, "dur": 0.148, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177833.68, "dur": 1.896, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177832.312, "dur": 3.492, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177839.273, "dur": 0.224, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177840.344, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177840.11, "dur": 0.756, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177841.465, "dur": 0.624, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177842.867, "dur": 0.284, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177843.85, "dur": 0.196, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177844.688, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177845.29, "dur": 0.184, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177845.645, "dur": 1.148, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177824.37, "dur": 22.704, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177823.285, "dur": 24.484, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177848.824, "dur": 0.532, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177851.074, "dur": 0.216, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177852.12, "dur": 0.524, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177851.72, "dur": 1.076, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177854.344, "dur": 0.76, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177856.48, "dur": 0.836, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177856.02, "dur": 1.484, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177855.586, "dur": 2.032, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177858.5, "dur": 5.368, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177864.348, "dur": 3.964, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177858.105, "dur": 12.32, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177871.98, "dur": 2.476, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177871.566, "dur": 3.064, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177871.254, "dur": 3.512, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177854.04, "dur": 23.864, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177853.457, "dur": 24.596, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177879.367, "dur": 9.616, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177890.13, "dur": 0.24, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177889.883, "dur": 0.592, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177890.86, "dur": 0.244, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177891.367, "dur": 0.492, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177892.445, "dur": 0.12, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177892.266, "dur": 0.424, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177889.617, "dur": 3.216, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177853.145, "dur": 39.852, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177893.465, "dur": 0.084, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177893.332, "dur": 0.28, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177850.77, "dur": 42.992, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177849.7, "dur": 44.692, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177848.348, "dur": 46.224, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177809.0, "dur": 85.72, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177806.64, "dur": 89.096, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177803.62, "dur": 92.408, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177897.207, "dur": 6.68, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177904.62, "dur": 86.828, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927177991.72, "dur": 237.272, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927178235.33, "dur": 0.296, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927178238.625, "dur": 0.148, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927178238.246, "dur": 0.672, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927178239.344, "dur": 0.692, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927178240.383, "dur": 0.66, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927178237.688, "dur": 36535.608, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214779.504, "dur": 0.272, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214781.715, "dur": 4.432, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214787.523, "dur": 0.288, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214789.863, "dur": 0.768, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214792.7, "dur": 0.528, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214792.273, "dur": 1.096, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214794.35, "dur": 0.22, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214796.53, "dur": 0.148, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214796.156, "dur": 0.616, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214797.21, "dur": 0.072, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214797.76, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214797.656, "dur": 0.208, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214791.957, "dur": 6.8, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214800.785, "dur": 0.104, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214802.105, "dur": 0.184, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214801.84, "dur": 0.672, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214803.426, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214804.105, "dur": 0.292, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214803.76, "dur": 0.748, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214808.625, "dur": 0.5, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214803.266, "dur": 6.6, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214810.785, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214811.023, "dur": 0.072, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214812.043, "dur": 0.196, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214812.445, "dur": 0.144, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214811.855, "dur": 1.9, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214810.594, "dur": 3.368, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214816.926, "dur": 0.18, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214817.816, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214817.574, "dur": 0.728, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214818.785, "dur": 0.588, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214820.113, "dur": 0.304, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214821.08, "dur": 0.152, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214821.996, "dur": 0.204, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214822.598, "dur": 0.196, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214822.95, "dur": 0.844, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214800.56, "dur": 23.444, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214799.637, "dur": 25.012, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214825.668, "dur": 0.5, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214827.867, "dur": 0.188, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214828.72, "dur": 0.476, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214828.445, "dur": 0.916, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214830.742, "dur": 0.764, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214832.664, "dur": 0.692, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214832.348, "dur": 1.176, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214831.953, "dur": 1.688, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214834.516, "dur": 4.644, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214839.57, "dur": 2.756, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214834.113, "dur": 10.068, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214845.56, "dur": 2.28, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214845.254, "dur": 2.752, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214844.957, "dur": 3.176, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214830.496, "dur": 18.096, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214829.965, "dur": 18.784, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214849.84, "dur": 8.16, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214858.906, "dur": 0.18, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214858.715, "dur": 0.448, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214859.535, "dur": 0.248, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214860.06, "dur": 0.424, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214861.047, "dur": 0.124, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214860.848, "dur": 0.428, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214858.516, "dur": 2.916, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214829.703, "dur": 31.88, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214862.02, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214861.89, "dur": 0.284, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214827.566, "dur": 36.756, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214826.53, "dur": 38.428, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214825.223, "dur": 39.92, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214791.37, "dur": 73.928, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214789.32, "dur": 76.84, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214786.945, "dur": 79.472, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927214998.184, "dur": 134.816, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927215304.74, "dur": 13100.816, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927228411.062, "dur": 2324.728, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927228408.96, "dur": 2327.084, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927228408.258, "dur": 2328.136, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927228407.28, "dur": 2329.372, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927231380.906, "dur": 65.7, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927230738.832, "dur": 2098.664, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232842.117, "dur": 0.516, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232840.766, "dur": 2.016, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232903.812, "dur": 36.916, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232961.145, "dur": 1.828, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232964.555, "dur": 0.304, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232967.03, "dur": 0.836, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232970.08, "dur": 0.384, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232969.65, "dur": 0.944, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232971.55, "dur": 0.252, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232973.96, "dur": 0.176, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232973.62, "dur": 0.588, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232974.668, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232975.336, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232975.215, "dur": 0.22, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232969.285, "dur": 7.052, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232978.605, "dur": 0.404, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232980.41, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232980.098, "dur": 0.696, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232982.04, "dur": 0.068, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232982.793, "dur": 0.248, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232982.41, "dur": 0.752, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232983.49, "dur": 0.556, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232981.863, "dur": 2.908, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232985.535, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232985.78, "dur": 0.096, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232986.836, "dur": 0.192, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232987.254, "dur": 0.14, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232986.66, "dur": 1.884, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232985.35, "dur": 3.384, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232991.824, "dur": 0.192, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232992.746, "dur": 0.068, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232992.49, "dur": 0.76, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232993.8, "dur": 0.428, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232998.996, "dur": 0.276, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232999.953, "dur": 0.172, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233000.754, "dur": 0.184, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233001.387, "dur": 0.208, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233001.758, "dur": 1.148, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232978.188, "dur": 24.932, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232977.2, "dur": 26.584, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233004.824, "dur": 0.532, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233006.902, "dur": 0.18, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233007.91, "dur": 0.448, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233007.5, "dur": 1.048, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233010.098, "dur": 0.852, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233012.176, "dur": 0.82, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233011.777, "dur": 1.392, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233011.387, "dur": 1.9, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233014.176, "dur": 4.7, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233019.355, "dur": 3.86, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233013.797, "dur": 11.424, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233026.633, "dur": 2.176, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233026.26, "dur": 2.696, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233026.004, "dur": 3.076, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233009.824, "dur": 19.736, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233009.258, "dur": 20.448, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233030.97, "dur": 9.496, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233041.473, "dur": 0.148, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233041.215, "dur": 0.508, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233042.086, "dur": 0.268, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233042.63, "dur": 0.416, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233043.61, "dur": 0.144, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233043.4, "dur": 0.468, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233041.0, "dur": 3.016, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233008.91, "dur": 35.256, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233044.6, "dur": 0.076, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233044.465, "dur": 0.276, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233006.67, "dur": 38.216, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233005.73, "dur": 39.812, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233004.305, "dur": 41.388, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232968.633, "dur": 77.196, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232966.51, "dur": 80.228, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927232963.695, "dur": 83.352, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233047.96, "dur": 5.896, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233054.508, "dur": 85.496, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233140.234, "dur": 237.56, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233383.73, "dur": 0.228, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233386.836, "dur": 0.152, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233386.395, "dur": 0.732, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233390.68, "dur": 0.648, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233391.652, "dur": 0.628, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927233385.836, "dur": 36453.616, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269845.45, "dur": 0.2, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269847.215, "dur": 4.416, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269852.89, "dur": 0.184, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269854.902, "dur": 0.724, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269857.61, "dur": 0.34, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269857.223, "dur": 0.832, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269858.906, "dur": 0.228, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269860.87, "dur": 0.14, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269860.562, "dur": 0.516, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269861.53, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269862.168, "dur": 0.04, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269862.043, "dur": 0.212, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269856.89, "dur": 6.272, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269865.1, "dur": 0.116, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269866.402, "dur": 0.188, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269866.12, "dur": 0.648, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269867.668, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269868.316, "dur": 0.276, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269867.97, "dur": 0.78, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269869.035, "dur": 0.48, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269867.496, "dur": 2.78, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269871.004, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269871.242, "dur": 0.108, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269872.184, "dur": 0.216, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269872.574, "dur": 0.136, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269872.035, "dur": 1.78, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269870.824, "dur": 3.172, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269876.617, "dur": 0.216, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269877.562, "dur": 0.076, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269877.332, "dur": 0.728, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269878.56, "dur": 0.396, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269879.543, "dur": 0.296, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269880.52, "dur": 0.164, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269881.32, "dur": 0.176, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269881.855, "dur": 0.168, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269882.19, "dur": 0.992, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269864.88, "dur": 18.504, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269863.992, "dur": 19.964, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269884.95, "dur": 0.532, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269887.004, "dur": 0.18, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269887.83, "dur": 0.412, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269887.508, "dur": 0.892, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269889.766, "dur": 0.7, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269891.535, "dur": 0.656, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269891.16, "dur": 4.352, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269890.87, "dur": 4.744, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269896.477, "dur": 4.604, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269901.434, "dur": 2.768, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269896.074, "dur": 9.944, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269907.426, "dur": 2.02, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269907.1, "dur": 2.508, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269906.832, "dur": 2.896, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269889.465, "dur": 20.672, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269888.992, "dur": 21.276, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269911.305, "dur": 8.276, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269920.504, "dur": 0.2, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269920.273, "dur": 0.532, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269921.18, "dur": 0.268, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269921.69, "dur": 0.404, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269922.715, "dur": 0.132, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269922.508, "dur": 0.448, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269920.062, "dur": 3.028, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269888.727, "dur": 34.52, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269923.703, "dur": 0.112, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269923.57, "dur": 0.316, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269886.793, "dur": 37.232, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269885.816, "dur": 38.804, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269884.523, "dur": 40.252, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269856.273, "dur": 68.64, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269854.426, "dur": 71.352, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927269852.316, "dur": 73.704, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927270054.8, "dur": 132.244, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927270358.47, "dur": 13079.068, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927283442.273, "dur": 2317.744, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927283440.426, "dur": 2319.792, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927283439.77, "dur": 2320.736, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927283438.957, "dur": 2321.82, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927286407.36, "dur": 65.44, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927285762.87, "dur": 2104.88, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287872.65, "dur": 0.412, "name": "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287871.33, "dur": 1.88, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287934.094, "dur": 35.864, "name": "type.all", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287990.38, "dur": 1.756, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287993.664, "dur": 0.272, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287996.055, "dur": 0.86, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287999.17, "dur": 0.36, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287998.707, "dur": 0.928, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288000.633, "dur": 0.224, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288002.824, "dur": 0.128, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288002.523, "dur": 0.496, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288007.113, "dur": 0.08, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288007.746, "dur": 0.044, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288007.633, "dur": 0.232, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287998.37, "dur": 10.436, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288011.086, "dur": 0.388, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288012.914, "dur": 0.196, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288012.6, "dur": 0.724, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288014.527, "dur": 0.064, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288015.297, "dur": 0.24, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288014.87, "dur": 0.796, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288015.973, "dur": 0.552, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288014.35, "dur": 2.944, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288018.062, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288018.254, "dur": 0.084, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288019.145, "dur": 0.2, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288019.52, "dur": 0.164, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288018.98, "dur": 1.796, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288017.89, "dur": 3.072, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288024.11, "dur": 0.188, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288024.98, "dur": 0.08, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288024.742, "dur": 0.696, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288025.848, "dur": 0.5, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288026.984, "dur": 0.264, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288027.89, "dur": 0.176, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288028.645, "dur": 0.196, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288029.223, "dur": 0.192, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288029.586, "dur": 1.12, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288010.664, "dur": 20.24, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288009.72, "dur": 21.816, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288032.523, "dur": 0.556, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288034.64, "dur": 0.184, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288035.594, "dur": 0.504, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288035.18, "dur": 1.016, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288037.766, "dur": 0.848, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288039.812, "dur": 0.764, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288039.434, "dur": 1.304, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288039.1, "dur": 1.756, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288041.69, "dur": 4.652, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288046.785, "dur": 3.56, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288041.332, "dur": 10.928, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288053.723, "dur": 2.144, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288053.37, "dur": 2.648, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288053.066, "dur": 3.084, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288037.445, "dur": 19.136, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288036.86, "dur": 19.86, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288057.83, "dur": 9.068, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288068.016, "dur": 0.184, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288067.758, "dur": 2.844, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288070.965, "dur": 0.244, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288071.48, "dur": 0.46, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288072.59, "dur": 0.172, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288072.39, "dur": 0.48, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288067.457, "dur": 5.556, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288036.547, "dur": 36.648, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288073.71, "dur": 0.088, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288073.574, "dur": 0.304, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288034.406, "dur": 39.62, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288033.41, "dur": 41.224, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288032.113, "dur": 42.688, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287997.727, "dur": 77.224, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287995.5, "dur": 80.368, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927287992.867, "dur": 83.244, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288077.027, "dur": 5.828, "name": "Tensor.unsqueeze", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288083.473, "dur": 84.568, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288168.297, "dur": 237.312, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288411.29, "dur": 0.3, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288414.223, "dur": 0.132, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288413.81, "dur": 0.688, "name": "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288414.906, "dur": 0.66, "name": "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288415.902, "dur": 0.584, "name": "Tensor.is_complex", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927288413.332, "dur": 36458.892, "name": "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324881.094, "dur": 0.444, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324883.797, "dur": 4.828, "name": "str.format", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324890.22, "dur": 0.288, "name": "builtins.len", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324892.723, "dur": 0.784, "name": "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324895.66, "dur": 0.416, "name": "sys._getframe", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324895.22, "dur": 0.964, "name": "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324897.22, "dur": 0.244, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324899.36, "dur": 0.128, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324899.066, "dur": 0.508, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324900.004, "dur": 0.068, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324900.617, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324900.496, "dur": 0.268, "name": "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324894.9, "dur": 6.772, "name": "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324903.832, "dur": 0.144, "name": "time.time", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324905.387, "dur": 0.216, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324905.098, "dur": 0.684, "name": "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324906.715, "dur": 0.052, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324907.375, "dur": 0.304, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324907.0, "dur": 0.824, "name": "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324908.1, "dur": 0.576, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324906.543, "dur": 2.888, "name": "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324910.16, "dur": 0.048, "name": "posix.fspath", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324913.043, "dur": 0.1, "name": "builtins.isinstance", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324913.98, "dur": 0.188, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324914.367, "dur": 0.144, "name": "str.rfind", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324913.797, "dur": 1.836, "name": "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324909.99, "dur": 5.824, "name": "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324918.734, "dur": 0.164, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324919.617, "dur": 0.072, "name": "_thread.get_ident", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324919.387, "dur": 0.732, "name": "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324920.523, "dur": 0.528, "name": "name (/root/miniconda3/lib/python3.8/threading.py:1031)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324921.656, "dur": 0.34, "name": "dict.get", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324922.617, "dur": 0.192, "name": "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324923.594, "dur": 0.188, "name": "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324924.133, "dur": 0.176, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324924.492, "dur": 1.092, "name": "posix.getpid", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324903.598, "dur": 22.204, "name": "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324902.504, "dur": 23.94, "name": "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324927.434, "dur": 0.488, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324929.5, "dur": 0.18, "name": "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324930.39, "dur": 0.496, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324929.99, "dur": 1.052, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324932.55, "dur": 0.692, "name": "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324934.348, "dur": 0.648, "name": "str.find", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324933.98, "dur": 1.208, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324933.65, "dur": 1.644, "name": "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324936.145, "dur": 4.64, "name": "time.localtime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324941.242, "dur": 3.704, "name": "time.strftime", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324935.793, "dur": 11.02, "name": "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324948.26, "dur": 2.14, "name": "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324947.92, "dur": 2.628, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324947.65, "dur": 3.016, "name": "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324932.24, "dur": 18.824, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324931.67, "dur": 19.536, "name": "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324952.18, "dur": 8.696, "name": "_io.TextIOWrapper.write", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324961.8, "dur": 0.168, "name": "_thread.RLock.acquire", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324961.547, "dur": 0.488, "name": "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324962.4, "dur": 0.216, "name": "builtins.hasattr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324962.84, "dur": 0.448, "name": "_io.TextIOWrapper.flush", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324963.9, "dur": 0.128, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324963.652, "dur": 0.464, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324961.332, "dur": 2.924, "name": "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324931.367, "dur": 33.056, "name": "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324964.887, "dur": 0.128, "name": "_thread.RLock.release", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324964.754, "dur": 0.336, "name": "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324929.258, "dur": 35.976, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324928.258, "dur": 37.548, "name": "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324926.992, "dur": 38.968, "name": "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324894.203, "dur": 71.884, "name": "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324892.18, "dur": 76.668, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927324889.6, "dur": 79.504, "name": "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927325109.367, "dur": 135.208, "name": "type.where", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927325417.445, "dur": 13101.88, "name": "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927338524.742, "dur": 2336.016, "name": "torch._ops.torch_scatter.segment_sum_csr", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927338522.793, "dur": 2338.172, "name": "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927338522.18, "dur": 2339.132, "name": "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927338521.363, "dur": 2340.236, "name": "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927341509.465, "dur": 65.264, "name": "type.abs", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927340863.812, "dur": 2109.748, "name": "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927342977.0, "dur": 0.756, "name": "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927343023.434, "dur": 41.656, "name": "type.zeros_like", "ph": "X", "cat": "FEE"}, {"pid": 30032, "tid": 30032, "ts": 18406927343128.574, "dur": 37.32, "name": "type.all", "ph": "X", "cat": "FEE"}], "viztracer_metadata": {"version": "0.15.6", "overflow": false}, "file_info": {"files": {"/root/miniconda3/lib/python3.8/logging/__init__.py": ["# Copyright 2001-2017 by Vinay Sajip. All Rights Reserved.\n#\n# Permission to use, copy, modify, and distribute this software and its\n# documentation for any purpose and without fee is hereby granted,\n# provided that the above copyright notice appear in all copies and that\n# both that copyright notice and this permission notice appear in\n# supporting documentation, and that the name of Vinay Sajip\n# not be used in advertising or publicity pertaining to distribution\n# of the software without specific, written prior permission.\n# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING\n# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\n# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR\n# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER\n# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\n# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n\"\"\"\nLogging package for Python. Based on PEP 282 and comments thereto in\ncomp.lang.python.\n\nCopyright (C) 2001-2017 Vinay Sajip. All Rights Reserved.\n\nTo use, simply 'import logging' and log away!\n\"\"\"\n\nimport sys, os, time, io, re, traceback, warnings, weakref, collections.abc\n\nfrom string import Template\nfrom string import Formatter as StrFormatter\n\n\n__all__ = ['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR',\n           'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO',\n           'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler',\n           'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig',\n           'captureWarnings', 'critical', 'debug', 'disable', 'error',\n           'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass',\n           'info', 'log', 'makeLogRecord', 'setLoggerClass', 'shutdown',\n           'warn', 'warning', 'getLogRecordFactory', 'setLogRecordFactory',\n           'lastResort', 'raiseExceptions']\n\nimport threading\n\n__author__  = \"Vinay Sajip <vinay_sajip@red-dove.com>\"\n__status__  = \"production\"\n# The following module attributes are no longer updated.\n__version__ = \"0.5.1.2\"\n__date__    = \"07 February 2010\"\n\n#---------------------------------------------------------------------------\n#   Miscellaneous module data\n#---------------------------------------------------------------------------\n\n#\n#_startTime is used as the base when calculating the relative time of events\n#\n_startTime = time.time()\n\n#\n#raiseExceptions is used to see if exceptions during handling should be\n#propagated\n#\nraiseExceptions = True\n\n#\n# If you don't want threading information in the log, set this to zero\n#\nlogThreads = True\n\n#\n# If you don't want multiprocessing information in the log, set this to zero\n#\nlogMultiprocessing = True\n\n#\n# If you don't want process information in the log, set this to zero\n#\nlogProcesses = True\n\n#---------------------------------------------------------------------------\n#   Level related stuff\n#---------------------------------------------------------------------------\n#\n# Default levels and level names, these can be replaced with any positive set\n# of values having corresponding names. There is a pseudo-level, NOTSET, which\n# is only really there as a lower limit for user-defined levels. Handlers and\n# loggers are initialized with NOTSET so that they will log all messages, even\n# at user-defined levels.\n#\n\nCRITICAL = 50\nFATAL = CRITICAL\nERROR = 40\nWARNING = 30\nWARN = WARNING\nINFO = 20\nDEBUG = 10\nNOTSET = 0\n\n_levelToName = {\n    CRITICAL: 'CRITICAL',\n    ERROR: 'ERROR',\n    WARNING: 'WARNING',\n    INFO: 'INFO',\n    DEBUG: 'DEBUG',\n    NOTSET: 'NOTSET',\n}\n_nameToLevel = {\n    'CRITICAL': CRITICAL,\n    'FATAL': FATAL,\n    'ERROR': ERROR,\n    'WARN': WARNING,\n    'WARNING': WARNING,\n    'INFO': INFO,\n    'DEBUG': DEBUG,\n    'NOTSET': NOTSET,\n}\n\ndef getLevelName(level):\n    \"\"\"\n    Return the textual or numeric representation of logging level 'level'.\n\n    If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,\n    INFO, DEBUG) then you get the corresponding string. If you have\n    associated levels with names using addLevelName then the name you have\n    associated with 'level' is returned.\n\n    If a numeric value corresponding to one of the defined levels is passed\n    in, the corresponding string representation is returned.\n\n    If a string representation of the level is passed in, the corresponding\n    numeric value is returned.\n\n    If no matching numeric or string value is passed in, the string\n    'Level %s' % level is returned.\n    \"\"\"\n    # See Issues #22386, #27937 and #29220 for why it's this way\n    result = _levelToName.get(level)\n    if result is not None:\n        return result\n    result = _nameToLevel.get(level)\n    if result is not None:\n        return result\n    return \"Level %s\" % level\n\ndef addLevelName(level, levelName):\n    \"\"\"\n    Associate 'levelName' with 'level'.\n\n    This is used when converting levels to text during message formatting.\n    \"\"\"\n    _acquireLock()\n    try:    #unlikely to cause an exception, but you never know...\n        _levelToName[level] = levelName\n        _nameToLevel[levelName] = level\n    finally:\n        _releaseLock()\n\nif hasattr(sys, '_getframe'):\n    currentframe = lambda: sys._getframe(3)\nelse: #pragma: no cover\n    def currentframe():\n        \"\"\"Return the frame object for the caller's stack frame.\"\"\"\n        try:\n            raise Exception\n        except Exception:\n            return sys.exc_info()[2].tb_frame.f_back\n\n#\n# _srcfile is used when walking the stack to check when we've got the first\n# caller stack frame, by skipping frames whose filename is that of this\n# module's source. It therefore should contain the filename of this module's\n# source file.\n#\n# Ordinarily we would use __file__ for this, but frozen modules don't always\n# have __file__ set, for some reason (see Issue #21736). Thus, we get the\n# filename from a handy code object from a function defined in this module.\n# (There's no particular reason for picking addLevelName.)\n#\n\n_srcfile = os.path.normcase(addLevelName.__code__.co_filename)\n\n# _srcfile is only used in conjunction with sys._getframe().\n# To provide compatibility with older versions of Python, set _srcfile\n# to None if _getframe() is not available; this value will prevent\n# findCaller() from being called. You can also do this if you want to avoid\n# the overhead of fetching caller information, even when _getframe() is\n# available.\n#if not hasattr(sys, '_getframe'):\n#    _srcfile = None\n\n\ndef _checkLevel(level):\n    if isinstance(level, int):\n        rv = level\n    elif str(level) == level:\n        if level not in _nameToLevel:\n            raise ValueError(\"Unknown level: %r\" % level)\n        rv = _nameToLevel[level]\n    else:\n        raise TypeError(\"Level not an integer or a valid string: %r\" % level)\n    return rv\n\n#---------------------------------------------------------------------------\n#   Thread-related stuff\n#---------------------------------------------------------------------------\n\n#\n#_lock is used to serialize access to shared data structures in this module.\n#This needs to be an RLock because fileConfig() creates and configures\n#Handlers, and so might arbitrary user threads. Since Handler code updates the\n#shared dictionary _handlers, it needs to acquire the lock. But if configuring,\n#the lock would already have been acquired - so we need an RLock.\n#The same argument applies to Loggers and Manager.loggerDict.\n#\n_lock = threading.RLock()\n\ndef _acquireLock():\n    \"\"\"\n    Acquire the module-level lock for serializing access to shared data.\n\n    This should be released with _releaseLock().\n    \"\"\"\n    if _lock:\n        _lock.acquire()\n\ndef _releaseLock():\n    \"\"\"\n    Release the module-level lock acquired by calling _acquireLock().\n    \"\"\"\n    if _lock:\n        _lock.release()\n\n\n# Prevent a held logging lock from blocking a child from logging.\n\nif not hasattr(os, 'register_at_fork'):  # Windows and friends.\n    def _register_at_fork_reinit_lock(instance):\n        pass  # no-op when os.register_at_fork does not exist.\nelse:\n    # A collection of instances with a createLock method (logging.Handler)\n    # to be called in the child after forking.  The weakref avoids us keeping\n    # discarded Handler instances alive.  A set is used to avoid accumulating\n    # duplicate registrations as createLock() is responsible for registering\n    # a new Handler instance with this set in the first place.\n    _at_fork_reinit_lock_weakset = weakref.WeakSet()\n\n    def _register_at_fork_reinit_lock(instance):\n        _acquireLock()\n        try:\n            _at_fork_reinit_lock_weakset.add(instance)\n        finally:\n            _releaseLock()\n\n    def _after_at_fork_child_reinit_locks():\n        # _acquireLock() was called in the parent before forking.\n        for handler in _at_fork_reinit_lock_weakset:\n            try:\n                handler.createLock()\n            except Exception as err:\n                # Similar to what PyErr_WriteUnraisable does.\n                print(\"Ignoring exception from logging atfork\", instance,\n                      \"._reinit_lock() method:\", err, file=sys.stderr)\n        _releaseLock()  # Acquired by os.register_at_fork(before=.\n\n\n    os.register_at_fork(before=_acquireLock,\n                        after_in_child=_after_at_fork_child_reinit_locks,\n                        after_in_parent=_releaseLock)\n\n\n#---------------------------------------------------------------------------\n#   The logging record\n#---------------------------------------------------------------------------\n\nclass LogRecord(object):\n    \"\"\"\n    A LogRecord instance represents an event being logged.\n\n    LogRecord instances are created every time something is logged. They\n    contain all the information pertinent to the event being logged. The\n    main information passed in is in msg and args, which are combined\n    using str(msg) % args to create the message field of the record. The\n    record also includes information such as when the record was created,\n    the source line where the logging call was made, and any exception\n    information to be logged.\n    \"\"\"\n    def __init__(self, name, level, pathname, lineno,\n                 msg, args, exc_info, func=None, sinfo=None, **kwargs):\n        \"\"\"\n        Initialize a logging record with interesting information.\n        \"\"\"\n        ct = time.time()\n        self.name = name\n        self.msg = msg\n        #\n        # The following statement allows passing of a dictionary as a sole\n        # argument, so that you can do something like\n        #  logging.debug(\"a %(a)d b %(b)s\", {'a':1, 'b':2})\n        # Suggested by Stefan Behnel.\n        # Note that without the test for args[0], we get a problem because\n        # during formatting, we test to see if the arg is present using\n        # 'if self.args:'. If the event being logged is e.g. 'Value is %d'\n        # and if the passed arg fails 'if self.args:' then no formatting\n        # is done. For example, logger.warning('Value is %d', 0) would log\n        # 'Value is %d' instead of 'Value is 0'.\n        # For the use case of passing a dictionary, this should not be a\n        # problem.\n        # Issue #21172: a request was made to relax the isinstance check\n        # to hasattr(args[0], '__getitem__'). However, the docs on string\n        # formatting still seem to suggest a mapping object is required.\n        # Thus, while not removing the isinstance check, it does now look\n        # for collections.abc.Mapping rather than, as before, dict.\n        if (args and len(args) == 1 and isinstance(args[0], collections.abc.Mapping)\n            and args[0]):\n            args = args[0]\n        self.args = args\n        self.levelname = getLevelName(level)\n        self.levelno = level\n        self.pathname = pathname\n        try:\n            self.filename = os.path.basename(pathname)\n            self.module = os.path.splitext(self.filename)[0]\n        except (TypeError, ValueError, AttributeError):\n            self.filename = pathname\n            self.module = \"Unknown module\"\n        self.exc_info = exc_info\n        self.exc_text = None      # used to cache the traceback text\n        self.stack_info = sinfo\n        self.lineno = lineno\n        self.funcName = func\n        self.created = ct\n        self.msecs = (ct - int(ct)) * 1000\n        self.relativeCreated = (self.created - _startTime) * 1000\n        if logThreads:\n            self.thread = threading.get_ident()\n            self.threadName = threading.current_thread().name\n        else: # pragma: no cover\n            self.thread = None\n            self.threadName = None\n        if not logMultiprocessing: # pragma: no cover\n            self.processName = None\n        else:\n            self.processName = 'MainProcess'\n            mp = sys.modules.get('multiprocessing')\n            if mp is not None:\n                # Errors may occur if multiprocessing has not finished loading\n                # yet - e.g. if a custom import hook causes third-party code\n                # to run when multiprocessing calls import. See issue 8200\n                # for an example\n                try:\n                    self.processName = mp.current_process().name\n                except Exception: #pragma: no cover\n                    pass\n        if logProcesses and hasattr(os, 'getpid'):\n            self.process = os.getpid()\n        else:\n            self.process = None\n\n    def __repr__(self):\n        return '<LogRecord: %s, %s, %s, %s, \"%s\">'%(self.name, self.levelno,\n            self.pathname, self.lineno, self.msg)\n\n    def getMessage(self):\n        \"\"\"\n        Return the message for this LogRecord.\n\n        Return the message for this LogRecord after merging any user-supplied\n        arguments with the message.\n        \"\"\"\n        msg = str(self.msg)\n        if self.args:\n            msg = msg % self.args\n        return msg\n\n#\n#   Determine which class to use when instantiating log records.\n#\n_logRecordFactory = LogRecord\n\ndef setLogRecordFactory(factory):\n    \"\"\"\n    Set the factory to be used when instantiating a log record.\n\n    :param factory: A callable which will be called to instantiate\n    a log record.\n    \"\"\"\n    global _logRecordFactory\n    _logRecordFactory = factory\n\ndef getLogRecordFactory():\n    \"\"\"\n    Return the factory to be used when instantiating a log record.\n    \"\"\"\n\n    return _logRecordFactory\n\ndef makeLogRecord(dict):\n    \"\"\"\n    Make a LogRecord whose attributes are defined by the specified dictionary,\n    This function is useful for converting a logging event received over\n    a socket connection (which is sent as a dictionary) into a LogRecord\n    instance.\n    \"\"\"\n    rv = _logRecordFactory(None, None, \"\", 0, \"\", (), None, None)\n    rv.__dict__.update(dict)\n    return rv\n\n\n#---------------------------------------------------------------------------\n#   Formatter classes and functions\n#---------------------------------------------------------------------------\n_str_formatter = StrFormatter()\ndel StrFormatter\n\n\nclass PercentStyle(object):\n\n    default_format = '%(message)s'\n    asctime_format = '%(asctime)s'\n    asctime_search = '%(asctime)'\n    validation_pattern = re.compile(r'%\\(\\w+\\)[#0+ -]*(\\*|\\d+)?(\\.(\\*|\\d+))?[diouxefgcrsa%]', re.I)\n\n    def __init__(self, fmt):\n        self._fmt = fmt or self.default_format\n\n    def usesTime(self):\n        return self._fmt.find(self.asctime_search) >= 0\n\n    def validate(self):\n        \"\"\"Validate the input format, ensure it matches the correct style\"\"\"\n        if not self.validation_pattern.search(self._fmt):\n            raise ValueError(\"Invalid format '%s' for '%s' style\" % (self._fmt, self.default_format[0]))\n\n    def _format(self, record):\n        return self._fmt % record.__dict__\n\n    def format(self, record):\n        try:\n            return self._format(record)\n        except KeyError as e:\n            raise ValueError('Formatting field not found in record: %s' % e)\n\n\nclass StrFormatStyle(PercentStyle):\n    default_format = '{message}'\n    asctime_format = '{asctime}'\n    asctime_search = '{asctime'\n\n    fmt_spec = re.compile(r'^(.?[<>=^])?[+ -]?#?0?(\\d+|{\\w+})?[,_]?(\\.(\\d+|{\\w+}))?[bcdefgnosx%]?$', re.I)\n    field_spec = re.compile(r'^(\\d+|\\w+)(\\.\\w+|\\[[^]]+\\])*$')\n\n    def _format(self, record):\n        return self._fmt.format(**record.__dict__)\n\n    def validate(self):\n        \"\"\"Validate the input format, ensure it is the correct string formatting style\"\"\"\n        fields = set()\n        try:\n            for _, fieldname, spec, conversion in _str_formatter.parse(self._fmt):\n                if fieldname:\n                    if not self.field_spec.match(fieldname):\n                        raise ValueError('invalid field name/expression: %r' % fieldname)\n                    fields.add(fieldname)\n                if conversion and conversion not in 'rsa':\n                    raise ValueError('invalid conversion: %r' % conversion)\n                if spec and not self.fmt_spec.match(spec):\n                    raise ValueError('bad specifier: %r' % spec)\n        except ValueError as e:\n            raise ValueError('invalid format: %s' % e)\n        if not fields:\n            raise ValueError('invalid format: no fields')\n\n\nclass StringTemplateStyle(PercentStyle):\n    default_format = '${message}'\n    asctime_format = '${asctime}'\n    asctime_search = '${asctime}'\n\n    def __init__(self, fmt):\n        self._fmt = fmt or self.default_format\n        self._tpl = Template(self._fmt)\n\n    def usesTime(self):\n        fmt = self._fmt\n        return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_format) >= 0\n\n    def validate(self):\n        pattern = Template.pattern\n        fields = set()\n        for m in pattern.finditer(self._fmt):\n            d = m.groupdict()\n            if d['named']:\n                fields.add(d['named'])\n            elif d['braced']:\n                fields.add(d['braced'])\n            elif m.group(0) == '$':\n                raise ValueError('invalid format: bare \\'$\\' not allowed')\n        if not fields:\n            raise ValueError('invalid format: no fields')\n\n    def _format(self, record):\n        return self._tpl.substitute(**record.__dict__)\n\n\nBASIC_FORMAT = \"%(levelname)s:%(name)s:%(message)s\"\n\n_STYLES = {\n    '%': (PercentStyle, BASIC_FORMAT),\n    '{': (StrFormatStyle, '{levelname}:{name}:{message}'),\n    '$': (StringTemplateStyle, '${levelname}:${name}:${message}'),\n}\n\nclass Formatter(object):\n    \"\"\"\n    Formatter instances are used to convert a LogRecord to text.\n\n    Formatters need to know how a LogRecord is constructed. They are\n    responsible for converting a LogRecord to (usually) a string which can\n    be interpreted by either a human or an external system. The base Formatter\n    allows a formatting string to be specified. If none is supplied, the\n    style-dependent default value, \"%(message)s\", \"{message}\", or\n    \"${message}\", is used.\n\n    The Formatter can be initialized with a format string which makes use of\n    knowledge of the LogRecord attributes - e.g. the default value mentioned\n    above makes use of the fact that the user's message and arguments are pre-\n    formatted into a LogRecord's message attribute. Currently, the useful\n    attributes in a LogRecord are described by:\n\n    %(name)s            Name of the logger (logging channel)\n    %(levelno)s         Numeric logging level for the message (DEBUG, INFO,\n                        WARNING, ERROR, CRITICAL)\n    %(levelname)s       Text logging level for the message (\"DEBUG\", \"INFO\",\n                        \"WARNING\", \"ERROR\", \"CRITICAL\")\n    %(pathname)s        Full pathname of the source file where the logging\n                        call was issued (if available)\n    %(filename)s        Filename portion of pathname\n    %(module)s          Module (name portion of filename)\n    %(lineno)d          Source line number where the logging call was issued\n                        (if available)\n    %(funcName)s        Function name\n    %(created)f         Time when the LogRecord was created (time.time()\n                        return value)\n    %(asctime)s         Textual time when the LogRecord was created\n    %(msecs)d           Millisecond portion of the creation time\n    %(relativeCreated)d Time in milliseconds when the LogRecord was created,\n                        relative to the time the logging module was loaded\n                        (typically at application startup time)\n    %(thread)d          Thread ID (if available)\n    %(threadName)s      Thread name (if available)\n    %(process)d         Process ID (if available)\n    %(message)s         The result of record.getMessage(), computed just as\n                        the record is emitted\n    \"\"\"\n\n    converter = time.localtime\n\n    def __init__(self, fmt=None, datefmt=None, style='%', validate=True):\n        \"\"\"\n        Initialize the formatter with specified format strings.\n\n        Initialize the formatter either with the specified format string, or a\n        default as described above. Allow for specialized date formatting with\n        the optional datefmt argument. If datefmt is omitted, you get an\n        ISO8601-like (or RFC 3339-like) format.\n\n        Use a style parameter of '%', '{' or '$' to specify that you want to\n        use one of %-formatting, :meth:`str.format` (``{}``) formatting or\n        :class:`string.Template` formatting in your format string.\n\n        .. versionchanged:: 3.2\n           Added the ``style`` parameter.\n        \"\"\"\n        if style not in _STYLES:\n            raise ValueError('Style must be one of: %s' % ','.join(\n                             _STYLES.keys()))\n        self._style = _STYLES[style][0](fmt)\n        if validate:\n            self._style.validate()\n\n        self._fmt = self._style._fmt\n        self.datefmt = datefmt\n\n    default_time_format = '%Y-%m-%d %H:%M:%S'\n    default_msec_format = '%s,%03d'\n\n    def formatTime(self, record, datefmt=None):\n        \"\"\"\n        Return the creation time of the specified LogRecord as formatted text.\n\n        This method should be called from format() by a formatter which\n        wants to make use of a formatted time. This method can be overridden\n        in formatters to provide for any specific requirement, but the\n        basic behaviour is as follows: if datefmt (a string) is specified,\n        it is used with time.strftime() to format the creation time of the\n        record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used.\n        The resulting string is returned. This function uses a user-configurable\n        function to convert the creation time to a tuple. By default,\n        time.localtime() is used; to change this for a particular formatter\n        instance, set the 'converter' attribute to a function with the same\n        signature as time.localtime() or time.gmtime(). To change it for all\n        formatters, for example if you want all logging times to be shown in GMT,\n        set the 'converter' attribute in the Formatter class.\n        \"\"\"\n        ct = self.converter(record.created)\n        if datefmt:\n            s = time.strftime(datefmt, ct)\n        else:\n            t = time.strftime(self.default_time_format, ct)\n            s = self.default_msec_format % (t, record.msecs)\n        return s\n\n    def formatException(self, ei):\n        \"\"\"\n        Format and return the specified exception information as a string.\n\n        This default implementation just uses\n        traceback.print_exception()\n        \"\"\"\n        sio = io.StringIO()\n        tb = ei[2]\n        # See issues #9427, #1553375. Commented out for now.\n        #if getattr(self, 'fullstack', False):\n        #    traceback.print_stack(tb.tb_frame.f_back, file=sio)\n        traceback.print_exception(ei[0], ei[1], tb, None, sio)\n        s = sio.getvalue()\n        sio.close()\n        if s[-1:] == \"\\n\":\n            s = s[:-1]\n        return s\n\n    def usesTime(self):\n        \"\"\"\n        Check if the format uses the creation time of the record.\n        \"\"\"\n        return self._style.usesTime()\n\n    def formatMessage(self, record):\n        return self._style.format(record)\n\n    def formatStack(self, stack_info):\n        \"\"\"\n        This method is provided as an extension point for specialized\n        formatting of stack information.\n\n        The input data is a string as returned from a call to\n        :func:`traceback.print_stack`, but with the last trailing newline\n        removed.\n\n        The base implementation just returns the value passed in.\n        \"\"\"\n        return stack_info\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record as text.\n\n        The record's attribute dictionary is used as the operand to a\n        string formatting operation which yields the returned string.\n        Before formatting the dictionary, a couple of preparatory steps\n        are carried out. The message attribute of the record is computed\n        using LogRecord.getMessage(). If the formatting string uses the\n        time (as determined by a call to usesTime(), formatTime() is\n        called to format the event time. If there is exception information,\n        it is formatted using formatException() and appended to the message.\n        \"\"\"\n        record.message = record.getMessage()\n        if self.usesTime():\n            record.asctime = self.formatTime(record, self.datefmt)\n        s = self.formatMessage(record)\n        if record.exc_info:\n            # Cache the traceback text to avoid converting it multiple times\n            # (it's constant anyway)\n            if not record.exc_text:\n                record.exc_text = self.formatException(record.exc_info)\n        if record.exc_text:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + record.exc_text\n        if record.stack_info:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + self.formatStack(record.stack_info)\n        return s\n\n#\n#   The default formatter to use when no other is specified\n#\n_defaultFormatter = Formatter()\n\nclass BufferingFormatter(object):\n    \"\"\"\n    A formatter suitable for formatting a number of records.\n    \"\"\"\n    def __init__(self, linefmt=None):\n        \"\"\"\n        Optionally specify a formatter which will be used to format each\n        individual record.\n        \"\"\"\n        if linefmt:\n            self.linefmt = linefmt\n        else:\n            self.linefmt = _defaultFormatter\n\n    def formatHeader(self, records):\n        \"\"\"\n        Return the header string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def formatFooter(self, records):\n        \"\"\"\n        Return the footer string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def format(self, records):\n        \"\"\"\n        Format the specified records and return the result as a string.\n        \"\"\"\n        rv = \"\"\n        if len(records) > 0:\n            rv = rv + self.formatHeader(records)\n            for record in records:\n                rv = rv + self.linefmt.format(record)\n            rv = rv + self.formatFooter(records)\n        return rv\n\n#---------------------------------------------------------------------------\n#   Filter classes and functions\n#---------------------------------------------------------------------------\n\nclass Filter(object):\n    \"\"\"\n    Filter instances are used to perform arbitrary filtering of LogRecords.\n\n    Loggers and Handlers can optionally use Filter instances to filter\n    records as desired. The base filter class only allows events which are\n    below a certain point in the logger hierarchy. For example, a filter\n    initialized with \"A.B\" will allow events logged by loggers \"A.B\",\n    \"A.B.C\", \"A.B.C.D\", \"A.B.D\" etc. but not \"A.BB\", \"B.A.B\" etc. If\n    initialized with the empty string, all events are passed.\n    \"\"\"\n    def __init__(self, name=''):\n        \"\"\"\n        Initialize a filter.\n\n        Initialize with the name of the logger which, together with its\n        children, will have its events allowed through the filter. If no\n        name is specified, allow every event.\n        \"\"\"\n        self.name = name\n        self.nlen = len(name)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if the specified record is to be logged.\n\n        Returns True if the record should be logged, or False otherwise.\n        If deemed appropriate, the record may be modified in-place.\n        \"\"\"\n        if self.nlen == 0:\n            return True\n        elif self.name == record.name:\n            return True\n        elif record.name.find(self.name, 0, self.nlen) != 0:\n            return False\n        return (record.name[self.nlen] == \".\")\n\nclass Filterer(object):\n    \"\"\"\n    A base class for loggers and handlers which allows them to share\n    common code.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialize the list of filters to be an empty list.\n        \"\"\"\n        self.filters = []\n\n    def addFilter(self, filter):\n        \"\"\"\n        Add the specified filter to this handler.\n        \"\"\"\n        if not (filter in self.filters):\n            self.filters.append(filter)\n\n    def removeFilter(self, filter):\n        \"\"\"\n        Remove the specified filter from this handler.\n        \"\"\"\n        if filter in self.filters:\n            self.filters.remove(filter)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if a record is loggable by consulting all the filters.\n\n        The default is to allow the record to be logged; any filter can veto\n        this and the record is then dropped. Returns a zero value if a record\n        is to be dropped, else non-zero.\n\n        .. versionchanged:: 3.2\n\n           Allow filters to be just callables.\n        \"\"\"\n        rv = True\n        for f in self.filters:\n            if hasattr(f, 'filter'):\n                result = f.filter(record)\n            else:\n                result = f(record) # assume callable - will raise if not\n            if not result:\n                rv = False\n                break\n        return rv\n\n#---------------------------------------------------------------------------\n#   Handler classes and functions\n#---------------------------------------------------------------------------\n\n_handlers = weakref.WeakValueDictionary()  #map of handler names to handlers\n_handlerList = [] # added to allow handlers to be removed in reverse of order initialized\n\ndef _removeHandlerRef(wr):\n    \"\"\"\n    Remove a handler reference from the internal cleanup list.\n    \"\"\"\n    # This function can be called during module teardown, when globals are\n    # set to None. It can also be called from another thread. So we need to\n    # pre-emptively grab the necessary globals and check if they're None,\n    # to prevent race conditions and failures during interpreter shutdown.\n    acquire, release, handlers = _acquireLock, _releaseLock, _handlerList\n    if acquire and release and handlers:\n        acquire()\n        try:\n            if wr in handlers:\n                handlers.remove(wr)\n        finally:\n            release()\n\ndef _addHandlerRef(handler):\n    \"\"\"\n    Add a handler to the internal cleanup list using a weak reference.\n    \"\"\"\n    _acquireLock()\n    try:\n        _handlerList.append(weakref.ref(handler, _removeHandlerRef))\n    finally:\n        _releaseLock()\n\nclass Handler(Filterer):\n    \"\"\"\n    Handler instances dispatch logging events to specific destinations.\n\n    The base handler class. Acts as a placeholder which defines the Handler\n    interface. Handlers can optionally use Formatter instances to format\n    records as desired. By default, no formatter is specified; in this case,\n    the 'raw' message as determined by record.message is logged.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initializes the instance - basically setting the formatter to None\n        and the filter list to empty.\n        \"\"\"\n        Filterer.__init__(self)\n        self._name = None\n        self.level = _checkLevel(level)\n        self.formatter = None\n        # Add the handler to the global _handlerList (for cleanup on shutdown)\n        _addHandlerRef(self)\n        self.createLock()\n\n    def get_name(self):\n        return self._name\n\n    def set_name(self, name):\n        _acquireLock()\n        try:\n            if self._name in _handlers:\n                del _handlers[self._name]\n            self._name = name\n            if name:\n                _handlers[name] = self\n        finally:\n            _releaseLock()\n\n    name = property(get_name, set_name)\n\n    def createLock(self):\n        \"\"\"\n        Acquire a thread lock for serializing access to the underlying I/O.\n        \"\"\"\n        self.lock = threading.RLock()\n        _register_at_fork_reinit_lock(self)\n\n    def acquire(self):\n        \"\"\"\n        Acquire the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.acquire()\n\n    def release(self):\n        \"\"\"\n        Release the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.release()\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this handler.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record.\n\n        If a formatter is set, use it. Otherwise, use the default formatter\n        for the module.\n        \"\"\"\n        if self.formatter:\n            fmt = self.formatter\n        else:\n            fmt = _defaultFormatter\n        return fmt.format(record)\n\n    def emit(self, record):\n        \"\"\"\n        Do whatever it takes to actually log the specified logging record.\n\n        This version is intended to be implemented by subclasses and so\n        raises a NotImplementedError.\n        \"\"\"\n        raise NotImplementedError('emit must be implemented '\n                                  'by Handler subclasses')\n\n    def handle(self, record):\n        \"\"\"\n        Conditionally emit the specified logging record.\n\n        Emission depends on filters which may have been added to the handler.\n        Wrap the actual emission of the record with acquisition/release of\n        the I/O thread lock. Returns whether the filter passed the record for\n        emission.\n        \"\"\"\n        rv = self.filter(record)\n        if rv:\n            self.acquire()\n            try:\n                self.emit(record)\n            finally:\n                self.release()\n        return rv\n\n    def setFormatter(self, fmt):\n        \"\"\"\n        Set the formatter for this handler.\n        \"\"\"\n        self.formatter = fmt\n\n    def flush(self):\n        \"\"\"\n        Ensure all logging output has been flushed.\n\n        This version does nothing and is intended to be implemented by\n        subclasses.\n        \"\"\"\n        pass\n\n    def close(self):\n        \"\"\"\n        Tidy up any resources used by the handler.\n\n        This version removes the handler from an internal map of handlers,\n        _handlers, which is used for handler lookup by name. Subclasses\n        should ensure that this gets called from overridden close()\n        methods.\n        \"\"\"\n        #get the module data lock, as we're updating a shared structure.\n        _acquireLock()\n        try:    #unlikely to raise an exception, but you never know...\n            if self._name and self._name in _handlers:\n                del _handlers[self._name]\n        finally:\n            _releaseLock()\n\n    def handleError(self, record):\n        \"\"\"\n        Handle errors which occur during an emit() call.\n\n        This method should be called from handlers when an exception is\n        encountered during an emit() call. If raiseExceptions is false,\n        exceptions get silently ignored. This is what is mostly wanted\n        for a logging system - most users will not care about errors in\n        the logging system, they are more interested in application errors.\n        You could, however, replace this with a custom handler if you wish.\n        The record which was being processed is passed in to this method.\n        \"\"\"\n        if raiseExceptions and sys.stderr:  # see issue 13807\n            t, v, tb = sys.exc_info()\n            try:\n                sys.stderr.write('--- Logging error ---\\n')\n                traceback.print_exception(t, v, tb, None, sys.stderr)\n                sys.stderr.write('Call stack:\\n')\n                # Walk the stack frame up until we're out of logging,\n                # so as to print the calling context.\n                frame = tb.tb_frame\n                while (frame and os.path.dirname(frame.f_code.co_filename) ==\n                       __path__[0]):\n                    frame = frame.f_back\n                if frame:\n                    traceback.print_stack(frame, file=sys.stderr)\n                else:\n                    # couldn't find the right stack frame, for some reason\n                    sys.stderr.write('Logged from file %s, line %s\\n' % (\n                                     record.filename, record.lineno))\n                # Issue 18671: output logging message and arguments\n                try:\n                    sys.stderr.write('Message: %r\\n'\n                                     'Arguments: %s\\n' % (record.msg,\n                                                          record.args))\n                except RecursionError:  # See issue 36272\n                    raise\n                except Exception:\n                    sys.stderr.write('Unable to print the message and arguments'\n                                     ' - possible formatting error.\\nUse the'\n                                     ' traceback above to help find the error.\\n'\n                                    )\n            except OSError: #pragma: no cover\n                pass    # see issue 5971\n            finally:\n                del t, v, tb\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        return '<%s (%s)>' % (self.__class__.__name__, level)\n\nclass StreamHandler(Handler):\n    \"\"\"\n    A handler class which writes logging records, appropriately formatted,\n    to a stream. Note that this class does not close the stream, as\n    sys.stdout or sys.stderr may be used.\n    \"\"\"\n\n    terminator = '\\n'\n\n    def __init__(self, stream=None):\n        \"\"\"\n        Initialize the handler.\n\n        If stream is not specified, sys.stderr is used.\n        \"\"\"\n        Handler.__init__(self)\n        if stream is None:\n            stream = sys.stderr\n        self.stream = stream\n\n    def flush(self):\n        \"\"\"\n        Flushes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.stream and hasattr(self.stream, \"flush\"):\n                self.stream.flush()\n        finally:\n            self.release()\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If a formatter is specified, it is used to format the record.\n        The record is then written to the stream with a trailing newline.  If\n        exception information is present, it is formatted using\n        traceback.print_exception and appended to the stream.  If the stream\n        has an 'encoding' attribute, it is used to determine how to do the\n        output to the stream.\n        \"\"\"\n        try:\n            msg = self.format(record)\n            stream = self.stream\n            # issue 35046: merged two stream.writes into one.\n            stream.write(msg + self.terminator)\n            self.flush()\n        except RecursionError:  # See issue 36272\n            raise\n        except Exception:\n            self.handleError(record)\n\n    def setStream(self, stream):\n        \"\"\"\n        Sets the StreamHandler's stream to the specified value,\n        if it is different.\n\n        Returns the old stream, if the stream was changed, or None\n        if it wasn't.\n        \"\"\"\n        if stream is self.stream:\n            result = None\n        else:\n            result = self.stream\n            self.acquire()\n            try:\n                self.flush()\n                self.stream = stream\n            finally:\n                self.release()\n        return result\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        name = getattr(self.stream, 'name', '')\n        #  bpo-36015: name can be an int\n        name = str(name)\n        if name:\n            name += ' '\n        return '<%s %s(%s)>' % (self.__class__.__name__, name, level)\n\n\nclass FileHandler(StreamHandler):\n    \"\"\"\n    A handler class which writes formatted logging records to disk files.\n    \"\"\"\n    def __init__(self, filename, mode='a', encoding=None, delay=False):\n        \"\"\"\n        Open the specified file and use it as the stream for logging.\n        \"\"\"\n        # Issue #27493: add support for Path objects to be passed in\n        filename = os.fspath(filename)\n        #keep the absolute path, otherwise derived classes which use this\n        #may come a cropper when the current directory changes\n        self.baseFilename = os.path.abspath(filename)\n        self.mode = mode\n        self.encoding = encoding\n        self.delay = delay\n        if delay:\n            #We don't open the stream, but we still need to call the\n            #Handler constructor to set level, formatter, lock etc.\n            Handler.__init__(self)\n            self.stream = None\n        else:\n            StreamHandler.__init__(self, self._open())\n\n    def close(self):\n        \"\"\"\n        Closes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            try:\n                if self.stream:\n                    try:\n                        self.flush()\n                    finally:\n                        stream = self.stream\n                        self.stream = None\n                        if hasattr(stream, \"close\"):\n                            stream.close()\n            finally:\n                # Issue #19523: call unconditionally to\n                # prevent a handler leak when delay is set\n                StreamHandler.close(self)\n        finally:\n            self.release()\n\n    def _open(self):\n        \"\"\"\n        Open the current base file with the (original) mode and encoding.\n        Return the resulting stream.\n        \"\"\"\n        return open(self.baseFilename, self.mode, encoding=self.encoding)\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If the stream was not opened because 'delay' was specified in the\n        constructor, open it before calling the superclass's emit.\n        \"\"\"\n        if self.stream is None:\n            self.stream = self._open()\n        StreamHandler.emit(self, record)\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        return '<%s %s (%s)>' % (self.__class__.__name__, self.baseFilename, level)\n\n\nclass _StderrHandler(StreamHandler):\n    \"\"\"\n    This class is like a StreamHandler using sys.stderr, but always uses\n    whatever sys.stderr is currently set to rather than the value of\n    sys.stderr at handler construction time.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initialize the handler.\n        \"\"\"\n        Handler.__init__(self, level)\n\n    @property\n    def stream(self):\n        return sys.stderr\n\n\n_defaultLastResort = _StderrHandler(WARNING)\nlastResort = _defaultLastResort\n\n#---------------------------------------------------------------------------\n#   Manager classes and functions\n#---------------------------------------------------------------------------\n\nclass PlaceHolder(object):\n    \"\"\"\n    PlaceHolder instances are used in the Manager logger hierarchy to take\n    the place of nodes for which no loggers have been defined. This class is\n    intended for internal use only and not as part of the public API.\n    \"\"\"\n    def __init__(self, alogger):\n        \"\"\"\n        Initialize with the specified logger being a child of this placeholder.\n        \"\"\"\n        self.loggerMap = { alogger : None }\n\n    def append(self, alogger):\n        \"\"\"\n        Add the specified logger as a child of this placeholder.\n        \"\"\"\n        if alogger not in self.loggerMap:\n            self.loggerMap[alogger] = None\n\n#\n#   Determine which class to use when instantiating loggers.\n#\n\ndef setLoggerClass(klass):\n    \"\"\"\n    Set the class to be used when instantiating a logger. The class should\n    define __init__() such that only a name argument is required, and the\n    __init__() should call Logger.__init__()\n    \"\"\"\n    if klass != Logger:\n        if not issubclass(klass, Logger):\n            raise TypeError(\"logger not derived from logging.Logger: \"\n                            + klass.__name__)\n    global _loggerClass\n    _loggerClass = klass\n\ndef getLoggerClass():\n    \"\"\"\n    Return the class to be used when instantiating a logger.\n    \"\"\"\n    return _loggerClass\n\nclass Manager(object):\n    \"\"\"\n    There is [under normal circumstances] just one Manager instance, which\n    holds the hierarchy of loggers.\n    \"\"\"\n    def __init__(self, rootnode):\n        \"\"\"\n        Initialize the manager with the root node of the logger hierarchy.\n        \"\"\"\n        self.root = rootnode\n        self.disable = 0\n        self.emittedNoHandlerWarning = False\n        self.loggerDict = {}\n        self.loggerClass = None\n        self.logRecordFactory = None\n\n    @property\n    def disable(self):\n        return self._disable\n\n    @disable.setter\n    def disable(self, value):\n        self._disable = _checkLevel(value)\n\n    def getLogger(self, name):\n        \"\"\"\n        Get a logger with the specified name (channel name), creating it\n        if it doesn't yet exist. This name is a dot-separated hierarchical\n        name, such as \"a\", \"a.b\", \"a.b.c\" or similar.\n\n        If a PlaceHolder existed for the specified name [i.e. the logger\n        didn't exist but a child of it did], replace it with the created\n        logger and fix up the parent/child references which pointed to the\n        placeholder to now point to the logger.\n        \"\"\"\n        rv = None\n        if not isinstance(name, str):\n            raise TypeError('A logger name must be a string')\n        _acquireLock()\n        try:\n            if name in self.loggerDict:\n                rv = self.loggerDict[name]\n                if isinstance(rv, PlaceHolder):\n                    ph = rv\n                    rv = (self.loggerClass or _loggerClass)(name)\n                    rv.manager = self\n                    self.loggerDict[name] = rv\n                    self._fixupChildren(ph, rv)\n                    self._fixupParents(rv)\n            else:\n                rv = (self.loggerClass or _loggerClass)(name)\n                rv.manager = self\n                self.loggerDict[name] = rv\n                self._fixupParents(rv)\n        finally:\n            _releaseLock()\n        return rv\n\n    def setLoggerClass(self, klass):\n        \"\"\"\n        Set the class to be used when instantiating a logger with this Manager.\n        \"\"\"\n        if klass != Logger:\n            if not issubclass(klass, Logger):\n                raise TypeError(\"logger not derived from logging.Logger: \"\n                                + klass.__name__)\n        self.loggerClass = klass\n\n    def setLogRecordFactory(self, factory):\n        \"\"\"\n        Set the factory to be used when instantiating a log record with this\n        Manager.\n        \"\"\"\n        self.logRecordFactory = factory\n\n    def _fixupParents(self, alogger):\n        \"\"\"\n        Ensure that there are either loggers or placeholders all the way\n        from the specified logger to the root of the logger hierarchy.\n        \"\"\"\n        name = alogger.name\n        i = name.rfind(\".\")\n        rv = None\n        while (i > 0) and not rv:\n            substr = name[:i]\n            if substr not in self.loggerDict:\n                self.loggerDict[substr] = PlaceHolder(alogger)\n            else:\n                obj = self.loggerDict[substr]\n                if isinstance(obj, Logger):\n                    rv = obj\n                else:\n                    assert isinstance(obj, PlaceHolder)\n                    obj.append(alogger)\n            i = name.rfind(\".\", 0, i - 1)\n        if not rv:\n            rv = self.root\n        alogger.parent = rv\n\n    def _fixupChildren(self, ph, alogger):\n        \"\"\"\n        Ensure that children of the placeholder ph are connected to the\n        specified logger.\n        \"\"\"\n        name = alogger.name\n        namelen = len(name)\n        for c in ph.loggerMap.keys():\n            #The if means ... if not c.parent.name.startswith(nm)\n            if c.parent.name[:namelen] != name:\n                alogger.parent = c.parent\n                c.parent = alogger\n\n    def _clear_cache(self):\n        \"\"\"\n        Clear the cache for all loggers in loggerDict\n        Called when level changes are made\n        \"\"\"\n\n        _acquireLock()\n        for logger in self.loggerDict.values():\n            if isinstance(logger, Logger):\n                logger._cache.clear()\n        self.root._cache.clear()\n        _releaseLock()\n\n#---------------------------------------------------------------------------\n#   Logger classes and functions\n#---------------------------------------------------------------------------\n\nclass Logger(Filterer):\n    \"\"\"\n    Instances of the Logger class represent a single logging channel. A\n    \"logging channel\" indicates an area of an application. Exactly how an\n    \"area\" is defined is up to the application developer. Since an\n    application can have any number of areas, logging channels are identified\n    by a unique string. Application areas can be nested (e.g. an area\n    of \"input processing\" might include sub-areas \"read CSV files\", \"read\n    XLS files\" and \"read Gnumeric files\"). To cater for this natural nesting,\n    channel names are organized into a namespace hierarchy where levels are\n    separated by periods, much like the Java or Python package namespace. So\n    in the instance given above, channel names might be \"input\" for the upper\n    level, and \"input.csv\", \"input.xls\" and \"input.gnu\" for the sub-levels.\n    There is no arbitrary limit to the depth of nesting.\n    \"\"\"\n    def __init__(self, name, level=NOTSET):\n        \"\"\"\n        Initialize the logger with a name and an optional level.\n        \"\"\"\n        Filterer.__init__(self)\n        self.name = name\n        self.level = _checkLevel(level)\n        self.parent = None\n        self.propagate = True\n        self.handlers = []\n        self.disabled = False\n        self._cache = {}\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this logger.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n        self.manager._clear_cache()\n\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'DEBUG'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(DEBUG):\n            self._log(DEBUG, msg, args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'INFO'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(INFO):\n            self._log(INFO, msg, args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'WARNING'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.warning(\"Houston, we have a %s\", \"bit of a problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(WARNING):\n            self._log(WARNING, msg, args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'ERROR'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.error(\"Houston, we have a %s\", \"major problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(ERROR):\n            self._log(ERROR, msg, args, **kwargs)\n\n    def exception(self, msg, *args, exc_info=True, **kwargs):\n        \"\"\"\n        Convenience method for logging an ERROR with exception information.\n        \"\"\"\n        self.error(msg, *args, exc_info=exc_info, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'CRITICAL'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.critical(\"Houston, we have a %s\", \"major disaster\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(CRITICAL):\n            self._log(CRITICAL, msg, args, **kwargs)\n\n    fatal = critical\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with the integer severity 'level'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)\n        \"\"\"\n        if not isinstance(level, int):\n            if raiseExceptions:\n                raise TypeError(\"level must be an integer\")\n            else:\n                return\n        if self.isEnabledFor(level):\n            self._log(level, msg, args, **kwargs)\n\n    def findCaller(self, stack_info=False, stacklevel=1):\n        \"\"\"\n        Find the stack frame of the caller so that we can note the source\n        file name, line number and function name.\n        \"\"\"\n        f = currentframe()\n        #On some versions of IronPython, currentframe() returns None if\n        #IronPython isn't run with -X:Frames.\n        if f is not None:\n            f = f.f_back\n        orig_f = f\n        while f and stacklevel > 1:\n            f = f.f_back\n            stacklevel -= 1\n        if not f:\n            f = orig_f\n        rv = \"(unknown file)\", 0, \"(unknown function)\", None\n        while hasattr(f, \"f_code\"):\n            co = f.f_code\n            filename = os.path.normcase(co.co_filename)\n            if filename == _srcfile:\n                f = f.f_back\n                continue\n            sinfo = None\n            if stack_info:\n                sio = io.StringIO()\n                sio.write('Stack (most recent call last):\\n')\n                traceback.print_stack(f, file=sio)\n                sinfo = sio.getvalue()\n                if sinfo[-1] == '\\n':\n                    sinfo = sinfo[:-1]\n                sio.close()\n            rv = (co.co_filename, f.f_lineno, co.co_name, sinfo)\n            break\n        return rv\n\n    def makeRecord(self, name, level, fn, lno, msg, args, exc_info,\n                   func=None, extra=None, sinfo=None):\n        \"\"\"\n        A factory method which can be overridden in subclasses to create\n        specialized LogRecords.\n        \"\"\"\n        rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n                             sinfo)\n        if extra is not None:\n            for key in extra:\n                if (key in [\"message\", \"asctime\"]) or (key in rv.__dict__):\n                    raise KeyError(\"Attempt to overwrite %r in LogRecord\" % key)\n                rv.__dict__[key] = extra[key]\n        return rv\n\n    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,\n             stacklevel=1):\n        \"\"\"\n        Low-level logging routine which creates a LogRecord and then calls\n        all the handlers of this logger to handle the record.\n        \"\"\"\n        sinfo = None\n        if _srcfile:\n            #IronPython doesn't track Python frames, so findCaller raises an\n            #exception on some versions of IronPython. We trap it here so that\n            #IronPython can use logging.\n            try:\n                fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)\n            except ValueError: # pragma: no cover\n                fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        else: # pragma: no cover\n            fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        if exc_info:\n            if isinstance(exc_info, BaseException):\n                exc_info = (type(exc_info), exc_info, exc_info.__traceback__)\n            elif not isinstance(exc_info, tuple):\n                exc_info = sys.exc_info()\n        record = self.makeRecord(self.name, level, fn, lno, msg, args,\n                                 exc_info, func, extra, sinfo)\n        self.handle(record)\n\n    def handle(self, record):\n        \"\"\"\n        Call the handlers for the specified record.\n\n        This method is used for unpickled records received from a socket, as\n        well as those created locally. Logger-level filtering is applied.\n        \"\"\"\n        if (not self.disabled) and self.filter(record):\n            self.callHandlers(record)\n\n    def addHandler(self, hdlr):\n        \"\"\"\n        Add the specified handler to this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if not (hdlr in self.handlers):\n                self.handlers.append(hdlr)\n        finally:\n            _releaseLock()\n\n    def removeHandler(self, hdlr):\n        \"\"\"\n        Remove the specified handler from this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if hdlr in self.handlers:\n                self.handlers.remove(hdlr)\n        finally:\n            _releaseLock()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if this logger has any handlers configured.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. Return True if a handler was found, else False.\n        Stop searching up the hierarchy whenever a logger with the \"propagate\"\n        attribute set to zero is found - that will be the last logger which\n        is checked for the existence of handlers.\n        \"\"\"\n        c = self\n        rv = False\n        while c:\n            if c.handlers:\n                rv = True\n                break\n            if not c.propagate:\n                break\n            else:\n                c = c.parent\n        return rv\n\n    def callHandlers(self, record):\n        \"\"\"\n        Pass a record to all relevant handlers.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. If no handler was found, output a one-off error\n        message to sys.stderr. Stop searching up the hierarchy whenever a\n        logger with the \"propagate\" attribute set to zero is found - that\n        will be the last logger whose handlers are called.\n        \"\"\"\n        c = self\n        found = 0\n        while c:\n            for hdlr in c.handlers:\n                found = found + 1\n                if record.levelno >= hdlr.level:\n                    hdlr.handle(record)\n            if not c.propagate:\n                c = None    #break out\n            else:\n                c = c.parent\n        if (found == 0):\n            if lastResort:\n                if record.levelno >= lastResort.level:\n                    lastResort.handle(record)\n            elif raiseExceptions and not self.manager.emittedNoHandlerWarning:\n                sys.stderr.write(\"No handlers could be found for logger\"\n                                 \" \\\"%s\\\"\\n\" % self.name)\n                self.manager.emittedNoHandlerWarning = True\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for this logger.\n\n        Loop through this logger and its parents in the logger hierarchy,\n        looking for a non-zero logging level. Return the first one found.\n        \"\"\"\n        logger = self\n        while logger:\n            if logger.level:\n                return logger.level\n            logger = logger.parent\n        return NOTSET\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        if self.disabled:\n            return False\n\n        try:\n            return self._cache[level]\n        except KeyError:\n            _acquireLock()\n            try:\n                if self.manager.disable >= level:\n                    is_enabled = self._cache[level] = False\n                else:\n                    is_enabled = self._cache[level] = (\n                        level >= self.getEffectiveLevel()\n                    )\n            finally:\n                _releaseLock()\n            return is_enabled\n\n    def getChild(self, suffix):\n        \"\"\"\n        Get a logger which is a descendant to this one.\n\n        This is a convenience method, such that\n\n        logging.getLogger('abc').getChild('def.ghi')\n\n        is the same as\n\n        logging.getLogger('abc.def.ghi')\n\n        It's useful, for example, when the parent logger is named using\n        __name__ rather than a literal string.\n        \"\"\"\n        if self.root is not self:\n            suffix = '.'.join((self.name, suffix))\n        return self.manager.getLogger(suffix)\n\n    def __repr__(self):\n        level = getLevelName(self.getEffectiveLevel())\n        return '<%s %s (%s)>' % (self.__class__.__name__, self.name, level)\n\n    def __reduce__(self):\n        # In general, only the root logger will not be accessible via its name.\n        # However, the root logger's class has its own __reduce__ method.\n        if getLogger(self.name) is not self:\n            import pickle\n            raise pickle.PicklingError('logger cannot be pickled')\n        return getLogger, (self.name,)\n\n\nclass RootLogger(Logger):\n    \"\"\"\n    A root logger is not that different to any other logger, except that\n    it must have a logging level and there is only one instance of it in\n    the hierarchy.\n    \"\"\"\n    def __init__(self, level):\n        \"\"\"\n        Initialize the logger with the name \"root\".\n        \"\"\"\n        Logger.__init__(self, \"root\", level)\n\n    def __reduce__(self):\n        return getLogger, ()\n\n_loggerClass = Logger\n\nclass LoggerAdapter(object):\n    \"\"\"\n    An adapter for loggers which makes it easier to specify contextual\n    information in logging output.\n    \"\"\"\n\n    def __init__(self, logger, extra):\n        \"\"\"\n        Initialize the adapter with a logger and a dict-like object which\n        provides contextual information. This constructor signature allows\n        easy stacking of LoggerAdapters, if so desired.\n\n        You can effectively pass keyword arguments as shown in the\n        following example:\n\n        adapter = LoggerAdapter(someLogger, dict(p1=v1, p2=\"v2\"))\n        \"\"\"\n        self.logger = logger\n        self.extra = extra\n\n    def process(self, msg, kwargs):\n        \"\"\"\n        Process the logging message and keyword arguments passed in to\n        a logging call to insert contextual information. You can either\n        manipulate the message itself, the keyword args or both. Return\n        the message and kwargs modified (or not) to suit your needs.\n\n        Normally, you'll only need to override this one method in a\n        LoggerAdapter subclass for your specific needs.\n        \"\"\"\n        kwargs[\"extra\"] = self.extra\n        return msg, kwargs\n\n    #\n    # Boilerplate convenience methods\n    #\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a debug call to the underlying logger.\n        \"\"\"\n        self.log(DEBUG, msg, *args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an info call to the underlying logger.\n        \"\"\"\n        self.log(INFO, msg, *args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a warning call to the underlying logger.\n        \"\"\"\n        self.log(WARNING, msg, *args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an error call to the underlying logger.\n        \"\"\"\n        self.log(ERROR, msg, *args, **kwargs)\n\n    def exception(self, msg, *args, exc_info=True, **kwargs):\n        \"\"\"\n        Delegate an exception call to the underlying logger.\n        \"\"\"\n        self.log(ERROR, msg, *args, exc_info=exc_info, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a critical call to the underlying logger.\n        \"\"\"\n        self.log(CRITICAL, msg, *args, **kwargs)\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a log call to the underlying logger, after adding\n        contextual information from this adapter instance.\n        \"\"\"\n        if self.isEnabledFor(level):\n            msg, kwargs = self.process(msg, kwargs)\n            self.logger.log(level, msg, *args, **kwargs)\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        return self.logger.isEnabledFor(level)\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the specified level on the underlying logger.\n        \"\"\"\n        self.logger.setLevel(level)\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for the underlying logger.\n        \"\"\"\n        return self.logger.getEffectiveLevel()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if the underlying logger has any handlers.\n        \"\"\"\n        return self.logger.hasHandlers()\n\n    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):\n        \"\"\"\n        Low-level log implementation, proxied to allow nested logger adapters.\n        \"\"\"\n        return self.logger._log(\n            level,\n            msg,\n            args,\n            exc_info=exc_info,\n            extra=extra,\n            stack_info=stack_info,\n        )\n\n    @property\n    def manager(self):\n        return self.logger.manager\n\n    @manager.setter\n    def manager(self, value):\n        self.logger.manager = value\n\n    @property\n    def name(self):\n        return self.logger.name\n\n    def __repr__(self):\n        logger = self.logger\n        level = getLevelName(logger.getEffectiveLevel())\n        return '<%s %s (%s)>' % (self.__class__.__name__, logger.name, level)\n\nroot = RootLogger(WARNING)\nLogger.root = root\nLogger.manager = Manager(Logger.root)\n\n#---------------------------------------------------------------------------\n# Configuration classes and functions\n#---------------------------------------------------------------------------\n\ndef basicConfig(**kwargs):\n    \"\"\"\n    Do basic configuration for the logging system.\n\n    This function does nothing if the root logger already has handlers\n    configured, unless the keyword argument *force* is set to ``True``.\n    It is a convenience method intended for use by simple scripts\n    to do one-shot configuration of the logging package.\n\n    The default behaviour is to create a StreamHandler which writes to\n    sys.stderr, set a formatter using the BASIC_FORMAT format string, and\n    add the handler to the root logger.\n\n    A number of optional keyword arguments may be specified, which can alter\n    the default behaviour.\n\n    filename  Specifies that a FileHandler be created, using the specified\n              filename, rather than a StreamHandler.\n    filemode  Specifies the mode to open the file, if filename is specified\n              (if filemode is unspecified, it defaults to 'a').\n    format    Use the specified format string for the handler.\n    datefmt   Use the specified date/time format.\n    style     If a format string is specified, use this to specify the\n              type of format string (possible values '%', '{', '$', for\n              %-formatting, :meth:`str.format` and :class:`string.Template`\n              - defaults to '%').\n    level     Set the root logger level to the specified level.\n    stream    Use the specified stream to initialize the StreamHandler. Note\n              that this argument is incompatible with 'filename' - if both\n              are present, 'stream' is ignored.\n    handlers  If specified, this should be an iterable of already created\n              handlers, which will be added to the root handler. Any handler\n              in the list which does not have a formatter assigned will be\n              assigned the formatter created in this function.\n    force     If this keyword  is specified as true, any existing handlers\n              attached to the root logger are removed and closed, before\n              carrying out the configuration as specified by the other\n              arguments.\n    Note that you could specify a stream created using open(filename, mode)\n    rather than passing the filename and mode in. However, it should be\n    remembered that StreamHandler does not close its stream (since it may be\n    using sys.stdout or sys.stderr), whereas FileHandler closes its stream\n    when the handler is closed.\n\n    .. versionchanged:: 3.8\n       Added the ``force`` parameter.\n\n    .. versionchanged:: 3.2\n       Added the ``style`` parameter.\n\n    .. versionchanged:: 3.3\n       Added the ``handlers`` parameter. A ``ValueError`` is now thrown for\n       incompatible arguments (e.g. ``handlers`` specified together with\n       ``filename``/``filemode``, or ``filename``/``filemode`` specified\n       together with ``stream``, or ``handlers`` specified together with\n       ``stream``.\n    \"\"\"\n    # Add thread safety in case someone mistakenly calls\n    # basicConfig() from multiple threads\n    _acquireLock()\n    try:\n        force = kwargs.pop('force', False)\n        if force:\n            for h in root.handlers[:]:\n                root.removeHandler(h)\n                h.close()\n        if len(root.handlers) == 0:\n            handlers = kwargs.pop(\"handlers\", None)\n            if handlers is None:\n                if \"stream\" in kwargs and \"filename\" in kwargs:\n                    raise ValueError(\"'stream' and 'filename' should not be \"\n                                     \"specified together\")\n            else:\n                if \"stream\" in kwargs or \"filename\" in kwargs:\n                    raise ValueError(\"'stream' or 'filename' should not be \"\n                                     \"specified together with 'handlers'\")\n            if handlers is None:\n                filename = kwargs.pop(\"filename\", None)\n                mode = kwargs.pop(\"filemode\", 'a')\n                if filename:\n                    h = FileHandler(filename, mode)\n                else:\n                    stream = kwargs.pop(\"stream\", None)\n                    h = StreamHandler(stream)\n                handlers = [h]\n            dfs = kwargs.pop(\"datefmt\", None)\n            style = kwargs.pop(\"style\", '%')\n            if style not in _STYLES:\n                raise ValueError('Style must be one of: %s' % ','.join(\n                                 _STYLES.keys()))\n            fs = kwargs.pop(\"format\", _STYLES[style][1])\n            fmt = Formatter(fs, dfs, style)\n            for h in handlers:\n                if h.formatter is None:\n                    h.setFormatter(fmt)\n                root.addHandler(h)\n            level = kwargs.pop(\"level\", None)\n            if level is not None:\n                root.setLevel(level)\n            if kwargs:\n                keys = ', '.join(kwargs.keys())\n                raise ValueError('Unrecognised argument(s): %s' % keys)\n    finally:\n        _releaseLock()\n\n#---------------------------------------------------------------------------\n# Utility functions at module level.\n# Basically delegate everything to the root logger.\n#---------------------------------------------------------------------------\n\ndef getLogger(name=None):\n    \"\"\"\n    Return a logger with the specified name, creating it if necessary.\n\n    If no name is specified, return the root logger.\n    \"\"\"\n    if name:\n        return Logger.manager.getLogger(name)\n    else:\n        return root\n\ndef critical(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'CRITICAL' on the root logger. If the logger\n    has no handlers, call basicConfig() to add a console handler with a\n    pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.critical(msg, *args, **kwargs)\n\nfatal = critical\n\ndef error(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.error(msg, *args, **kwargs)\n\ndef exception(msg, *args, exc_info=True, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger, with exception\n    information. If the logger has no handlers, basicConfig() is called to add\n    a console handler with a pre-defined format.\n    \"\"\"\n    error(msg, *args, exc_info=exc_info, **kwargs)\n\ndef warning(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'WARNING' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.warning(msg, *args, **kwargs)\n\ndef warn(msg, *args, **kwargs):\n    warnings.warn(\"The 'warn' function is deprecated, \"\n        \"use 'warning' instead\", DeprecationWarning, 2)\n    warning(msg, *args, **kwargs)\n\ndef info(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'INFO' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.info(msg, *args, **kwargs)\n\ndef debug(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'DEBUG' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.debug(msg, *args, **kwargs)\n\ndef log(level, msg, *args, **kwargs):\n    \"\"\"\n    Log 'msg % args' with the integer severity 'level' on the root logger. If\n    the logger has no handlers, call basicConfig() to add a console handler\n    with a pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.log(level, msg, *args, **kwargs)\n\ndef disable(level=CRITICAL):\n    \"\"\"\n    Disable all logging calls of severity 'level' and below.\n    \"\"\"\n    root.manager.disable = level\n    root.manager._clear_cache()\n\ndef shutdown(handlerList=_handlerList):\n    \"\"\"\n    Perform any cleanup actions in the logging system (e.g. flushing\n    buffers).\n\n    Should be called at application exit.\n    \"\"\"\n    for wr in reversed(handlerList[:]):\n        #errors might occur, for example, if files are locked\n        #we just ignore them if raiseExceptions is not set\n        try:\n            h = wr()\n            if h:\n                try:\n                    h.acquire()\n                    h.flush()\n                    h.close()\n                except (OSError, ValueError):\n                    # Ignore errors which might be caused\n                    # because handlers have been closed but\n                    # references to them are still around at\n                    # application exit.\n                    pass\n                finally:\n                    h.release()\n        except: # ignore everything, as we're shutting down\n            if raiseExceptions:\n                raise\n            #else, swallow\n\n#Let's try and shutdown automatically on application exit...\nimport atexit\natexit.register(shutdown)\n\n# Null handler\n\nclass NullHandler(Handler):\n    \"\"\"\n    This handler does nothing. It's intended to be used to avoid the\n    \"No handlers could be found for logger XXX\" one-off warning. This is\n    important for library code, which may contain code to log events. If a user\n    of the library does not configure logging, the one-off warning might be\n    produced; to avoid this, the library developer simply needs to instantiate\n    a NullHandler and add it to the top-level logger of the library module or\n    package.\n    \"\"\"\n    def handle(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def emit(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def createLock(self):\n        self.lock = None\n\n# Warnings integration\n\n_warnings_showwarning = None\n\ndef _showwarning(message, category, filename, lineno, file=None, line=None):\n    \"\"\"\n    Implementation of showwarnings which redirects to logging, which will first\n    check to see if the file parameter is None. If a file is specified, it will\n    delegate to the original warnings implementation of showwarning. Otherwise,\n    it will call warnings.formatwarning and will log the resulting string to a\n    warnings logger named \"py.warnings\" with level logging.WARNING.\n    \"\"\"\n    if file is not None:\n        if _warnings_showwarning is not None:\n            _warnings_showwarning(message, category, filename, lineno, file, line)\n    else:\n        s = warnings.formatwarning(message, category, filename, lineno, line)\n        logger = getLogger(\"py.warnings\")\n        if not logger.handlers:\n            logger.addHandler(NullHandler())\n        logger.warning(\"%s\", s)\n\ndef captureWarnings(capture):\n    \"\"\"\n    If capture is true, redirect all warnings to the logging package.\n    If capture is False, ensure that warnings are not redirected to logging\n    but to their original destinations.\n    \"\"\"\n    global _warnings_showwarning\n    if capture:\n        if _warnings_showwarning is None:\n            _warnings_showwarning = warnings.showwarning\n            warnings.showwarning = _showwarning\n    else:\n        if _warnings_showwarning is not None:\n            warnings.showwarning = _warnings_showwarning\n            _warnings_showwarning = None\n", 2202], "/root/miniconda3/lib/python3.8/posixpath.py": ["\"\"\"Common operations on Posix pathnames.\n\nInstead of importing this module directly, import os and refer to\nthis module as os.path.  The \"os.path\" name is an alias for this\nmodule on Posix systems; on other systems (e.g. Windows),\nos.path provides the same operations in a manner specific to that\nplatform, and is an alias to another module (e.g. ntpath).\n\nSome of this can actually be useful on non-Posix systems too, e.g.\nfor manipulation of the pathname component of URLs.\n\"\"\"\n\n# Strings representing various path-related bits and pieces.\n# These are primarily for export; internally, they are hardcoded.\n# Should be set before imports for resolving cyclic dependency.\ncurdir = '.'\npardir = '..'\nextsep = '.'\nsep = '/'\npathsep = ':'\ndefpath = '/bin:/usr/bin'\naltsep = None\ndevnull = '/dev/null'\n\nimport os\nimport sys\nimport stat\nimport genericpath\nfrom genericpath import *\n\n__all__ = [\"normcase\",\"isabs\",\"join\",\"splitdrive\",\"split\",\"splitext\",\n           \"basename\",\"dirname\",\"commonprefix\",\"getsize\",\"getmtime\",\n           \"getatime\",\"getctime\",\"islink\",\"exists\",\"lexists\",\"isdir\",\"isfile\",\n           \"ismount\", \"expanduser\",\"expandvars\",\"normpath\",\"abspath\",\n           \"samefile\",\"sameopenfile\",\"samestat\",\n           \"curdir\",\"pardir\",\"sep\",\"pathsep\",\"defpath\",\"altsep\",\"extsep\",\n           \"devnull\",\"realpath\",\"supports_unicode_filenames\",\"relpath\",\n           \"commonpath\"]\n\n\ndef _get_sep(path):\n    if isinstance(path, bytes):\n        return b'/'\n    else:\n        return '/'\n\n# Normalize the case of a pathname.  Trivial in Posix, string.lower on Mac.\n# On MS-DOS this may also turn slashes into backslashes; however, other\n# normalizations (such as optimizing '../' away) are not allowed\n# (another function should be defined to do that).\n\ndef normcase(s):\n    \"\"\"Normalize case of pathname.  Has no effect under Posix\"\"\"\n    return os.fspath(s)\n\n\n# Return whether a path is absolute.\n# Trivial in Posix, harder on the Mac or MS-DOS.\n\ndef isabs(s):\n    \"\"\"Test whether a path is absolute\"\"\"\n    s = os.fspath(s)\n    sep = _get_sep(s)\n    return s.startswith(sep)\n\n\n# Join pathnames.\n# Ignore the previous parts if a part is absolute.\n# Insert a '/' unless the first part is empty or already ends in '/'.\n\ndef join(a, *p):\n    \"\"\"Join two or more pathname components, inserting '/' as needed.\n    If any component is an absolute path, all previous path components\n    will be discarded.  An empty last part will result in a path that\n    ends with a separator.\"\"\"\n    a = os.fspath(a)\n    sep = _get_sep(a)\n    path = a\n    try:\n        if not p:\n            path[:0] + sep  #23780: Ensure compatible data type even if p is null.\n        for b in map(os.fspath, p):\n            if b.startswith(sep):\n                path = b\n            elif not path or path.endswith(sep):\n                path += b\n            else:\n                path += sep + b\n    except (TypeError, AttributeError, BytesWarning):\n        genericpath._check_arg_types('join', a, *p)\n        raise\n    return path\n\n\n# Split a path in head (everything up to the last '/') and tail (the\n# rest).  If the path ends in '/', tail will be empty.  If there is no\n# '/' in the path, head  will be empty.\n# Trailing '/'es are stripped from head unless it is the root.\n\ndef split(p):\n    \"\"\"Split a pathname.  Returns tuple \"(head, tail)\" where \"tail\" is\n    everything after the final slash.  Either part may be empty.\"\"\"\n    p = os.fspath(p)\n    sep = _get_sep(p)\n    i = p.rfind(sep) + 1\n    head, tail = p[:i], p[i:]\n    if head and head != sep*len(head):\n        head = head.rstrip(sep)\n    return head, tail\n\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\ndef splitext(p):\n    p = os.fspath(p)\n    if isinstance(p, bytes):\n        sep = b'/'\n        extsep = b'.'\n    else:\n        sep = '/'\n        extsep = '.'\n    return genericpath._splitext(p, sep, None, extsep)\nsplitext.__doc__ = genericpath._splitext.__doc__\n\n# Split a pathname into a drive specification and the rest of the\n# path.  Useful on DOS/Windows/NT; on Unix, the drive is always empty.\n\ndef splitdrive(p):\n    \"\"\"Split a pathname into drive and path. On Posix, drive is always\n    empty.\"\"\"\n    p = os.fspath(p)\n    return p[:0], p\n\n\n# Return the tail (basename) part of a path, same as split(path)[1].\n\ndef basename(p):\n    \"\"\"Returns the final component of a pathname\"\"\"\n    p = os.fspath(p)\n    sep = _get_sep(p)\n    i = p.rfind(sep) + 1\n    return p[i:]\n\n\n# Return the head (dirname) part of a path, same as split(path)[0].\n\ndef dirname(p):\n    \"\"\"Returns the directory component of a pathname\"\"\"\n    p = os.fspath(p)\n    sep = _get_sep(p)\n    i = p.rfind(sep) + 1\n    head = p[:i]\n    if head and head != sep*len(head):\n        head = head.rstrip(sep)\n    return head\n\n\n# Is a path a symbolic link?\n# This will always return false on systems where os.lstat doesn't exist.\n\ndef islink(path):\n    \"\"\"Test whether a path is a symbolic link\"\"\"\n    try:\n        st = os.lstat(path)\n    except (OSError, ValueError, AttributeError):\n        return False\n    return stat.S_ISLNK(st.st_mode)\n\n# Being true for dangling symbolic links is also useful.\n\ndef lexists(path):\n    \"\"\"Test whether a path exists.  Returns True for broken symbolic links\"\"\"\n    try:\n        os.lstat(path)\n    except (OSError, ValueError):\n        return False\n    return True\n\n\n# Is a path a mount point?\n# (Does this work for all UNIXes?  Is it even guaranteed to work by Posix?)\n\ndef ismount(path):\n    \"\"\"Test whether a path is a mount point\"\"\"\n    try:\n        s1 = os.lstat(path)\n    except (OSError, ValueError):\n        # It doesn't exist -- so not a mount point. :-)\n        return False\n    else:\n        # A symlink can never be a mount point\n        if stat.S_ISLNK(s1.st_mode):\n            return False\n\n    if isinstance(path, bytes):\n        parent = join(path, b'..')\n    else:\n        parent = join(path, '..')\n    parent = realpath(parent)\n    try:\n        s2 = os.lstat(parent)\n    except (OSError, ValueError):\n        return False\n\n    dev1 = s1.st_dev\n    dev2 = s2.st_dev\n    if dev1 != dev2:\n        return True     # path/.. on a different device as path\n    ino1 = s1.st_ino\n    ino2 = s2.st_ino\n    if ino1 == ino2:\n        return True     # path/.. is the same i-node as path\n    return False\n\n\n# Expand paths beginning with '~' or '~user'.\n# '~' means $HOME; '~user' means that user's home directory.\n# If the path doesn't begin with '~', or if the user or $HOME is unknown,\n# the path is returned unchanged (leaving error reporting to whatever\n# function is called with the expanded path as argument).\n# See also module 'glob' for expansion of *, ? and [...] in pathnames.\n# (A function should also be defined to do full *sh-style environment\n# variable expansion.)\n\ndef expanduser(path):\n    \"\"\"Expand ~ and ~user constructions.  If user or $HOME is unknown,\n    do nothing.\"\"\"\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        tilde = b'~'\n    else:\n        tilde = '~'\n    if not path.startswith(tilde):\n        return path\n    sep = _get_sep(path)\n    i = path.find(sep, 1)\n    if i < 0:\n        i = len(path)\n    if i == 1:\n        if 'HOME' not in os.environ:\n            import pwd\n            try:\n                userhome = pwd.getpwuid(os.getuid()).pw_dir\n            except KeyError:\n                # bpo-10496: if the current user identifier doesn't exist in the\n                # password database, return the path unchanged\n                return path\n        else:\n            userhome = os.environ['HOME']\n    else:\n        import pwd\n        name = path[1:i]\n        if isinstance(name, bytes):\n            name = str(name, 'ASCII')\n        try:\n            pwent = pwd.getpwnam(name)\n        except KeyError:\n            # bpo-10496: if the user name from the path doesn't exist in the\n            # password database, return the path unchanged\n            return path\n        userhome = pwent.pw_dir\n    if isinstance(path, bytes):\n        userhome = os.fsencode(userhome)\n        root = b'/'\n    else:\n        root = '/'\n    userhome = userhome.rstrip(root)\n    return (userhome + path[i:]) or root\n\n\n# Expand paths containing shell variable substitutions.\n# This expands the forms $variable and ${variable} only.\n# Non-existent variables are left unchanged.\n\n_varprog = None\n_varprogb = None\n\ndef expandvars(path):\n    \"\"\"Expand shell variables of form $var and ${var}.  Unknown variables\n    are left unchanged.\"\"\"\n    path = os.fspath(path)\n    global _varprog, _varprogb\n    if isinstance(path, bytes):\n        if b'$' not in path:\n            return path\n        if not _varprogb:\n            import re\n            _varprogb = re.compile(br'\\$(\\w+|\\{[^}]*\\})', re.ASCII)\n        search = _varprogb.search\n        start = b'{'\n        end = b'}'\n        environ = getattr(os, 'environb', None)\n    else:\n        if '$' not in path:\n            return path\n        if not _varprog:\n            import re\n            _varprog = re.compile(r'\\$(\\w+|\\{[^}]*\\})', re.ASCII)\n        search = _varprog.search\n        start = '{'\n        end = '}'\n        environ = os.environ\n    i = 0\n    while True:\n        m = search(path, i)\n        if not m:\n            break\n        i, j = m.span(0)\n        name = m.group(1)\n        if name.startswith(start) and name.endswith(end):\n            name = name[1:-1]\n        try:\n            if environ is None:\n                value = os.fsencode(os.environ[os.fsdecode(name)])\n            else:\n                value = environ[name]\n        except KeyError:\n            i = j\n        else:\n            tail = path[j:]\n            path = path[:i] + value\n            i = len(path)\n            path += tail\n    return path\n\n\n# Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A/B.\n# It should be understood that this may change the meaning of the path\n# if it contains symbolic links!\n\ndef normpath(path):\n    \"\"\"Normalize path, eliminating double slashes, etc.\"\"\"\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        sep = b'/'\n        empty = b''\n        dot = b'.'\n        dotdot = b'..'\n    else:\n        sep = '/'\n        empty = ''\n        dot = '.'\n        dotdot = '..'\n    if path == empty:\n        return dot\n    initial_slashes = path.startswith(sep)\n    # POSIX allows one or two initial slashes, but treats three or more\n    # as single slash.\n    if (initial_slashes and\n        path.startswith(sep*2) and not path.startswith(sep*3)):\n        initial_slashes = 2\n    comps = path.split(sep)\n    new_comps = []\n    for comp in comps:\n        if comp in (empty, dot):\n            continue\n        if (comp != dotdot or (not initial_slashes and not new_comps) or\n             (new_comps and new_comps[-1] == dotdot)):\n            new_comps.append(comp)\n        elif new_comps:\n            new_comps.pop()\n    comps = new_comps\n    path = sep.join(comps)\n    if initial_slashes:\n        path = sep*initial_slashes + path\n    return path or dot\n\n\ndef abspath(path):\n    \"\"\"Return an absolute path.\"\"\"\n    path = os.fspath(path)\n    if not isabs(path):\n        if isinstance(path, bytes):\n            cwd = os.getcwdb()\n        else:\n            cwd = os.getcwd()\n        path = join(cwd, path)\n    return normpath(path)\n\n\n# Return a canonical path (i.e. the absolute location of a file on the\n# filesystem).\n\ndef realpath(filename):\n    \"\"\"Return the canonical path of the specified filename, eliminating any\nsymbolic links encountered in the path.\"\"\"\n    filename = os.fspath(filename)\n    path, ok = _joinrealpath(filename[:0], filename, {})\n    return abspath(path)\n\n# Join two paths, normalizing and eliminating any symbolic links\n# encountered in the second path.\ndef _joinrealpath(path, rest, seen):\n    if isinstance(path, bytes):\n        sep = b'/'\n        curdir = b'.'\n        pardir = b'..'\n    else:\n        sep = '/'\n        curdir = '.'\n        pardir = '..'\n\n    if isabs(rest):\n        rest = rest[1:]\n        path = sep\n\n    while rest:\n        name, _, rest = rest.partition(sep)\n        if not name or name == curdir:\n            # current dir\n            continue\n        if name == pardir:\n            # parent dir\n            if path:\n                path, name = split(path)\n                if name == pardir:\n                    path = join(path, pardir, pardir)\n            else:\n                path = pardir\n            continue\n        newpath = join(path, name)\n        if not islink(newpath):\n            path = newpath\n            continue\n        # Resolve the symbolic link\n        if newpath in seen:\n            # Already seen this path\n            path = seen[newpath]\n            if path is not None:\n                # use cached value\n                continue\n            # The symlink is not resolved, so we must have a symlink loop.\n            # Return already resolved part + rest of the path unchanged.\n            return join(newpath, rest), False\n        seen[newpath] = None # not resolved symlink\n        path, ok = _joinrealpath(path, os.readlink(newpath), seen)\n        if not ok:\n            return join(path, rest), False\n        seen[newpath] = path # resolved symlink\n\n    return path, True\n\n\nsupports_unicode_filenames = (sys.platform == 'darwin')\n\ndef relpath(path, start=None):\n    \"\"\"Return a relative version of a path\"\"\"\n\n    if not path:\n        raise ValueError(\"no path specified\")\n\n    path = os.fspath(path)\n    if isinstance(path, bytes):\n        curdir = b'.'\n        sep = b'/'\n        pardir = b'..'\n    else:\n        curdir = '.'\n        sep = '/'\n        pardir = '..'\n\n    if start is None:\n        start = curdir\n    else:\n        start = os.fspath(start)\n\n    try:\n        start_list = [x for x in abspath(start).split(sep) if x]\n        path_list = [x for x in abspath(path).split(sep) if x]\n        # Work out how much of the filepath is shared by start and path.\n        i = len(commonprefix([start_list, path_list]))\n\n        rel_list = [pardir] * (len(start_list)-i) + path_list[i:]\n        if not rel_list:\n            return curdir\n        return join(*rel_list)\n    except (TypeError, AttributeError, BytesWarning, DeprecationWarning):\n        genericpath._check_arg_types('relpath', path, start)\n        raise\n\n\n# Return the longest common sub-path of the sequence of paths given as input.\n# The paths are not normalized before comparing them (this is the\n# responsibility of the caller). Any trailing separator is stripped from the\n# returned path.\n\ndef commonpath(paths):\n    \"\"\"Given a sequence of path names, returns the longest common sub-path.\"\"\"\n\n    if not paths:\n        raise ValueError('commonpath() arg is an empty sequence')\n\n    paths = tuple(map(os.fspath, paths))\n    if isinstance(paths[0], bytes):\n        sep = b'/'\n        curdir = b'.'\n    else:\n        sep = '/'\n        curdir = '.'\n\n    try:\n        split_paths = [path.split(sep) for path in paths]\n\n        try:\n            isabs, = set(p[:1] == sep for p in paths)\n        except ValueError:\n            raise ValueError(\"Can't mix absolute and relative paths\") from None\n\n        split_paths = [[c for c in s if c and c != curdir] for s in split_paths]\n        s1 = min(split_paths)\n        s2 = max(split_paths)\n        common = s1\n        for i, c in enumerate(s1):\n            if c != s2[i]:\n                common = s1[:i]\n                break\n\n        prefix = sep if isabs else sep[:0]\n        return prefix + sep.join(common)\n    except (TypeError, AttributeError):\n        genericpath._check_arg_types('commonpath', *paths)\n        raise\n", 525], "/root/miniconda3/lib/python3.8/genericpath.py": ["\"\"\"\nPath operations common to more than one OS\nDo not use directly.  The OS specific modules import the appropriate\nfunctions from this module themselves.\n\"\"\"\nimport os\nimport stat\n\n__all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',\n           'getsize', 'isdir', 'isfile', 'samefile', 'sameopenfile',\n           'samestat']\n\n\n# Does a path exist?\n# This is false for dangling symbolic links on systems that support them.\ndef exists(path):\n    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\n    try:\n        os.stat(path)\n    except (OSError, ValueError):\n        return False\n    return True\n\n\n# This follows symbolic links, so both islink() and isdir() can be true\n# for the same path on systems that support symlinks\ndef isfile(path):\n    \"\"\"Test whether a path is a regular file\"\"\"\n    try:\n        st = os.stat(path)\n    except (OSError, ValueError):\n        return False\n    return stat.S_ISREG(st.st_mode)\n\n\n# Is a path a directory?\n# This follows symbolic links, so both islink() and isdir()\n# can be true for the same path on systems that support symlinks\ndef isdir(s):\n    \"\"\"Return true if the pathname refers to an existing directory.\"\"\"\n    try:\n        st = os.stat(s)\n    except (OSError, ValueError):\n        return False\n    return stat.S_ISDIR(st.st_mode)\n\n\ndef getsize(filename):\n    \"\"\"Return the size of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_size\n\n\ndef getmtime(filename):\n    \"\"\"Return the last modification time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_mtime\n\n\ndef getatime(filename):\n    \"\"\"Return the last access time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_atime\n\n\ndef getctime(filename):\n    \"\"\"Return the metadata change time of a file, reported by os.stat().\"\"\"\n    return os.stat(filename).st_ctime\n\n\n# Return the longest prefix of all list elements.\ndef commonprefix(m):\n    \"Given a list of pathnames, returns the longest common leading component\"\n    if not m: return ''\n    # Some people pass in a list of pathname parts to operate in an OS-agnostic\n    # fashion; don't try to translate in that case as that's an abuse of the\n    # API and they are already doing what they need to be OS-agnostic and so\n    # they most likely won't be using an os.PathLike object in the sublists.\n    if not isinstance(m[0], (list, tuple)):\n        m = tuple(map(os.fspath, m))\n    s1 = min(m)\n    s2 = max(m)\n    for i, c in enumerate(s1):\n        if c != s2[i]:\n            return s1[:i]\n    return s1\n\n# Are two stat buffers (obtained from stat, fstat or lstat)\n# describing the same file?\ndef samestat(s1, s2):\n    \"\"\"Test whether two stat buffers reference the same file\"\"\"\n    return (s1.st_ino == s2.st_ino and\n            s1.st_dev == s2.st_dev)\n\n\n# Are two filenames really pointing to the same file?\ndef samefile(f1, f2):\n    \"\"\"Test whether two pathnames reference the same actual file or directory\n\n    This is determined by the device number and i-node number and\n    raises an exception if an os.stat() call on either pathname fails.\n    \"\"\"\n    s1 = os.stat(f1)\n    s2 = os.stat(f2)\n    return samestat(s1, s2)\n\n\n# Are two open files really referencing the same file?\n# (Not necessarily the same file descriptor!)\ndef sameopenfile(fp1, fp2):\n    \"\"\"Test whether two open file objects reference the same file\"\"\"\n    s1 = os.fstat(fp1)\n    s2 = os.fstat(fp2)\n    return samestat(s1, s2)\n\n\n# Split a path in root and extension.\n# The extension is everything starting at the last dot in the last\n# pathname component; the root is everything before that.\n# It is always true that root + ext == p.\n\n# Generic implementation of splitext, to be parametrized with\n# the separators\ndef _splitext(p, sep, altsep, extsep):\n    \"\"\"Split the extension from a pathname.\n\n    Extension is everything from the last dot to the end, ignoring\n    leading dots.  Returns \"(root, ext)\"; ext may be empty.\"\"\"\n    # NOTE: This code must work for text and bytes strings.\n\n    sepIndex = p.rfind(sep)\n    if altsep:\n        altsepIndex = p.rfind(altsep)\n        sepIndex = max(sepIndex, altsepIndex)\n\n    dotIndex = p.rfind(extsep)\n    if dotIndex > sepIndex:\n        # skip all leading dots\n        filenameIndex = sepIndex + 1\n        while filenameIndex < dotIndex:\n            if p[filenameIndex:filenameIndex+1] != extsep:\n                return p[:dotIndex], p[dotIndex:]\n            filenameIndex += 1\n\n    return p, p[:0]\n\ndef _check_arg_types(funcname, *args):\n    hasstr = hasbytes = False\n    for s in args:\n        if isinstance(s, str):\n            hasstr = True\n        elif isinstance(s, bytes):\n            hasbytes = True\n        else:\n            raise TypeError(f'{funcname}() argument must be str, bytes, or '\n                            f'os.PathLike object, not {s.__class__.__name__!r}') from None\n    if hasstr and hasbytes:\n        raise TypeError(\"Can't mix strings and bytes in path components\") from None\n", 155], "/root/miniconda3/lib/python3.8/threading.py": ["\"\"\"Thread module emulating a subset of Java's threading model.\"\"\"\n\nimport os as _os\nimport sys as _sys\nimport _thread\n\nfrom time import monotonic as _time\nfrom _weakrefset import WeakSet\nfrom itertools import islice as _islice, count as _count\ntry:\n    from _collections import deque as _deque\nexcept ImportError:\n    from collections import deque as _deque\n\n# Note regarding PEP 8 compliant names\n#  This threading model was originally inspired by Java, and inherited\n# the convention of camelCase function and method names from that\n# language. Those original names are not in any imminent danger of\n# being deprecated (even for Py3k),so this module provides them as an\n# alias for the PEP 8 compliant names\n# Note that using the new PEP 8 compliant names facilitates substitution\n# with the multiprocessing module, which doesn't provide the old\n# Java inspired names.\n\n__all__ = ['get_ident', 'active_count', 'Condition', 'current_thread',\n           'enumerate', 'main_thread', 'TIMEOUT_MAX',\n           'Event', 'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Thread',\n           'Barrier', 'BrokenBarrierError', 'Timer', 'ThreadError',\n           'setprofile', 'settrace', 'local', 'stack_size',\n           'excepthook', 'ExceptHookArgs']\n\n# Rename some stuff so \"from threading import *\" is safe\n_start_new_thread = _thread.start_new_thread\n_allocate_lock = _thread.allocate_lock\n_set_sentinel = _thread._set_sentinel\nget_ident = _thread.get_ident\ntry:\n    get_native_id = _thread.get_native_id\n    _HAVE_THREAD_NATIVE_ID = True\n    __all__.append('get_native_id')\nexcept AttributeError:\n    _HAVE_THREAD_NATIVE_ID = False\nThreadError = _thread.error\ntry:\n    _CRLock = _thread.RLock\nexcept AttributeError:\n    _CRLock = None\nTIMEOUT_MAX = _thread.TIMEOUT_MAX\ndel _thread\n\n\n# Support for profile and trace hooks\n\n_profile_hook = None\n_trace_hook = None\n\ndef setprofile(func):\n    \"\"\"Set a profile function for all threads started from the threading module.\n\n    The func will be passed to sys.setprofile() for each thread, before its\n    run() method is called.\n\n    \"\"\"\n    global _profile_hook\n    _profile_hook = func\n\ndef settrace(func):\n    \"\"\"Set a trace function for all threads started from the threading module.\n\n    The func will be passed to sys.settrace() for each thread, before its run()\n    method is called.\n\n    \"\"\"\n    global _trace_hook\n    _trace_hook = func\n\n# Synchronization classes\n\nLock = _allocate_lock\n\ndef RLock(*args, **kwargs):\n    \"\"\"Factory function that returns a new reentrant lock.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it again\n    without blocking; the thread must release it once for each time it has\n    acquired it.\n\n    \"\"\"\n    if _CRLock is None:\n        return _PyRLock(*args, **kwargs)\n    return _CRLock(*args, **kwargs)\n\nclass _RLock:\n    \"\"\"This class implements reentrant lock objects.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it\n    again without blocking; the thread must release it once for each time it\n    has acquired it.\n\n    \"\"\"\n\n    def __init__(self):\n        self._block = _allocate_lock()\n        self._owner = None\n        self._count = 0\n\n    def __repr__(self):\n        owner = self._owner\n        try:\n            owner = _active[owner].name\n        except KeyError:\n            pass\n        return \"<%s %s.%s object owner=%r count=%d at %s>\" % (\n            \"locked\" if self._block.locked() else \"unlocked\",\n            self.__class__.__module__,\n            self.__class__.__qualname__,\n            owner,\n            self._count,\n            hex(id(self))\n        )\n\n    def acquire(self, blocking=True, timeout=-1):\n        \"\"\"Acquire a lock, blocking or non-blocking.\n\n        When invoked without arguments: if this thread already owns the lock,\n        increment the recursion level by one, and return immediately. Otherwise,\n        if another thread owns the lock, block until the lock is unlocked. Once\n        the lock is unlocked (not owned by any thread), then grab ownership, set\n        the recursion level to one, and return. If more than one thread is\n        blocked waiting until the lock is unlocked, only one at a time will be\n        able to grab ownership of the lock. There is no return value in this\n        case.\n\n        When invoked with the blocking argument set to true, do the same thing\n        as when called without arguments, and return true.\n\n        When invoked with the blocking argument set to false, do not block. If a\n        call without an argument would block, return false immediately;\n        otherwise, do the same thing as when called without arguments, and\n        return true.\n\n        When invoked with the floating-point timeout argument set to a positive\n        value, block for at most the number of seconds specified by timeout\n        and as long as the lock cannot be acquired.  Return true if the lock has\n        been acquired, false if the timeout has elapsed.\n\n        \"\"\"\n        me = get_ident()\n        if self._owner == me:\n            self._count += 1\n            return 1\n        rc = self._block.acquire(blocking, timeout)\n        if rc:\n            self._owner = me\n            self._count = 1\n        return rc\n\n    __enter__ = acquire\n\n    def release(self):\n        \"\"\"Release a lock, decrementing the recursion level.\n\n        If after the decrement it is zero, reset the lock to unlocked (not owned\n        by any thread), and if any other threads are blocked waiting for the\n        lock to become unlocked, allow exactly one of them to proceed. If after\n        the decrement the recursion level is still nonzero, the lock remains\n        locked and owned by the calling thread.\n\n        Only call this method when the calling thread owns the lock. A\n        RuntimeError is raised if this method is called when the lock is\n        unlocked.\n\n        There is no return value.\n\n        \"\"\"\n        if self._owner != get_ident():\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        self._count = count = self._count - 1\n        if not count:\n            self._owner = None\n            self._block.release()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n    # Internal methods used by condition variables\n\n    def _acquire_restore(self, state):\n        self._block.acquire()\n        self._count, self._owner = state\n\n    def _release_save(self):\n        if self._count == 0:\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        count = self._count\n        self._count = 0\n        owner = self._owner\n        self._owner = None\n        self._block.release()\n        return (count, owner)\n\n    def _is_owned(self):\n        return self._owner == get_ident()\n\n_PyRLock = _RLock\n\n\nclass Condition:\n    \"\"\"Class that implements a condition variable.\n\n    A condition variable allows one or more threads to wait until they are\n    notified by another thread.\n\n    If the lock argument is given and not None, it must be a Lock or RLock\n    object, and it is used as the underlying lock. Otherwise, a new RLock object\n    is created and used as the underlying lock.\n\n    \"\"\"\n\n    def __init__(self, lock=None):\n        if lock is None:\n            lock = RLock()\n        self._lock = lock\n        # Export the lock's acquire() and release() methods\n        self.acquire = lock.acquire\n        self.release = lock.release\n        # If the lock defines _release_save() and/or _acquire_restore(),\n        # these override the default implementations (which just call\n        # release() and acquire() on the lock).  Ditto for _is_owned().\n        try:\n            self._release_save = lock._release_save\n        except AttributeError:\n            pass\n        try:\n            self._acquire_restore = lock._acquire_restore\n        except AttributeError:\n            pass\n        try:\n            self._is_owned = lock._is_owned\n        except AttributeError:\n            pass\n        self._waiters = _deque()\n\n    def __enter__(self):\n        return self._lock.__enter__()\n\n    def __exit__(self, *args):\n        return self._lock.__exit__(*args)\n\n    def __repr__(self):\n        return \"<Condition(%s, %d)>\" % (self._lock, len(self._waiters))\n\n    def _release_save(self):\n        self._lock.release()           # No state to save\n\n    def _acquire_restore(self, x):\n        self._lock.acquire()           # Ignore saved state\n\n    def _is_owned(self):\n        # Return True if lock is owned by current_thread.\n        # This method is called only if _lock doesn't have _is_owned().\n        if self._lock.acquire(0):\n            self._lock.release()\n            return False\n        else:\n            return True\n\n    def wait(self, timeout=None):\n        \"\"\"Wait until notified or until a timeout occurs.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method releases the underlying lock, and then blocks until it is\n        awakened by a notify() or notify_all() call for the same condition\n        variable in another thread, or until the optional timeout occurs. Once\n        awakened or timed out, it re-acquires the lock and returns.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        When the underlying lock is an RLock, it is not released using its\n        release() method, since this may not actually unlock the lock when it\n        was acquired multiple times recursively. Instead, an internal interface\n        of the RLock class is used, which really unlocks it even when it has\n        been recursively acquired several times. Another internal interface is\n        then used to restore the recursion level when the lock is reacquired.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot wait on un-acquired lock\")\n        waiter = _allocate_lock()\n        waiter.acquire()\n        self._waiters.append(waiter)\n        saved_state = self._release_save()\n        gotit = False\n        try:    # restore state no matter what (e.g., KeyboardInterrupt)\n            if timeout is None:\n                waiter.acquire()\n                gotit = True\n            else:\n                if timeout > 0:\n                    gotit = waiter.acquire(True, timeout)\n                else:\n                    gotit = waiter.acquire(False)\n            return gotit\n        finally:\n            self._acquire_restore(saved_state)\n            if not gotit:\n                try:\n                    self._waiters.remove(waiter)\n                except ValueError:\n                    pass\n\n    def wait_for(self, predicate, timeout=None):\n        \"\"\"Wait until a condition evaluates to True.\n\n        predicate should be a callable which result will be interpreted as a\n        boolean value.  A timeout may be provided giving the maximum time to\n        wait.\n\n        \"\"\"\n        endtime = None\n        waittime = timeout\n        result = predicate()\n        while not result:\n            if waittime is not None:\n                if endtime is None:\n                    endtime = _time() + waittime\n                else:\n                    waittime = endtime - _time()\n                    if waittime <= 0:\n                        break\n            self.wait(waittime)\n            result = predicate()\n        return result\n\n    def notify(self, n=1):\n        \"\"\"Wake up one or more threads waiting on this condition, if any.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method wakes up at most n of the threads waiting for the condition\n        variable; it is a no-op if no threads are waiting.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot notify on un-acquired lock\")\n        all_waiters = self._waiters\n        waiters_to_notify = _deque(_islice(all_waiters, n))\n        if not waiters_to_notify:\n            return\n        for waiter in waiters_to_notify:\n            waiter.release()\n            try:\n                all_waiters.remove(waiter)\n            except ValueError:\n                pass\n\n    def notify_all(self):\n        \"\"\"Wake up all threads waiting on this condition.\n\n        If the calling thread has not acquired the lock when this method\n        is called, a RuntimeError is raised.\n\n        \"\"\"\n        self.notify(len(self._waiters))\n\n    notifyAll = notify_all\n\n\nclass Semaphore:\n    \"\"\"This class implements semaphore objects.\n\n    Semaphores manage a counter representing the number of release() calls minus\n    the number of acquire() calls, plus an initial value. The acquire() method\n    blocks if necessary until it can return without making the counter\n    negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    # After Tim Peters' semaphore class, but not quite the same (no maximum)\n\n    def __init__(self, value=1):\n        if value < 0:\n            raise ValueError(\"semaphore initial value must be >= 0\")\n        self._cond = Condition(Lock())\n        self._value = value\n\n    def acquire(self, blocking=True, timeout=None):\n        \"\"\"Acquire a semaphore, decrementing the internal counter by one.\n\n        When invoked without arguments: if the internal counter is larger than\n        zero on entry, decrement it by one and return immediately. If it is zero\n        on entry, block, waiting until some other thread has called release() to\n        make it larger than zero. This is done with proper interlocking so that\n        if multiple acquire() calls are blocked, release() will wake exactly one\n        of them up. The implementation may pick one at random, so the order in\n        which blocked threads are awakened should not be relied on. There is no\n        return value in this case.\n\n        When invoked with blocking set to true, do the same thing as when called\n        without arguments, and return true.\n\n        When invoked with blocking set to false, do not block. If a call without\n        an argument would block, return false immediately; otherwise, do the\n        same thing as when called without arguments, and return true.\n\n        When invoked with a timeout other than None, it will block for at\n        most timeout seconds.  If acquire does not complete successfully in\n        that interval, return false.  Return true otherwise.\n\n        \"\"\"\n        if not blocking and timeout is not None:\n            raise ValueError(\"can't specify timeout for non-blocking acquire\")\n        rc = False\n        endtime = None\n        with self._cond:\n            while self._value == 0:\n                if not blocking:\n                    break\n                if timeout is not None:\n                    if endtime is None:\n                        endtime = _time() + timeout\n                    else:\n                        timeout = endtime - _time()\n                        if timeout <= 0:\n                            break\n                self._cond.wait(timeout)\n            else:\n                self._value -= 1\n                rc = True\n        return rc\n\n    __enter__ = acquire\n\n    def release(self):\n        \"\"\"Release a semaphore, incrementing the internal counter by one.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        \"\"\"\n        with self._cond:\n            self._value += 1\n            self._cond.notify()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n\nclass BoundedSemaphore(Semaphore):\n    \"\"\"Implements a bounded semaphore.\n\n    A bounded semaphore checks to make sure its current value doesn't exceed its\n    initial value. If it does, ValueError is raised. In most situations\n    semaphores are used to guard resources with limited capacity.\n\n    If the semaphore is released too many times it's a sign of a bug. If not\n    given, value defaults to 1.\n\n    Like regular semaphores, bounded semaphores manage a counter representing\n    the number of release() calls minus the number of acquire() calls, plus an\n    initial value. The acquire() method blocks if necessary until it can return\n    without making the counter negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    def __init__(self, value=1):\n        Semaphore.__init__(self, value)\n        self._initial_value = value\n\n    def release(self):\n        \"\"\"Release a semaphore, incrementing the internal counter by one.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        If the number of releases exceeds the number of acquires,\n        raise a ValueError.\n\n        \"\"\"\n        with self._cond:\n            if self._value >= self._initial_value:\n                raise ValueError(\"Semaphore released too many times\")\n            self._value += 1\n            self._cond.notify()\n\n\nclass Event:\n    \"\"\"Class implementing event objects.\n\n    Events manage a flag that can be set to true with the set() method and reset\n    to false with the clear() method. The wait() method blocks until the flag is\n    true.  The flag is initially false.\n\n    \"\"\"\n\n    # After Tim Peters' event class (without is_posted())\n\n    def __init__(self):\n        self._cond = Condition(Lock())\n        self._flag = False\n\n    def _reset_internal_locks(self):\n        # private!  called by Thread._reset_internal_locks by _after_fork()\n        self._cond.__init__(Lock())\n\n    def is_set(self):\n        \"\"\"Return true if and only if the internal flag is true.\"\"\"\n        return self._flag\n\n    isSet = is_set\n\n    def set(self):\n        \"\"\"Set the internal flag to true.\n\n        All threads waiting for it to become true are awakened. Threads\n        that call wait() once the flag is true will not block at all.\n\n        \"\"\"\n        with self._cond:\n            self._flag = True\n            self._cond.notify_all()\n\n    def clear(self):\n        \"\"\"Reset the internal flag to false.\n\n        Subsequently, threads calling wait() will block until set() is called to\n        set the internal flag to true again.\n\n        \"\"\"\n        with self._cond:\n            self._flag = False\n\n    def wait(self, timeout=None):\n        \"\"\"Block until the internal flag is true.\n\n        If the internal flag is true on entry, return immediately. Otherwise,\n        block until another thread calls set() to set the flag to true, or until\n        the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        This method returns the internal flag on exit, so it will always return\n        True except if a timeout is given and the operation times out.\n\n        \"\"\"\n        with self._cond:\n            signaled = self._flag\n            if not signaled:\n                signaled = self._cond.wait(timeout)\n            return signaled\n\n\n# A barrier class.  Inspired in part by the pthread_barrier_* api and\n# the CyclicBarrier class from Java.  See\n# http://sourceware.org/pthreads-win32/manual/pthread_barrier_init.html and\n# http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/\n#        CyclicBarrier.html\n# for information.\n# We maintain two main states, 'filling' and 'draining' enabling the barrier\n# to be cyclic.  Threads are not allowed into it until it has fully drained\n# since the previous cycle.  In addition, a 'resetting' state exists which is\n# similar to 'draining' except that threads leave with a BrokenBarrierError,\n# and a 'broken' state in which all threads get the exception.\nclass Barrier:\n    \"\"\"Implements a Barrier.\n\n    Useful for synchronizing a fixed number of threads at known synchronization\n    points.  Threads block on 'wait()' and are simultaneously awoken once they\n    have all made that call.\n\n    \"\"\"\n\n    def __init__(self, parties, action=None, timeout=None):\n        \"\"\"Create a barrier, initialised to 'parties' threads.\n\n        'action' is a callable which, when supplied, will be called by one of\n        the threads after they have all entered the barrier and just prior to\n        releasing them all. If a 'timeout' is provided, it is used as the\n        default for all subsequent 'wait()' calls.\n\n        \"\"\"\n        self._cond = Condition(Lock())\n        self._action = action\n        self._timeout = timeout\n        self._parties = parties\n        self._state = 0 #0 filling, 1, draining, -1 resetting, -2 broken\n        self._count = 0\n\n    def wait(self, timeout=None):\n        \"\"\"Wait for the barrier.\n\n        When the specified number of threads have started waiting, they are all\n        simultaneously awoken. If an 'action' was provided for the barrier, one\n        of the threads will have executed that callback prior to returning.\n        Returns an individual index number from 0 to 'parties-1'.\n\n        \"\"\"\n        if timeout is None:\n            timeout = self._timeout\n        with self._cond:\n            self._enter() # Block while the barrier drains.\n            index = self._count\n            self._count += 1\n            try:\n                if index + 1 == self._parties:\n                    # We release the barrier\n                    self._release()\n                else:\n                    # We wait until someone releases us\n                    self._wait(timeout)\n                return index\n            finally:\n                self._count -= 1\n                # Wake up any threads waiting for barrier to drain.\n                self._exit()\n\n    # Block until the barrier is ready for us, or raise an exception\n    # if it is broken.\n    def _enter(self):\n        while self._state in (-1, 1):\n            # It is draining or resetting, wait until done\n            self._cond.wait()\n        #see if the barrier is in a broken state\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 0\n\n    # Optionally run the 'action' and release the threads waiting\n    # in the barrier.\n    def _release(self):\n        try:\n            if self._action:\n                self._action()\n            # enter draining state\n            self._state = 1\n            self._cond.notify_all()\n        except:\n            #an exception during the _action handler.  Break and reraise\n            self._break()\n            raise\n\n    # Wait in the barrier until we are released.  Raise an exception\n    # if the barrier is reset or broken.\n    def _wait(self, timeout):\n        if not self._cond.wait_for(lambda : self._state != 0, timeout):\n            #timed out.  Break the barrier\n            self._break()\n            raise BrokenBarrierError\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 1\n\n    # If we are the last thread to exit the barrier, signal any threads\n    # waiting for the barrier to drain.\n    def _exit(self):\n        if self._count == 0:\n            if self._state in (-1, 1):\n                #resetting or draining\n                self._state = 0\n                self._cond.notify_all()\n\n    def reset(self):\n        \"\"\"Reset the barrier to the initial state.\n\n        Any threads currently waiting will get the BrokenBarrier exception\n        raised.\n\n        \"\"\"\n        with self._cond:\n            if self._count > 0:\n                if self._state == 0:\n                    #reset the barrier, waking up threads\n                    self._state = -1\n                elif self._state == -2:\n                    #was broken, set it to reset state\n                    #which clears when the last thread exits\n                    self._state = -1\n            else:\n                self._state = 0\n            self._cond.notify_all()\n\n    def abort(self):\n        \"\"\"Place the barrier into a 'broken' state.\n\n        Useful in case of error.  Any currently waiting threads and threads\n        attempting to 'wait()' will have BrokenBarrierError raised.\n\n        \"\"\"\n        with self._cond:\n            self._break()\n\n    def _break(self):\n        # An internal error was detected.  The barrier is set to\n        # a broken state all parties awakened.\n        self._state = -2\n        self._cond.notify_all()\n\n    @property\n    def parties(self):\n        \"\"\"Return the number of threads required to trip the barrier.\"\"\"\n        return self._parties\n\n    @property\n    def n_waiting(self):\n        \"\"\"Return the number of threads currently waiting at the barrier.\"\"\"\n        # We don't need synchronization here since this is an ephemeral result\n        # anyway.  It returns the correct value in the steady state.\n        if self._state == 0:\n            return self._count\n        return 0\n\n    @property\n    def broken(self):\n        \"\"\"Return True if the barrier is in a broken state.\"\"\"\n        return self._state == -2\n\n# exception raised by the Barrier class\nclass BrokenBarrierError(RuntimeError):\n    pass\n\n\n# Helper to generate new thread names\n_counter = _count().__next__\n_counter() # Consume 0 so first non-main thread has id 1.\ndef _newname(template=\"Thread-%d\"):\n    return template % _counter()\n\n# Active thread administration\n_active_limbo_lock = _allocate_lock()\n_active = {}    # maps thread id to Thread object\n_limbo = {}\n_dangling = WeakSet()\n# Set of Thread._tstate_lock locks of non-daemon threads used by _shutdown()\n# to wait until all Python thread states get deleted:\n# see Thread._set_tstate_lock().\n_shutdown_locks_lock = _allocate_lock()\n_shutdown_locks = set()\n\n# Main class for threads\n\nclass Thread:\n    \"\"\"A class that represents a thread of control.\n\n    This class can be safely subclassed in a limited fashion. There are two ways\n    to specify the activity: by passing a callable object to the constructor, or\n    by overriding the run() method in a subclass.\n\n    \"\"\"\n\n    _initialized = False\n\n    def __init__(self, group=None, target=None, name=None,\n                 args=(), kwargs=None, *, daemon=None):\n        \"\"\"This constructor should always be called with keyword arguments. Arguments are:\n\n        *group* should be None; reserved for future extension when a ThreadGroup\n        class is implemented.\n\n        *target* is the callable object to be invoked by the run()\n        method. Defaults to None, meaning nothing is called.\n\n        *name* is the thread name. By default, a unique name is constructed of\n        the form \"Thread-N\" where N is a small decimal number.\n\n        *args* is the argument tuple for the target invocation. Defaults to ().\n\n        *kwargs* is a dictionary of keyword arguments for the target\n        invocation. Defaults to {}.\n\n        If a subclass overrides the constructor, it must make sure to invoke\n        the base class constructor (Thread.__init__()) before doing anything\n        else to the thread.\n\n        \"\"\"\n        assert group is None, \"group argument must be None for now\"\n        if kwargs is None:\n            kwargs = {}\n        self._target = target\n        self._name = str(name or _newname())\n        self._args = args\n        self._kwargs = kwargs\n        if daemon is not None:\n            self._daemonic = daemon\n        else:\n            self._daemonic = current_thread().daemon\n        self._ident = None\n        if _HAVE_THREAD_NATIVE_ID:\n            self._native_id = None\n        self._tstate_lock = None\n        self._started = Event()\n        self._is_stopped = False\n        self._initialized = True\n        # Copy of sys.stderr used by self._invoke_excepthook()\n        self._stderr = _sys.stderr\n        self._invoke_excepthook = _make_invoke_excepthook()\n        # For debugging and _after_fork()\n        _dangling.add(self)\n\n    def _reset_internal_locks(self, is_alive):\n        # private!  Called by _after_fork() to reset our internal locks as\n        # they may be in an invalid state leading to a deadlock or crash.\n        self._started._reset_internal_locks()\n        if is_alive:\n            self._set_tstate_lock()\n        else:\n            # The thread isn't alive after fork: it doesn't have a tstate\n            # anymore.\n            self._is_stopped = True\n            self._tstate_lock = None\n\n    def __repr__(self):\n        assert self._initialized, \"Thread.__init__() was not called\"\n        status = \"initial\"\n        if self._started.is_set():\n            status = \"started\"\n        self.is_alive() # easy way to get ._is_stopped set when appropriate\n        if self._is_stopped:\n            status = \"stopped\"\n        if self._daemonic:\n            status += \" daemon\"\n        if self._ident is not None:\n            status += \" %s\" % self._ident\n        return \"<%s(%s, %s)>\" % (self.__class__.__name__, self._name, status)\n\n    def start(self):\n        \"\"\"Start the thread's activity.\n\n        It must be called at most once per thread object. It arranges for the\n        object's run() method to be invoked in a separate thread of control.\n\n        This method will raise a RuntimeError if called more than once on the\n        same thread object.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"thread.__init__() not called\")\n\n        if self._started.is_set():\n            raise RuntimeError(\"threads can only be started once\")\n        with _active_limbo_lock:\n            _limbo[self] = self\n        try:\n            _start_new_thread(self._bootstrap, ())\n        except Exception:\n            with _active_limbo_lock:\n                del _limbo[self]\n            raise\n        self._started.wait()\n\n    def run(self):\n        \"\"\"Method representing the thread's activity.\n\n        You may override this method in a subclass. The standard run() method\n        invokes the callable object passed to the object's constructor as the\n        target argument, if any, with sequential and keyword arguments taken\n        from the args and kwargs arguments, respectively.\n\n        \"\"\"\n        try:\n            if self._target:\n                self._target(*self._args, **self._kwargs)\n        finally:\n            # Avoid a refcycle if the thread is running a function with\n            # an argument that has a member that points to the thread.\n            del self._target, self._args, self._kwargs\n\n    def _bootstrap(self):\n        # Wrapper around the real bootstrap code that ignores\n        # exceptions during interpreter cleanup.  Those typically\n        # happen when a daemon thread wakes up at an unfortunate\n        # moment, finds the world around it destroyed, and raises some\n        # random exception *** while trying to report the exception in\n        # _bootstrap_inner() below ***.  Those random exceptions\n        # don't help anybody, and they confuse users, so we suppress\n        # them.  We suppress them only when it appears that the world\n        # indeed has already been destroyed, so that exceptions in\n        # _bootstrap_inner() during normal business hours are properly\n        # reported.  Also, we only suppress them for daemonic threads;\n        # if a non-daemonic encounters this, something else is wrong.\n        try:\n            self._bootstrap_inner()\n        except:\n            if self._daemonic and _sys is None:\n                return\n            raise\n\n    def _set_ident(self):\n        self._ident = get_ident()\n\n    if _HAVE_THREAD_NATIVE_ID:\n        def _set_native_id(self):\n            self._native_id = get_native_id()\n\n    def _set_tstate_lock(self):\n        \"\"\"\n        Set a lock object which will be released by the interpreter when\n        the underlying thread state (see pystate.h) gets deleted.\n        \"\"\"\n        self._tstate_lock = _set_sentinel()\n        self._tstate_lock.acquire()\n\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                _shutdown_locks.add(self._tstate_lock)\n\n    def _bootstrap_inner(self):\n        try:\n            self._set_ident()\n            self._set_tstate_lock()\n            if _HAVE_THREAD_NATIVE_ID:\n                self._set_native_id()\n            self._started.set()\n            with _active_limbo_lock:\n                _active[self._ident] = self\n                del _limbo[self]\n\n            if _trace_hook:\n                _sys.settrace(_trace_hook)\n            if _profile_hook:\n                _sys.setprofile(_profile_hook)\n\n            try:\n                self.run()\n            except:\n                self._invoke_excepthook(self)\n        finally:\n            with _active_limbo_lock:\n                try:\n                    # We don't call self._delete() because it also\n                    # grabs _active_limbo_lock.\n                    del _active[get_ident()]\n                except:\n                    pass\n\n    def _stop(self):\n        # After calling ._stop(), .is_alive() returns False and .join() returns\n        # immediately.  ._tstate_lock must be released before calling ._stop().\n        #\n        # Normal case:  C code at the end of the thread's life\n        # (release_sentinel in _threadmodule.c) releases ._tstate_lock, and\n        # that's detected by our ._wait_for_tstate_lock(), called by .join()\n        # and .is_alive().  Any number of threads _may_ call ._stop()\n        # simultaneously (for example, if multiple threads are blocked in\n        # .join() calls), and they're not serialized.  That's harmless -\n        # they'll just make redundant rebindings of ._is_stopped and\n        # ._tstate_lock.  Obscure:  we rebind ._tstate_lock last so that the\n        # \"assert self._is_stopped\" in ._wait_for_tstate_lock() always works\n        # (the assert is executed only if ._tstate_lock is None).\n        #\n        # Special case:  _main_thread releases ._tstate_lock via this\n        # module's _shutdown() function.\n        lock = self._tstate_lock\n        if lock is not None:\n            assert not lock.locked()\n        self._is_stopped = True\n        self._tstate_lock = None\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                _shutdown_locks.discard(lock)\n\n    def _delete(self):\n        \"Remove current thread from the dict of currently running threads.\"\n        with _active_limbo_lock:\n            del _active[get_ident()]\n            # There must not be any python code between the previous line\n            # and after the lock is released.  Otherwise a tracing function\n            # could try to acquire the lock again in the same thread, (in\n            # current_thread()), and would block.\n\n    def join(self, timeout=None):\n        \"\"\"Wait until the thread terminates.\n\n        This blocks the calling thread until the thread whose join() method is\n        called terminates -- either normally or through an unhandled exception\n        or until the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof). As join() always returns None, you must call\n        is_alive() after join() to decide whether a timeout happened -- if the\n        thread is still alive, the join() call timed out.\n\n        When the timeout argument is not present or None, the operation will\n        block until the thread terminates.\n\n        A thread can be join()ed many times.\n\n        join() raises a RuntimeError if an attempt is made to join the current\n        thread as that would cause a deadlock. It is also an error to join() a\n        thread before it has been started and attempts to do so raises the same\n        exception.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if not self._started.is_set():\n            raise RuntimeError(\"cannot join thread before it is started\")\n        if self is current_thread():\n            raise RuntimeError(\"cannot join current thread\")\n\n        if timeout is None:\n            self._wait_for_tstate_lock()\n        else:\n            # the behavior of a negative timeout isn't documented, but\n            # historically .join(timeout=x) for x<0 has acted as if timeout=0\n            self._wait_for_tstate_lock(timeout=max(timeout, 0))\n\n    def _wait_for_tstate_lock(self, block=True, timeout=-1):\n        # Issue #18808: wait for the thread state to be gone.\n        # At the end of the thread's life, after all knowledge of the thread\n        # is removed from C data structures, C code releases our _tstate_lock.\n        # This method passes its arguments to _tstate_lock.acquire().\n        # If the lock is acquired, the C code is done, and self._stop() is\n        # called.  That sets ._is_stopped to True, and ._tstate_lock to None.\n        lock = self._tstate_lock\n        if lock is None:  # already determined that the C code is done\n            assert self._is_stopped\n        elif lock.acquire(block, timeout):\n            lock.release()\n            self._stop()\n\n    @property\n    def name(self):\n        \"\"\"A string used for identification purposes only.\n\n        It has no semantics. Multiple threads may be given the same name. The\n        initial name is set by the constructor.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        assert self._initialized, \"Thread.__init__() not called\"\n        self._name = str(name)\n\n    @property\n    def ident(self):\n        \"\"\"Thread identifier of this thread or None if it has not been started.\n\n        This is a nonzero integer. See the get_ident() function. Thread\n        identifiers may be recycled when a thread exits and another thread is\n        created. The identifier is available even after the thread has exited.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._ident\n\n    if _HAVE_THREAD_NATIVE_ID:\n        @property\n        def native_id(self):\n            \"\"\"Native integral thread ID of this thread, or None if it has not been started.\n\n            This is a non-negative integer. See the get_native_id() function.\n            This represents the Thread ID as reported by the kernel.\n\n            \"\"\"\n            assert self._initialized, \"Thread.__init__() not called\"\n            return self._native_id\n\n    def is_alive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method returns True just before the run() method starts until just\n        after the run() method terminates. The module function enumerate()\n        returns a list of all alive threads.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        if self._is_stopped or not self._started.is_set():\n            return False\n        self._wait_for_tstate_lock(False)\n        return not self._is_stopped\n\n    def isAlive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method is deprecated, use is_alive() instead.\n        \"\"\"\n        import warnings\n        warnings.warn('isAlive() is deprecated, use is_alive() instead',\n                      DeprecationWarning, stacklevel=2)\n        return self.is_alive()\n\n    @property\n    def daemon(self):\n        \"\"\"A boolean value indicating whether this thread is a daemon thread.\n\n        This must be set before start() is called, otherwise RuntimeError is\n        raised. Its initial value is inherited from the creating thread; the\n        main thread is not a daemon thread and therefore all threads created in\n        the main thread default to daemon = False.\n\n        The entire Python program exits when only daemon threads are left.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._daemonic\n\n    @daemon.setter\n    def daemon(self, daemonic):\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if self._started.is_set():\n            raise RuntimeError(\"cannot set daemon status of active thread\")\n        self._daemonic = daemonic\n\n    def isDaemon(self):\n        return self.daemon\n\n    def setDaemon(self, daemonic):\n        self.daemon = daemonic\n\n    def getName(self):\n        return self.name\n\n    def setName(self, name):\n        self.name = name\n\n\ntry:\n    from _thread import (_excepthook as excepthook,\n                         _ExceptHookArgs as ExceptHookArgs)\nexcept ImportError:\n    # Simple Python implementation if _thread._excepthook() is not available\n    from traceback import print_exception as _print_exception\n    from collections import namedtuple\n\n    _ExceptHookArgs = namedtuple(\n        'ExceptHookArgs',\n        'exc_type exc_value exc_traceback thread')\n\n    def ExceptHookArgs(args):\n        return _ExceptHookArgs(*args)\n\n    def excepthook(args, /):\n        \"\"\"\n        Handle uncaught Thread.run() exception.\n        \"\"\"\n        if args.exc_type == SystemExit:\n            # silently ignore SystemExit\n            return\n\n        if _sys is not None and _sys.stderr is not None:\n            stderr = _sys.stderr\n        elif args.thread is not None:\n            stderr = args.thread._stderr\n            if stderr is None:\n                # do nothing if sys.stderr is None and sys.stderr was None\n                # when the thread was created\n                return\n        else:\n            # do nothing if sys.stderr is None and args.thread is None\n            return\n\n        if args.thread is not None:\n            name = args.thread.name\n        else:\n            name = get_ident()\n        print(f\"Exception in thread {name}:\",\n              file=stderr, flush=True)\n        _print_exception(args.exc_type, args.exc_value, args.exc_traceback,\n                         file=stderr)\n        stderr.flush()\n\n\ndef _make_invoke_excepthook():\n    # Create a local namespace to ensure that variables remain alive\n    # when _invoke_excepthook() is called, even if it is called late during\n    # Python shutdown. It is mostly needed for daemon threads.\n\n    old_excepthook = excepthook\n    old_sys_excepthook = _sys.excepthook\n    if old_excepthook is None:\n        raise RuntimeError(\"threading.excepthook is None\")\n    if old_sys_excepthook is None:\n        raise RuntimeError(\"sys.excepthook is None\")\n\n    sys_exc_info = _sys.exc_info\n    local_print = print\n    local_sys = _sys\n\n    def invoke_excepthook(thread):\n        global excepthook\n        try:\n            hook = excepthook\n            if hook is None:\n                hook = old_excepthook\n\n            args = ExceptHookArgs([*sys_exc_info(), thread])\n\n            hook(args)\n        except Exception as exc:\n            exc.__suppress_context__ = True\n            del exc\n\n            if local_sys is not None and local_sys.stderr is not None:\n                stderr = local_sys.stderr\n            else:\n                stderr = thread._stderr\n\n            local_print(\"Exception in threading.excepthook:\",\n                        file=stderr, flush=True)\n\n            if local_sys is not None and local_sys.excepthook is not None:\n                sys_excepthook = local_sys.excepthook\n            else:\n                sys_excepthook = old_sys_excepthook\n\n            sys_excepthook(*sys_exc_info())\n        finally:\n            # Break reference cycle (exception stored in a variable)\n            args = None\n\n    return invoke_excepthook\n\n\n# The timer class was contributed by Itamar Shtull-Trauring\n\nclass Timer(Thread):\n    \"\"\"Call a function after a specified number of seconds:\n\n            t = Timer(30.0, f, args=None, kwargs=None)\n            t.start()\n            t.cancel()     # stop the timer's action if it's still waiting\n\n    \"\"\"\n\n    def __init__(self, interval, function, args=None, kwargs=None):\n        Thread.__init__(self)\n        self.interval = interval\n        self.function = function\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.finished = Event()\n\n    def cancel(self):\n        \"\"\"Stop the timer if it hasn't finished yet.\"\"\"\n        self.finished.set()\n\n    def run(self):\n        self.finished.wait(self.interval)\n        if not self.finished.is_set():\n            self.function(*self.args, **self.kwargs)\n        self.finished.set()\n\n\n# Special thread class to represent the main thread\n\nclass _MainThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=\"MainThread\", daemon=False)\n        self._set_tstate_lock()\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n\n# Dummy thread class to represent threads not started here.\n# These aren't garbage collected when they die, nor can they be waited for.\n# If they invoke anything in threading.py that calls current_thread(), they\n# leave an entry in the _active dict forever after.\n# Their purpose is to return *something* from current_thread().\n# They are marked as daemon threads so we won't wait for them\n# when we exit (conform previous semantics).\n\nclass _DummyThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=_newname(\"Dummy-%d\"), daemon=True)\n\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n    def _stop(self):\n        pass\n\n    def is_alive(self):\n        assert not self._is_stopped and self._started.is_set()\n        return True\n\n    def join(self, timeout=None):\n        assert False, \"cannot join a dummy thread\"\n\n\n# Global API functions\n\ndef current_thread():\n    \"\"\"Return the current Thread object, corresponding to the caller's thread of control.\n\n    If the caller's thread of control was not created through the threading\n    module, a dummy thread object with limited functionality is returned.\n\n    \"\"\"\n    try:\n        return _active[get_ident()]\n    except KeyError:\n        return _DummyThread()\n\ncurrentThread = current_thread\n\ndef active_count():\n    \"\"\"Return the number of Thread objects currently alive.\n\n    The returned count is equal to the length of the list returned by\n    enumerate().\n\n    \"\"\"\n    with _active_limbo_lock:\n        return len(_active) + len(_limbo)\n\nactiveCount = active_count\n\ndef _enumerate():\n    # Same as enumerate(), but without the lock. Internal use only.\n    return list(_active.values()) + list(_limbo.values())\n\ndef enumerate():\n    \"\"\"Return a list of all Thread objects currently alive.\n\n    The list includes daemonic threads, dummy thread objects created by\n    current_thread(), and the main thread. It excludes terminated threads and\n    threads that have not yet been started.\n\n    \"\"\"\n    with _active_limbo_lock:\n        return list(_active.values()) + list(_limbo.values())\n\nfrom _thread import stack_size\n\n# Create the main thread object,\n# and make it available for the interpreter\n# (Py_Main) as threading._shutdown.\n\n_main_thread = _MainThread()\n\ndef _shutdown():\n    \"\"\"\n    Wait until the Python thread state of all non-daemon threads get deleted.\n    \"\"\"\n    # Obscure:  other threads may be waiting to join _main_thread.  That's\n    # dubious, but some code does it.  We can't wait for C code to release\n    # the main thread's tstate_lock - that won't happen until the interpreter\n    # is nearly dead.  So we release it here.  Note that just calling _stop()\n    # isn't enough:  other threads may already be waiting on _tstate_lock.\n    if _main_thread._is_stopped:\n        # _shutdown() was already called\n        return\n\n    # Main thread\n    tlock = _main_thread._tstate_lock\n    # The main thread isn't finished yet, so its thread state lock can't have\n    # been released.\n    assert tlock is not None\n    assert tlock.locked()\n    tlock.release()\n    _main_thread._stop()\n\n    # Join all non-deamon threads\n    while True:\n        with _shutdown_locks_lock:\n            locks = list(_shutdown_locks)\n            _shutdown_locks.clear()\n\n        if not locks:\n            break\n\n        for lock in locks:\n            # mimick Thread.join()\n            lock.acquire()\n            lock.release()\n\n        # new threads can be spawned while we were waiting for the other\n        # threads to complete\n\n\ndef main_thread():\n    \"\"\"Return the main thread object.\n\n    In normal conditions, the main thread is the thread from which the\n    Python interpreter was started.\n    \"\"\"\n    return _main_thread\n\n# get thread-local implementation, either from the thread\n# module, or from the python fallback\n\ntry:\n    from _thread import _local as local\nexcept ImportError:\n    from _threading_local import local\n\n\ndef _after_fork():\n    \"\"\"\n    Cleanup threading module state that should not exist after a fork.\n    \"\"\"\n    # Reset _active_limbo_lock, in case we forked while the lock was held\n    # by another (non-forked) thread.  http://bugs.python.org/issue874900\n    global _active_limbo_lock, _main_thread\n    global _shutdown_locks_lock, _shutdown_locks\n    _active_limbo_lock = _allocate_lock()\n\n    # fork() only copied the current thread; clear references to others.\n    new_active = {}\n\n    try:\n        current = _active[get_ident()]\n    except KeyError:\n        # fork() was called in a thread which was not spawned\n        # by threading.Thread. For example, a thread spawned\n        # by thread.start_new_thread().\n        current = _MainThread()\n\n    _main_thread = current\n\n    # reset _shutdown() locks: threads re-register their _tstate_lock below\n    _shutdown_locks_lock = _allocate_lock()\n    _shutdown_locks = set()\n\n    with _active_limbo_lock:\n        # Dangling thread instances must still have their locks reset,\n        # because someone may join() them.\n        threads = set(_enumerate())\n        threads.update(_dangling)\n        for thread in threads:\n            # Any lock/condition variable may be currently locked or in an\n            # invalid state, so we reinitialize them.\n            if thread is current:\n                # There is only one active thread. We reset the ident to\n                # its new value since it can have changed.\n                thread._reset_internal_locks(True)\n                ident = get_ident()\n                thread._ident = ident\n                new_active[ident] = thread\n            else:\n                # All the others are already stopped.\n                thread._reset_internal_locks(False)\n                thread._stop()\n\n        _limbo.clear()\n        _active.clear()\n        _active.update(new_active)\n        assert len(_active) == 1\n\n\nif hasattr(_os, \"register_at_fork\"):\n    _os.register_at_fork(after_in_child=_after_fork)\n", 1466], "/root/miniconda3/lib/python3.8/multiprocessing/process.py": ["#\n# Module providing the `Process` class which emulates `threading.Thread`\n#\n# multiprocessing/process.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\n__all__ = ['BaseProcess', 'current_process', 'active_children',\n           'parent_process']\n\n#\n# Imports\n#\n\nimport os\nimport sys\nimport signal\nimport itertools\nimport threading\nfrom _weakrefset import WeakSet\n\n#\n#\n#\n\ntry:\n    ORIGINAL_DIR = os.path.abspath(os.getcwd())\nexcept OSError:\n    ORIGINAL_DIR = None\n\n#\n# Public functions\n#\n\ndef current_process():\n    '''\n    Return process object representing the current process\n    '''\n    return _current_process\n\ndef active_children():\n    '''\n    Return list of process objects corresponding to live child processes\n    '''\n    _cleanup()\n    return list(_children)\n\n\ndef parent_process():\n    '''\n    Return process object representing the parent process\n    '''\n    return _parent_process\n\n#\n#\n#\n\ndef _cleanup():\n    # check for processes which have finished\n    for p in list(_children):\n        if p._popen.poll() is not None:\n            _children.discard(p)\n\n#\n# The `Process` class\n#\n\nclass BaseProcess(object):\n    '''\n    Process objects represent activity that is run in a separate process\n\n    The class is analogous to `threading.Thread`\n    '''\n    def _Popen(self):\n        raise NotImplementedError\n\n    def __init__(self, group=None, target=None, name=None, args=(), kwargs={},\n                 *, daemon=None):\n        assert group is None, 'group argument must be None for now'\n        count = next(_process_counter)\n        self._identity = _current_process._identity + (count,)\n        self._config = _current_process._config.copy()\n        self._parent_pid = os.getpid()\n        self._parent_name = _current_process.name\n        self._popen = None\n        self._closed = False\n        self._target = target\n        self._args = tuple(args)\n        self._kwargs = dict(kwargs)\n        self._name = name or type(self).__name__ + '-' + \\\n                     ':'.join(str(i) for i in self._identity)\n        if daemon is not None:\n            self.daemon = daemon\n        _dangling.add(self)\n\n    def _check_closed(self):\n        if self._closed:\n            raise ValueError(\"process object is closed\")\n\n    def run(self):\n        '''\n        Method to be run in sub-process; can be overridden in sub-class\n        '''\n        if self._target:\n            self._target(*self._args, **self._kwargs)\n\n    def start(self):\n        '''\n        Start child process\n        '''\n        self._check_closed()\n        assert self._popen is None, 'cannot start a process twice'\n        assert self._parent_pid == os.getpid(), \\\n               'can only start a process object created by current process'\n        assert not _current_process._config.get('daemon'), \\\n               'daemonic processes are not allowed to have children'\n        _cleanup()\n        self._popen = self._Popen(self)\n        self._sentinel = self._popen.sentinel\n        # Avoid a refcycle if the target function holds an indirect\n        # reference to the process object (see bpo-30775)\n        del self._target, self._args, self._kwargs\n        _children.add(self)\n\n    def terminate(self):\n        '''\n        Terminate process; sends SIGTERM signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.terminate()\n\n    def kill(self):\n        '''\n        Terminate process; sends SIGKILL signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.kill()\n\n    def join(self, timeout=None):\n        '''\n        Wait until child process terminates\n        '''\n        self._check_closed()\n        assert self._parent_pid == os.getpid(), 'can only join a child process'\n        assert self._popen is not None, 'can only join a started process'\n        res = self._popen.wait(timeout)\n        if res is not None:\n            _children.discard(self)\n\n    def is_alive(self):\n        '''\n        Return whether process is alive\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return True\n        assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n        if self._popen is None:\n            return False\n\n        returncode = self._popen.poll()\n        if returncode is None:\n            return True\n        else:\n            _children.discard(self)\n            return False\n\n    def close(self):\n        '''\n        Close the Process object.\n\n        This method releases resources held by the Process object.  It is\n        an error to call this method if the child process is still running.\n        '''\n        if self._popen is not None:\n            if self._popen.poll() is None:\n                raise ValueError(\"Cannot close a process while it is still running. \"\n                                 \"You should first call join() or terminate().\")\n            self._popen.close()\n            self._popen = None\n            del self._sentinel\n            _children.discard(self)\n        self._closed = True\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        assert isinstance(name, str), 'name must be a string'\n        self._name = name\n\n    @property\n    def daemon(self):\n        '''\n        Return whether process is a daemon\n        '''\n        return self._config.get('daemon', False)\n\n    @daemon.setter\n    def daemon(self, daemonic):\n        '''\n        Set whether process is a daemon\n        '''\n        assert self._popen is None, 'process has already started'\n        self._config['daemon'] = daemonic\n\n    @property\n    def authkey(self):\n        return self._config['authkey']\n\n    @authkey.setter\n    def authkey(self, authkey):\n        '''\n        Set authorization key of process\n        '''\n        self._config['authkey'] = AuthenticationString(authkey)\n\n    @property\n    def exitcode(self):\n        '''\n        Return exit code of process or `None` if it has yet to stop\n        '''\n        self._check_closed()\n        if self._popen is None:\n            return self._popen\n        return self._popen.poll()\n\n    @property\n    def ident(self):\n        '''\n        Return identifier (PID) of process or `None` if it has yet to start\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return os.getpid()\n        else:\n            return self._popen and self._popen.pid\n\n    pid = ident\n\n    @property\n    def sentinel(self):\n        '''\n        Return a file descriptor (Unix) or handle (Windows) suitable for\n        waiting for process termination.\n        '''\n        self._check_closed()\n        try:\n            return self._sentinel\n        except AttributeError:\n            raise ValueError(\"process not started\") from None\n\n    def __repr__(self):\n        exitcode = None\n        if self is _current_process:\n            status = 'started'\n        elif self._closed:\n            status = 'closed'\n        elif self._parent_pid != os.getpid():\n            status = 'unknown'\n        elif self._popen is None:\n            status = 'initial'\n        else:\n            exitcode = self._popen.poll()\n            if exitcode is not None:\n                status = 'stopped'\n            else:\n                status = 'started'\n\n        info = [type(self).__name__, 'name=%r' % self._name]\n        if self._popen is not None:\n            info.append('pid=%s' % self._popen.pid)\n        info.append('parent=%s' % self._parent_pid)\n        info.append(status)\n        if exitcode is not None:\n            exitcode = _exitcode_to_name.get(exitcode, exitcode)\n            info.append('exitcode=%s' % exitcode)\n        if self.daemon:\n            info.append('daemon')\n        return '<%s>' % ' '.join(info)\n\n    ##\n\n    def _bootstrap(self, parent_sentinel=None):\n        from . import util, context\n        global _current_process, _parent_process, _process_counter, _children\n\n        try:\n            if self._start_method is not None:\n                context._force_start_method(self._start_method)\n            _process_counter = itertools.count(1)\n            _children = set()\n            util._close_stdin()\n            old_process = _current_process\n            _current_process = self\n            _parent_process = _ParentProcess(\n                self._parent_name, self._parent_pid, parent_sentinel)\n            if threading._HAVE_THREAD_NATIVE_ID:\n                threading.main_thread()._set_native_id()\n            try:\n                util._finalizer_registry.clear()\n                util._run_after_forkers()\n            finally:\n                # delay finalization of the old process object until after\n                # _run_after_forkers() is executed\n                del old_process\n            util.info('child process calling self.run()')\n            try:\n                self.run()\n                exitcode = 0\n            finally:\n                util._exit_function()\n        except SystemExit as e:\n            if not e.args:\n                exitcode = 1\n            elif isinstance(e.args[0], int):\n                exitcode = e.args[0]\n            else:\n                sys.stderr.write(str(e.args[0]) + '\\n')\n                exitcode = 1\n        except:\n            exitcode = 1\n            import traceback\n            sys.stderr.write('Process %s:\\n' % self.name)\n            traceback.print_exc()\n        finally:\n            threading._shutdown()\n            util.info('process exiting with exitcode %d' % exitcode)\n            util._flush_std_streams()\n\n        return exitcode\n\n#\n# We subclass bytes to avoid accidental transmission of auth keys over network\n#\n\nclass AuthenticationString(bytes):\n    def __reduce__(self):\n        from .context import get_spawning_popen\n        if get_spawning_popen() is None:\n            raise TypeError(\n                'Pickling an AuthenticationString object is '\n                'disallowed for security reasons'\n                )\n        return AuthenticationString, (bytes(self),)\n\n\n#\n# Create object representing the parent process\n#\n\nclass _ParentProcess(BaseProcess):\n\n    def __init__(self, name, pid, sentinel):\n        self._identity = ()\n        self._name = name\n        self._pid = pid\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._sentinel = sentinel\n        self._config = {}\n\n    def is_alive(self):\n        from multiprocessing.connection import wait\n        return not wait([self._sentinel], timeout=0)\n\n    @property\n    def ident(self):\n        return self._pid\n\n    def join(self, timeout=None):\n        '''\n        Wait until parent process terminates\n        '''\n        from multiprocessing.connection import wait\n        wait([self._sentinel], timeout=timeout)\n\n    pid = ident\n\n#\n# Create object representing the main process\n#\n\nclass _MainProcess(BaseProcess):\n\n    def __init__(self):\n        self._identity = ()\n        self._name = 'MainProcess'\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._config = {'authkey': AuthenticationString(os.urandom(32)),\n                        'semprefix': '/mp'}\n        # Note that some versions of FreeBSD only allow named\n        # semaphores to have names of up to 14 characters.  Therefore\n        # we choose a short prefix.\n        #\n        # On MacOSX in a sandbox it may be necessary to use a\n        # different prefix -- see #19478.\n        #\n        # Everything in self._config will be inherited by descendant\n        # processes.\n\n    def close(self):\n        pass\n\n\n_parent_process = None\n_current_process = _MainProcess()\n_process_counter = itertools.count(1)\n_children = set()\ndel _MainProcess\n\n#\n# Give names to some return codes\n#\n\n_exitcode_to_name = {}\n\nfor name, signum in list(signal.__dict__.items()):\n    if name[:3]=='SIG' and '_' not in name:\n        _exitcode_to_name[-signum] = f'-{name}'\n\n# For debug and leak testing\n_dangling = WeakSet()\n", 432], "/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py": ["import contextlib\nimport io\nimport logging\nimport os\nimport pickle\nimport time\nimport warnings\nfrom datetime import timedelta\nfrom typing import Callable, Dict, Optional, Tuple, Union\n\nimport torch\nfrom torch._C._distributed_c10d import (\n    AllreduceCoalescedOptions,\n    AllreduceOptions,\n    AllToAllOptions,\n    BarrierOptions,\n    BroadcastOptions,\n    GatherOptions,\n    PrefixStore,\n    ProcessGroup,\n    ReduceOp,\n    ReduceOptions,\n    ReduceScatterOptions,\n    ScatterOptions,\n    Store,\n    DebugLevel,\n    get_debug_level,\n)\nfrom torch._six import string_classes\n\nfrom .constants import default_pg_timeout\nfrom .rendezvous import register_rendezvous_handler, rendezvous  # noqa: F401\n\n\n# This module is wildcard imported from torch.distributed.\n# TODO: specify __all__\n\n\n_MPI_AVAILABLE = True\n_NCCL_AVAILABLE = True\n_GLOO_AVAILABLE = True\n\n_pickler = pickle.Pickler\n_unpickler = pickle.Unpickler\n\ntry:\n    from torch._C._distributed_c10d import ProcessGroupMPI\nexcept ImportError:\n    _MPI_AVAILABLE = False\n\ntry:\n    from torch._C._distributed_c10d import ProcessGroupNCCL\nexcept ImportError:\n    _NCCL_AVAILABLE = False\n\ntry:\n    from torch._C._distributed_c10d import ProcessGroupGloo\n    from torch._C._distributed_c10d import _ProcessGroupWrapper\nexcept ImportError:\n    _GLOO_AVAILABLE = False\n\n\nlogger = logging.getLogger(__name__)\n\nPG_WRAPPER_STORE_PREFIX = \"pg_wrapper\"\n\n\n# Some reduce ops are not supported by complex numbers and will result in an error.\n# We currently provide complex support to the distributed API by viewing\n# complex tensors as real (torch.view_as_real), meaning that calling\n# these unsupported ops will return garbage values rather than error out.\n# (e.g. max(2+3i, 3+2i) = 3+3i)\n# We'd like calls to unsupported ops to error out accordingly,\n# rather than returning garbage values.\ndef supports_complex(reduceOp: ReduceOp) -> bool:\n    denyList = [\n        ReduceOp.MAX,\n        ReduceOp.MIN,\n        ReduceOp.PRODUCT,\n        ReduceOp.BAND,\n        ReduceOp.BOR,\n        ReduceOp.BXOR,\n    ]\n    return reduceOp not in denyList\n\n\nclass Backend(object):\n    \"\"\"\n    An enum-like class of available backends: GLOO, NCCL, MPI, and other registered\n    backends.\n\n    The values of this class are lowercase strings, e.g., ``\"gloo\"``. They can\n    be accessed as attributes, e.g., ``Backend.NCCL``.\n\n    This class can be directly called to parse the string, e.g.,\n    ``Backend(backend_str)`` will check if ``backend_str`` is valid, and\n    return the parsed lowercase string if so. It also accepts uppercase strings,\n    e.g., ``Backend(\"GLOO\")`` returns ``\"gloo\"``.\n\n    .. note:: The entry ``Backend.UNDEFINED`` is present but only used as\n              initial value of some fields. Users should neither use it directly\n              nor assume its existence.\n    \"\"\"\n\n    UNDEFINED = \"undefined\"\n    GLOO = \"gloo\"\n    NCCL = \"nccl\"\n    MPI = \"mpi\"\n    TCP = \"tcp\"\n    _plugins: Dict[str, Callable] = {}\n\n    def __new__(cls, name: str):\n        if not isinstance(name, string_classes):\n            raise ValueError(\"Backend name must be a string, but got: {}\".format(name))\n        value = getattr(Backend, name.upper(), Backend.UNDEFINED)\n\n        if value == Backend.TCP:\n            raise ValueError(\n                \"TCP backend has been deprecated. Please use \"\n                \"Gloo or MPI backend for collective operations \"\n                \"on CPU tensors.\"\n            )\n        elif value == Backend.UNDEFINED:\n            raise ValueError(\"Invalid backend: '{}'\".format(name))\n        elif value != Backend.GLOO and value != Backend.NCCL and value != Backend.MPI:\n            value = name.lower()\n        return value\n\n    @classmethod\n    def register_backend(cls, name, func):\n        \"\"\"\n        Registers a new backend with the given name and instantiating function.\n\n        This class method is used by 3rd party ``ProcessGroup`` extension to\n        register new backends.\n\n        Args:\n            name (str): Backend name of the ``ProcessGroup`` extension. It\n                        should match the one in ``init_process_group()``.\n            func (function): Function handler that instantiates the backend.\n                             The function should be implemented in the backend\n                             extension and takes four arguments, including\n                             ``store``, ``rank``, ``world_size``, and ``timeout``.\n\n        .. note:: This support of 3rd party backend is experimental and subject to change.\n\n        \"\"\"\n        assert not hasattr(Backend, name.upper()), (\n            f\"{name.upper()} c10d backend already exist\"\n        )\n        assert name.upper() not in Backend._plugins, (\n            f\"{name.upper()} c10d backend creator function already exist\"\n        )\n\n        setattr(Backend, name.upper(), name.upper())\n        Backend._plugins[name.upper()] = func\n\n\n# `_backend`, `dist_backend`, and `reduce_op` are here to maintain backward\n# compatibility with pre-c10d distributed package.\n# TODO: remove them when users are ready to take a hard dependency on PyTorch 1.\n_backend: str = Backend.UNDEFINED\ndist_backend = Backend\n\n\nclass _reduce_op(object):\n    r\"\"\"\n    Deprecated enum-like class for reduction operations: ``SUM``, ``PRODUCT``,\n    ``MIN``, and ``MAX``.\n\n    :class:`~torch.distributed.ReduceOp` is recommended to use instead.\n    \"\"\"\n\n    def __init__(self):\n        # __members__ is a dict storing key-value pairs for enum classes\n        for k, v in ReduceOp.__members__.items():\n            setattr(self, k, v)\n        self.__members__ = ReduceOp.__members__\n\n    def __getattribute__(self, key):\n        warnings.warn(\n            \"torch.distributed.reduce_op is deprecated, please use \"\n            \"torch.distributed.ReduceOp instead\"\n        )\n        return object.__getattribute__(self, key)\n\n\nreduce_op = _reduce_op()\n\n\nclass group(object):\n    # Points to the default PG once initialized.\n    WORLD: Optional[ProcessGroup] = None\n\n\nclass GroupMember(object):\n    # Alias to group.WORLD for backward compatibility\n    WORLD = group.WORLD\n    NON_GROUP_MEMBER = object()\n\n\n# Cached process groups\n# For NCCL and GLOO pg, it is a map from ProcessGroup to (Backend, Store)\n# For MPI pg, it is a map from ProcessGroup to (Backend, None)\n_pg_map: Dict[ProcessGroup, Tuple[str, Optional[Store]]] = {}\n# Process group's names, map from ProcessGroup to str\n_pg_names: Dict[ProcessGroup, str] = {}\n# Process group's global rank to local rank mapping\n_pg_group_ranks: Dict[ProcessGroup, Dict[int, int]] = {}\n\n# Default process group state\n_default_pg_init_method = None\n\n# Process group count for default naming\n_group_count = 0\n\nSTORE_BASED_BARRIER_PREFIX = \"store_based_barrier_key\"\n\n\ndef _store_based_barrier(rank, store, timeout):\n    \"\"\"\n    Barrier based on store which is used for synchronizing processes after\n    ``init_process_group`` or ``new_group``. Intended to be used only with\n    those two methods and is not a generic alternative to ``barrier()``.\n    \"\"\"\n    store_key = \"{}:{}\".format(STORE_BASED_BARRIER_PREFIX, _group_count)\n    store.add(store_key, 1)\n    logger.info(\"Added key: {} to store for rank: {}\".format(store_key, rank))\n\n    # Now wait for all workers to check in with the store.\n    world_size = get_world_size()\n    # Use 'add' instead of 'get' since for some store implementations 'add'\n    # doesn't work well with 'get'. Ideally the store implementations should\n    # be fixed, but for backward compatiblity reasons it is risky to change\n    # the store implementations. Once, we completely migrate away from these\n    # legacy stores, we can use 'get' here instead.\n    worker_count = store.add(store_key, 0)\n    start = time.time()\n    log_time = time.time()\n    while worker_count != world_size:\n        time.sleep(0.01)\n        worker_count = store.add(store_key, 0)\n\n        # Print status periodically to keep track.\n        if timedelta(seconds=(time.time() - log_time)) > timedelta(seconds=10):\n            logger.info(\n                \"Waiting in store based barrier to initialize process group for \"\n                \"rank: {}, key: {} (world_size={}, worker_count={}, timeout={})\".format(\n                    rank, store_key, world_size, worker_count, timeout\n                )\n            )\n            log_time = time.time()\n\n        if timedelta(seconds=(time.time() - start)) > timeout:\n            raise RuntimeError(\n                \"Timed out initializing process group in store based barrier on \"\n                \"rank: {}, for key: {} (world_size={}, worker_count={}, timeout={})\".format(\n                    rank, store_key, world_size, worker_count, timeout\n                )\n            )\n\n    logger.info(\n        f\"Rank {rank}: Completed store-based barrier for key:{store_key} with {world_size} nodes.\"\n    )\n\n\ndef _rank_not_in_group(group: ProcessGroup):\n    \"\"\"\n    Helper that checks if the current process's rank is not in a given group.\n    \"\"\"\n    if group is None:\n        return False\n    return group == GroupMember.NON_GROUP_MEMBER\n\n\ndef _warn_not_in_group(op_name):\n    global_rank = -1 if GroupMember.WORLD is None else GroupMember.WORLD.rank()\n    warnings.warn(\n        f\"Running {op_name} on global rank {global_rank} which does not \"\n        \"belong to the given group.\"\n    )\n\n\ndef _get_group_rank(group: ProcessGroup, rank):\n    \"\"\"\n    Helper that gets a given group's local rank in the group from a given global\n    rank.\n    \"\"\"\n    if group is GroupMember.WORLD:\n        raise RuntimeError(\n            \"group.WORLD does not have local rank to global \" \"rank mapping\"\n        )\n    if group not in _pg_group_ranks:\n        raise RuntimeError(\"The given group does not exist\")\n    try:\n        group_rank = _pg_group_ranks[group][rank]\n    except KeyError:\n        raise RuntimeError(\n            f\"The global rank {rank} is not part of the group {group}\"\n        ) from None\n    return group_rank\n\n\ndef _get_global_rank(group, group_rank):\n    \"\"\"\n    Helper that gets a given group's global rank from a given local rank in the\n    group.\n    \"\"\"\n    if group is GroupMember.WORLD:\n        raise RuntimeError(\n            \"group.WORLD does not have local rank to global \" \"rank mapping\"\n        )\n    group_rank_map = _pg_group_ranks[group]\n    for rank, grp_rank in group_rank_map.items():\n        if grp_rank == group_rank:\n            return rank\n    raise RuntimeError(\"The group rank is not part of the group\")\n\n\ndef _get_group_size(group):\n    \"\"\"\n    Helper that gets a given group's world size.\n    \"\"\"\n    if group is GroupMember.WORLD or group is None:\n        default_pg = _get_default_group()\n        return default_pg.size()\n    return group.size()\n\n\ndef _check_single_tensor(param, param_name):\n    \"\"\"\n    Helper to check that the parameter ``param_name`` is a single tensor.\n    \"\"\"\n    if not isinstance(param, torch.Tensor):\n        raise RuntimeError(\n            \"Invalid function argument. Expected parameter `{}` \"\n            \"to be of type torch.Tensor.\".format(param_name)\n        )\n\n\ndef _check_tensor_list(param, param_name):\n    \"\"\"\n    Helper to check that the parameter ``param_name`` is a list of tensors.\n    \"\"\"\n    if not isinstance(param, list) or not all(\n        isinstance(p, torch.Tensor) for p in param\n    ):\n        raise RuntimeError(\n            \"Invalid function argument. Expected parameter `{}` \"\n            \"to be of type List[torch.Tensor].\".format(param_name)\n        )\n\n\ndef _check_op(op):\n    \"\"\"\n    Helper to check that the ``op`` is either isend or irecv.\n    \"\"\"\n    if op not in [isend, irecv]:\n        raise RuntimeError(\n            \"Invalid ``op``. Expected ``op`` \"\n            \"to be of type ``torch.distributed.isend`` or \"\n            \"``torch.distributed.irecv``.\"\n        )\n\n\ndef _check_p2p_op_list(p2p_op_list):\n    \"\"\"\n    Helper to check that the ``p2p_op_list`` is a list of P2POp instances and\n    all ops use the same backend.\n    \"\"\"\n    if not isinstance(p2p_op_list, list) or not all(\n        isinstance(p2p_op, P2POp) for p2p_op in p2p_op_list\n    ):\n        raise RuntimeError(\n            \"Invalid ``p2p_op_list``. Each op is expected to \"\n            \"to be of type ``torch.distributed.P2POp``.\"\n        )\n\n    backend = get_backend(p2p_op_list[0].group)\n    if not all(backend == get_backend(p2p_op.group) for p2p_op in p2p_op_list):\n        raise RuntimeError(\"All groups need to use the same backend.\")\n\n\ndef is_mpi_available():\n    \"\"\"\n    Checks if the MPI backend is available.\n    \"\"\"\n    return _MPI_AVAILABLE\n\n\ndef is_nccl_available():\n    \"\"\"\n    Checks if the NCCL backend is available.\n    \"\"\"\n    return _NCCL_AVAILABLE\n\n\ndef is_gloo_available():\n    \"\"\"\n    Checks if the Gloo backend is available.\n    \"\"\"\n    return _GLOO_AVAILABLE\n\n\ndef is_initialized():\n    \"\"\"\n    Checking if the default process group has been initialized\n    \"\"\"\n    return GroupMember.WORLD is not None\n\n\ndef is_torchelastic_launched():\n    \"\"\"\n    Checks whether this process was launched with ``torch.distributed.elastic``\n    (aka torchelastic). The existence of ``TORCHELASTIC_RUN_ID`` environment\n    variable is used as a proxy to determine whether the current process\n    was launched with torchelastic. This is a reasonable proxy since\n    ``TORCHELASTIC_RUN_ID`` maps to the rendezvous id which is always a\n    non-null value indicating the job id for peer discovery purposes..\n    \"\"\"\n    return os.getenv(\"TORCHELASTIC_RUN_ID\") is not None\n\n\ndef _get_default_group():\n    \"\"\"\n    Getting the default process group created by init_process_group\n    \"\"\"\n    if not is_initialized():\n        raise RuntimeError(\n            \"Default process group has not been initialized, \"\n            \"please make sure to call init_process_group.\"\n        )\n    return GroupMember.WORLD\n\n\ndef _get_default_store():\n    \"\"\"\n    Getting the default store created by init_process_group\n    \"\"\"\n    if not is_initialized():\n        raise RuntimeError(\n            \"Default process group has not been initialized, \"\n            \"please make sure to call init_process_group.\"\n        )\n    default_pg = _get_default_group()\n    _, default_store = _pg_map[default_pg]\n    return default_store\n\n\ndef _update_default_pg(pg):\n    GroupMember.WORLD = group.WORLD = pg\n\n\ndef get_backend(group=None):\n    \"\"\"\n    Returns the backend of the given process group.\n\n    Args:\n        group (ProcessGroup, optional): The process group to work on. The\n            default is the general main process group. If another specific group\n            is specified, the calling process must be part of :attr:`group`.\n\n    Returns:\n        The backend of the given process group as a lower case string.\n\n    \"\"\"\n    if group is None:\n        pg = _get_default_group()\n    else:\n        pg = group\n    if _rank_not_in_group(pg):\n        raise RuntimeError(\"Invalid process group specified\")\n    pg_store = _pg_map.get(pg, None)\n    assert pg_store is not None\n    return pg_store[0]\n\n\ndef init_process_group(\n    backend,\n    init_method=None,\n    timeout=default_pg_timeout,\n    world_size=-1,\n    rank=-1,\n    store=None,\n    group_name=\"\",\n    pg_options=None,\n):\n    \"\"\"\n    Initializes the default distributed process group, and this will also\n    initialize the distributed package.\n\n    There are 2 main ways to initialize a process group:\n        1. Specify ``store``, ``rank``, and ``world_size`` explicitly.\n        2. Specify ``init_method`` (a URL string) which indicates where/how\n           to discover peers. Optionally specify ``rank`` and ``world_size``,\n           or encode all required parameters in the URL and omit them.\n\n    If neither is specified, ``init_method`` is assumed to be \"env://\".\n\n\n    Args:\n        backend (str or Backend): The backend to use. Depending on\n            build-time configurations, valid values include ``mpi``, ``gloo``,\n            and ``nccl``. This field should be given as a lowercase string\n            (e.g., ``\"gloo\"``), which can also be accessed via\n            :class:`Backend` attributes (e.g., ``Backend.GLOO``). If using\n            multiple processes per machine with ``nccl`` backend, each process\n            must have exclusive access to every GPU it uses, as sharing GPUs\n            between processes can result in deadlocks.\n        init_method (str, optional): URL specifying how to initialize the\n                                     process group. Default is \"env://\" if no\n                                     ``init_method`` or ``store`` is specified.\n                                     Mutually exclusive with ``store``.\n        world_size (int, optional): Number of processes participating in\n                                    the job. Required if ``store`` is specified.\n        rank (int, optional): Rank of the current process (it should be a\n                              number between 0 and ``world_size``-1).\n                              Required if ``store`` is specified.\n        store(Store, optional): Key/value store accessible to all workers, used\n                                to exchange connection/address information.\n                                Mutually exclusive with ``init_method``.\n        timeout (timedelta, optional): Timeout for operations executed against\n            the process group. Default value equals 30 minutes.\n            This is applicable for the ``gloo`` backend. For ``nccl``, this is\n            applicable only if the environment variable ``NCCL_BLOCKING_WAIT``\n            or ``NCCL_ASYNC_ERROR_HANDLING`` is set to 1. When\n            ``NCCL_BLOCKING_WAIT`` is set, this is the duration for which the\n            process will block and wait for collectives to complete before\n            throwing an exception. When ``NCCL_ASYNC_ERROR_HANDLING`` is set,\n            this is the duration after which collectives will be aborted\n            asynchronously and the process will crash. ``NCCL_BLOCKING_WAIT``\n            will provide errors to the user which can be caught and handled,\n            but due to its blocking nature, it has a performance overhead. On\n            the other hand, ``NCCL_ASYNC_ERROR_HANDLING`` has very little\n            performance overhead, but crashes the process on errors. This is\n            done since CUDA execution is async and it is no longer safe to\n            continue executing user code since failed async NCCL operations\n            might result in subsequent CUDA operations running on corrupted\n            data. Only one of these two environment variables should be set.\n        group_name (str, optional, deprecated): Group name.\n        pg_options (ProcessGroupOptions, optional): process group options\n            specifying what additional options need to be passed in during\n            the construction of specific process groups. As of now, the only\n            options we support is ``ProcessGroupNCCL.Options`` for the ``nccl``\n            backend, ``is_high_priority_stream`` can be specified so that\n            the nccl backend can pick up high priority cuda streams when\n            there're compute kernels waiting.\n\n    .. note:: To enable ``backend == Backend.MPI``, PyTorch needs to be built from source\n        on a system that supports MPI.\n\n    \"\"\"\n    global _pg_group_ranks\n    global _backend\n    global _default_pg_init_method\n\n    if not isinstance(timeout, timedelta):\n        raise RuntimeError(\n            \"Expected timeout argument to be of type\" \"datetime.timedelta\"\n        )\n\n    if GroupMember.WORLD is not None:\n        raise RuntimeError(\"trying to initialize the default process group \" \"twice!\")\n\n    assert (store is None) or (\n        init_method is None\n    ), \"Cannot specify both init_method and store.\"\n\n    if store is not None:\n        assert world_size > 0, \"world_size must be positive if using store\"\n        assert rank >= 0, \"rank must be non-negative if using store\"\n    elif init_method is None:\n        init_method = \"env://\"\n\n    backend = Backend(backend)\n\n    if backend == Backend.MPI:\n        if world_size != -1 or rank != -1:\n            warnings.warn(\n                \"For MPI backend, world_size ({}) and rank ({}) \"\n                \"are ignored since they are assigned by the \"\n                \"MPI runtime.\".format(world_size, rank)\n            )\n\n        default_pg = _new_process_group_helper(\n            -1, -1, [], Backend.MPI, None, group_name=group_name, timeout=timeout\n        )\n        _update_default_pg(default_pg)\n    else:\n        # backward compatible API\n        if store is None:\n            rendezvous_iterator = rendezvous(\n                init_method, rank, world_size, timeout=timeout\n            )\n            store, rank, world_size = next(rendezvous_iterator)\n            store.set_timeout(timeout)\n\n            # Use a PrefixStore to avoid accidental overrides of keys used by\n            # different systems (e.g. RPC) in case the store is multi-tenant.\n            store = PrefixStore(\"default_pg\", store)\n\n        default_pg = _new_process_group_helper(\n            world_size,\n            rank,\n            [],\n            backend,\n            store,\n            pg_options=pg_options,\n            group_name=group_name,\n            timeout=timeout,\n        )\n        _update_default_pg(default_pg)\n\n    _pg_group_ranks[GroupMember.WORLD] = {i: i for i in range(GroupMember.WORLD.size())}  # type: ignore[attr-defined, index]\n    _backend = _pg_map[GroupMember.WORLD][0]  # type: ignore[index]\n    _default_pg_init_method = init_method\n\n    # barrier at the end to ensure that once we return from this method, all\n    # process groups including global variables are updated correctly on all\n    # ranks.\n    if backend == Backend.MPI:\n        # MPI backend doesn't use store.\n        barrier()\n    else:\n        # Use store based barrier here since barrier() used a bunch of\n        # default devices and messes up NCCL internal state.\n        _store_based_barrier(rank, store, timeout)\n        # Set sequence numbers for gloo and nccl process groups.\n        if get_backend(default_pg) in [Backend.GLOO, Backend.NCCL]:\n            default_pg._set_sequence_number_for_group()\n\n\ndef _new_process_group_helper(\n    world_size,\n    rank,\n    group_ranks,\n    backend,\n    store,\n    pg_options=None,\n    group_name=None,\n    timeout=default_pg_timeout,\n):\n    \"\"\"\n    Create a new distributed process group.\n\n    This function must be called by ALL processes in the global group, even if\n    the calling process is not part of the newly created group. In that case,\n    this function returns GroupMember.NON_GROUP_MEMBER.\n\n    This function is called with ``group_ranks == []`` for the default group.\n    \"\"\"\n    global _pg_map\n    global _group_count\n    global _pg_names\n\n    if not group_name:\n        group_name = str(_group_count)\n        _group_count += 1\n\n    if group_name in _pg_names.values():\n        raise RuntimeError(\n            \"The specified group name has already been \"\n            \"created, please use a different group name\"\n        )\n\n    if not isinstance(timeout, timedelta):\n        raise RuntimeError(\n            \"Expected timeout argument to be of type\" \"datetime.timedelta\"\n        )\n\n    # The list of group ranks is empty if we're creating the default group.\n    is_default_group = len(group_ranks) == 0\n\n    backend = Backend(backend)\n    pg: Union[ProcessGroupGloo, ProcessGroupMPI, ProcessGroupNCCL]\n    if backend == Backend.MPI:\n        if not is_mpi_available():\n            raise RuntimeError(\n                \"Distributed package doesn't have MPI built in.\"\n                \" MPI is only included if you build PyTorch from\"\n                \" source on a host that has MPI installed.\"\n            )\n        pg = ProcessGroupMPI.create(group_ranks)\n        if not pg:\n            return GroupMember.NON_GROUP_MEMBER\n        _pg_map[pg] = (Backend.MPI, None)\n        _pg_names[pg] = group_name\n    else:\n        # If this is a subgroup (which means group_ranks is specified),\n        # we check if the current process is a member of the new group.\n        if not is_default_group:\n            global_rank = _get_default_group().rank()\n            if global_rank not in group_ranks:\n                return GroupMember.NON_GROUP_MEMBER\n\n        # Use the group name as prefix in the default store, such that\n        # a single store can be reused by multiple groups.\n        prefix_store = PrefixStore(group_name, store)\n\n        if backend == Backend.GLOO:\n            if pg_options is not None:\n                raise RuntimeError(\"GLOO options not supported\")\n            pg = ProcessGroupGloo(prefix_store, rank, world_size, timeout=timeout)\n            # In debug mode and if GLOO is available, wrap in a wrapper PG that\n            # enables enhanced collective checking for debugability.\n            if get_debug_level() == DebugLevel.DETAIL:\n                if not _GLOO_AVAILABLE:\n                    logger.info(\n                        \"\"\"TORCH_DISTRIBUTED_DEBUG was set to DETAIL, but\n                                GLOO is not available. Build with Gloo to\n                                create a wrapper process group in debug mode\n                                to aid collective desynchronization debugging.\"\"\"\n                    )\n                else:\n                    pg = _create_process_group_wrapper(\n                        wrapped_pg=pg,\n                        store_prefix=group_name,\n                        store=store,\n                        rank=rank,\n                        world_size=world_size,\n                        timeout=timeout,\n                    )\n            _pg_map[pg] = (Backend.GLOO, store)\n            _pg_names[pg] = group_name\n        elif backend == Backend.NCCL:\n            if not is_nccl_available():\n                raise RuntimeError(\"Distributed package doesn't have NCCL \" \"built in\")\n            if pg_options is not None:\n                assert isinstance(\n                    pg_options, ProcessGroupNCCL.Options\n                ), \"Expected pg_options argument to be of type ProcessGroupNCCL.Options\"\n            else:\n                # default pg_options for NCCL\n                pg_options = ProcessGroupNCCL.Options()\n                pg_options.is_high_priority_stream = False\n                pg_options._timeout = timeout\n\n            pg = ProcessGroupNCCL(prefix_store, rank, world_size, pg_options)\n            # In debug mode and if GLOO is available, wrap in a wrapper PG that\n            # enables enhanced collective checking for debugability.\n            if get_debug_level() == DebugLevel.DETAIL:\n                if not _GLOO_AVAILABLE:\n                    logger.info(\n                        \"\"\"TORCH_DISTRIBUTED_DEBUG was set to DETAIL, but\n                                GLOO is not available. Build with Gloo to\n                                create a wrapper process group in debug mode\n                                to aid collective desynchronization debugging.\"\"\"\n                    )\n                else:\n                    pg = _create_process_group_wrapper(\n                        wrapped_pg=pg,\n                        store_prefix=group_name,\n                        store=store,\n                        rank=rank,\n                        world_size=world_size,\n                        timeout=timeout,\n                    )\n            _pg_map[pg] = (Backend.NCCL, store)\n            _pg_names[pg] = group_name\n        else:\n            assert backend.upper() in Backend._plugins, (\n                f\"unknown c10d backend type {backend.upper()}\"\n            )\n            pg = Backend._plugins[backend.upper()](\n                prefix_store, rank, world_size, timeout\n            )\n            _pg_map[pg] = (backend, store)\n            _pg_names[pg] = group_name\n\n    return pg\n\n\ndef destroy_process_group(group=None):\n    \"\"\"\n    Destroy a given process group, and deinitialize the distributed package\n\n    Args:\n        group (ProcessGroup, optional): The process group to be destroyed, if\n                                        group.WORLD is given, all process\n                                        groups including the default one will\n                                        be destroyed.\n    \"\"\"\n    global _pg_map\n    global _pg_names\n    global _pg_group_ranks\n    global _default_pg_init_method\n    global _group_count\n\n    if group == GroupMember.NON_GROUP_MEMBER:\n        return\n\n    if group is None:\n        pg = GroupMember.WORLD\n    else:\n        pg = group\n\n    assert pg is not None\n    if _pg_map.get(pg, None) is None:\n        raise RuntimeError(\"Invalid process group specified\")\n\n    if group is None or group == GroupMember.WORLD:\n        _update_default_pg(None)\n        _default_pg_init_method = None\n        _pg_map.clear()\n        _pg_names.clear()\n        _pg_group_ranks.clear()\n\n        # when process group doesn't have an explicit name (only WORLD (default)\n        # process group can have an explicit name), we use global _group_counter\n        # to generate the name. We need to reset the counter on destruction to\n        # allow consistent value to be generated when we re-create process\n        # groups after some trainers recover from failure\n        #\n        # We only reset this when WORLD is being destroyed because if this\n        # process group is in good state, we aren't dealing with failures.\n        _group_count = 0\n    else:\n        del _pg_map[pg]\n        del _pg_names[pg]\n        del _pg_group_ranks[pg]\n\n\ndef get_rank(group=None):\n    \"\"\"\n    Returns the rank of the current process in the provided ``group`` or the\n    default group if none was provided.\n\n    Rank is a unique identifier assigned to each process within a distributed\n    process group. They are always consecutive integers ranging from 0 to\n    ``world_size``.\n\n    Args:\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n\n    Returns:\n        The rank of the process group\n        -1, if not part of the group\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        return -1\n\n    default_pg = _get_default_group()\n    if group is None or group is GroupMember.WORLD:\n        return default_pg.rank()\n\n    return _get_group_rank(group, default_pg.rank())\n\n\ndef get_world_size(group=None):\n    \"\"\"\n    Returns the number of processes in the current process group\n\n    Args:\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n\n    Returns:\n        The world size of the process group\n        -1, if not part of the group\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        return -1\n\n    return _get_group_size(group)\n\n\ndef isend(tensor, dst, group=None, tag=0):\n    \"\"\"\n    Sends a tensor asynchronously.\n\n    .. warning::\n        Modifying ``tensor`` before the request completes causes undefined\n        behavior.\n\n    Args:\n        tensor (Tensor): Tensor to send.\n        dst (int): Destination rank.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        tag (int, optional): Tag to match send with remote recv\n\n    Returns:\n        A distributed request object.\n        None, if not part of the group\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"isend\")\n        return\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        return default_pg.send([tensor], dst, tag)\n    else:\n        group_dst_rank = _get_group_rank(group, dst)\n        return group.send([tensor], group_dst_rank, tag)\n\n\ndef irecv(tensor, src=None, group=None, tag=0):\n    \"\"\"\n    Receives a tensor asynchronously.\n\n    Args:\n        tensor (Tensor): Tensor to fill with received data.\n        src (int, optional): Source rank. Will receive from any\n            process if unspecified.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        tag (int, optional): Tag to match recv with remote send\n\n    Returns:\n        A distributed request object.\n        None, if not part of the group\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"irecv\")\n        return\n\n    if group is None or group is GroupMember.WORLD:\n        pg = _get_default_group()\n    else:\n        pg = group\n\n    if src is None:\n        return pg.recv_anysource([tensor], tag)\n    else:\n        if pg is GroupMember.WORLD:\n            return pg.recv([tensor], src, tag)\n        else:\n            group_src_rank = _get_group_rank(pg, src)\n            return pg.recv([tensor], group_src_rank, tag)\n\n\ndef send(tensor, dst, group=None, tag=0):\n    \"\"\"\n    Sends a tensor synchronously.\n\n    Args:\n        tensor (Tensor): Tensor to send.\n        dst (int): Destination rank.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        tag (int, optional): Tag to match send with remote recv\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"send\")\n        return\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        default_pg.send([tensor], dst, tag).wait()\n    else:\n        group_dst_rank = _get_group_rank(group, dst)\n        group.send([tensor], group_dst_rank, tag).wait()\n\n\ndef recv(tensor, src=None, group=None, tag=0):\n    \"\"\"\n    Receives a tensor synchronously.\n\n    Args:\n        tensor (Tensor): Tensor to fill with received data.\n        src (int, optional): Source rank. Will receive from any\n            process if unspecified.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        tag (int, optional): Tag to match recv with remote send\n\n    Returns:\n        Sender rank\n        -1, if not part of the group\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"recv\")\n        return -1\n\n    if group is None:\n        pg = _get_default_group()\n    else:\n        pg = group\n\n    if src is None:\n        work = pg.recv_anysource([tensor], tag)\n        work.wait()\n        src_rank = work._source_rank()\n        if group is None or group is GroupMember.WORLD:\n            return src_rank\n        else:\n            return _get_global_rank(pg, src_rank)\n    else:\n        if group is None or group is GroupMember.WORLD:\n            pg.recv([tensor], src, tag).wait()\n        else:\n            group_src_rank = _get_group_rank(pg, src)\n            pg.recv([tensor], group_src_rank, tag).wait()\n        return src\n\n\nclass P2POp(object):\n    \"\"\"\n    A class to build point-to-point operations for ``batch_isend_irecv``.\n\n    This class builds the type of P2P operation, communication buffer, peer rank,\n    Process Group group, and tag. Instances of this class will be passed to\n    ``batch_isend_irecv`` for point-to-point communications.\n\n    Args:\n        op (callable): A function to send data to or receive data from a peer process.\n            The type of ``op`` is either ``torch.distributed.isend`` or\n            ``torch.distributed.irecv``.\n        tensor (Tensor): Tensor to send or receive.\n        peer (int): Destination or source rank.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        tag (int, optional): Tag to match send with recv.\n    \"\"\"\n\n    def __init__(self, op, tensor, peer, group=None, tag=0):\n        self.op = op\n        self.tensor = tensor\n        self.peer = peer\n        self.group = group\n        self.tag = tag\n\n    def __new__(cls, op, tensor, peer, group=None, tag=0):\n        _check_op(op)\n        _check_single_tensor(tensor, \"tensor\")\n        return object.__new__(cls)\n\n\n@contextlib.contextmanager\ndef _batch_p2p_manager(backend):\n    if backend == Backend.NCCL:\n        ProcessGroupNCCL._group_start()\n    try:\n        yield\n    finally:\n        if backend == Backend.NCCL:\n            ProcessGroupNCCL._group_end()\n\n\ndef batch_isend_irecv(p2p_op_list):\n    \"\"\"\n    Send or Receive a batch of tensors asynchronously and return a list of requests.\n\n    Process each of the operations in p2p_op_list and return the corresponding\n    requests. NCCL and Gloo backend are currently supported.\n\n    Args:\n        p2p_op_list: A list of point-to-point operations(type of each operator is\n            ``torch.distributed.P2POp``). The order of the isend/irecv in the list\n            matters and it needs to match with corresponding isend/irecv on the\n            remote end.\n\n    Returns:\n        A list of distributed request objects returned by calling the corresponding\n        op in the op_list.\n\n    Examples:\n        >>> send_tensor = torch.arange(2) + 2 * rank\n        >>> recv_tensor = torch.randn(2)\n        >>> send_op = dist.P2POp(dist.isend, send_tensor, (rank + 1)%world_size)\n        >>> recv_op = dist.P2POp(dist.irecv, recv_tensor, (rank + 1)%world_size)\n        >>> reqs = batch_isend_irecv([send_op, recv_op])\n        >>> for req in reqs:\n        >>>     req.wait()\n        >>> recv_tensor\n        tensor([2, 3])     # Rank 0\n        tensor([0, 1])     # Rank 1\n\n    .. note:: Note that when this API is used with the NCCL PG backend, users must set\n        the current GPU device with `torch.cuda.set_device`, otherwise it will\n        lead to unexpected hang issues.\n    \"\"\"\n    _check_p2p_op_list(p2p_op_list)\n    backend = get_backend(p2p_op_list[0].group)\n    reqs = []\n    with _batch_p2p_manager(backend):\n        for p2p_op in p2p_op_list:\n            op = p2p_op.op\n            tensor = p2p_op.tensor\n            peer = p2p_op.peer\n            curr_group = p2p_op.group\n            tag = p2p_op.tag\n\n            ret = op(tensor, peer, curr_group, tag)\n\n            if ret is not None:\n                reqs.append(ret)\n    return reqs\n\n\ndef broadcast_multigpu(tensor_list, src, group=None, async_op=False, src_tensor=0):\n    \"\"\"\n    Broadcasts the tensor to the whole group with multiple GPU tensors\n    per node.\n\n    ``tensor`` must have the same number of elements in all the GPUs from\n    all processes participating in the collective. each tensor in the list must\n    be on a different GPU\n\n    Only nccl and gloo backend are currently supported\n    tensors should only be GPU tensors\n\n    Args:\n        tensor_list (List[Tensor]): Tensors that participate in the collective\n            operation. If ``src`` is the rank, then the specified ``src_tensor``\n            element of ``tensor_list`` (``tensor_list[src_tensor]``) will be\n            broadcast to all other tensors (on different GPUs) in the src process\n            and all tensors in ``tensor_list`` of other non-src processes.\n            You also need to make sure that ``len(tensor_list)`` is the same\n            for all the distributed processes calling this function.\n\n        src (int): Source rank.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n        src_tensor (int, optional): Source tensor rank within ``tensor_list``\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"broadcast_multigpu\")\n        return\n\n    opts = BroadcastOptions()\n    opts.rootRank = src\n    opts.rootTensor = src_tensor\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        work = default_pg.broadcast(tensor_list, opts)\n    else:\n        group_src_rank = _get_group_rank(group, src)\n        opts.rootRank = group_src_rank\n        work = group.broadcast(tensor_list, opts)\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef broadcast(tensor, src, group=None, async_op=False):\n    \"\"\"\n    Broadcasts the tensor to the whole group.\n\n    ``tensor`` must have the same number of elements in all processes\n    participating in the collective.\n\n    Args:\n        tensor (Tensor): Data to be sent if ``src`` is the rank of current\n            process, and tensor to be used to save received data otherwise.\n        src (int): Source rank.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"broadcast\")\n        return\n\n    opts = BroadcastOptions()\n    opts.rootRank = src\n    opts.rootTensor = 0\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        work = default_pg.broadcast([tensor], opts)\n    else:\n        group_src_rank = _get_group_rank(group, src)\n        opts.rootRank = group_src_rank\n        work = group.broadcast([tensor], opts)\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef all_reduce_multigpu(tensor_list, op=ReduceOp.SUM, group=None, async_op=False):\n    r\"\"\"\n    Reduces the tensor data across all machines in such a way that all get\n    the final result. This function reduces a number of tensors on every node,\n    while each tensor resides on different GPUs.\n    Therefore, the input tensor in the tensor list needs to be GPU tensors.\n    Also, each tensor in the tensor list needs to reside on a different GPU.\n\n    After the call, all ``tensor`` in ``tensor_list`` is going to be bitwise\n    identical in all processes.\n\n    Complex tensors are supported.\n\n    Only nccl and gloo backend is currently supported\n    tensors should only be GPU tensors\n\n    Args:\n        tensor_list (List[Tensor]): List of input and output tensors of\n            the collective. The function operates in-place and requires that\n            each tensor to be a GPU tensor on different GPUs.\n            You also need to make sure that ``len(tensor_list)`` is the same for\n            all the distributed processes calling this function.\n        op (optional): One of the values from\n            ``torch.distributed.ReduceOp``\n            enum.  Specifies an operation used for element-wise reductions.\n        group (ProcessGroup, optional): The process group to work on. If\n            ``None``, the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        return\n\n    tensor_list = [\n        t if not t.is_complex() else torch.view_as_real(t) for t in tensor_list\n    ]\n\n    opts = AllreduceOptions()\n    opts.reduceOp = op\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.allreduce(tensor_list, opts)\n    else:\n        work = group.allreduce(tensor_list, opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef all_reduce(tensor, op=ReduceOp.SUM, group=None, async_op=False):\n    \"\"\"\n    Reduces the tensor data across all machines in such a way that all get\n    the final result.\n\n    After the call ``tensor`` is going to be bitwise identical in all processes.\n\n    Complex tensors are supported.\n\n    Args:\n        tensor (Tensor): Input and output of the collective. The function\n            operates in-place.\n        op (optional): One of the values from\n            ``torch.distributed.ReduceOp``\n            enum.  Specifies an operation used for element-wise reductions.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    Examples:\n        >>> # All tensors below are of torch.int64 type.\n        >>> # We have 2 process groups, 2 ranks.\n        >>> tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank\n        >>> tensor\n        tensor([1, 2]) # Rank 0\n        tensor([3, 4]) # Rank 1\n        >>> dist.all_reduce(tensor, op=ReduceOp.SUM)\n        >>> tensor\n        tensor([4, 6]) # Rank 0\n        tensor([4, 6]) # Rank 1\n\n        >>> # All tensors below are of torch.cfloat type.\n        >>> # We have 2 process groups, 2 ranks.\n        >>> tensor = torch.tensor([1+1j, 2+2j], dtype=torch.cfloat) + 2 * rank * (1+1j)\n        >>> tensor\n        tensor([1.+1.j, 2.+2.j]) # Rank 0\n        tensor([3.+3.j, 4.+4.j]) # Rank 1\n        >>> dist.all_reduce(tensor, op=ReduceOp.SUM)\n        >>> tensor\n        tensor([4.+4.j, 6.+6.j]) # Rank 0\n        tensor([4.+4.j, 6.+6.j]) # Rank 1\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_reduce\")\n        return\n\n    if tensor.is_complex():\n        if not supports_complex(op):\n            raise RuntimeError(f\"all_reduce does not support {op} on complex tensors\")\n        tensor = torch.view_as_real(tensor)\n\n    opts = AllreduceOptions()\n    opts.reduceOp = op\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.allreduce([tensor], opts)\n    else:\n        work = group.allreduce([tensor], opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef all_reduce_coalesced(tensors, op=ReduceOp.SUM, group=None, async_op=False):\n    \"\"\"\n    WARNING: at this time individual shape checking is not implemented across nodes.\n    For example, if the rank 0 node passes [torch.rand(4), torch.rand(2)] and the\n    rank 1 node passes [torch.rand(2), torch.rand(2), torch.rand(2)], the allreduce\n    operation will proceed without complaint and return erroneous outputs. This lack\n    of shape checking results in significant performance improvements but users of this\n    function should take extra care to ensure that each node passes in tensors whose\n    shapes match across nodes.\n\n    Reduces each tensor in tensors (residing on the same device) across all machines\n    in such a way that all get the final result.\n\n    After the call each tensor in tensors is going to bitwise identical\n    in all processes.\n\n    Complex tensors are supported.\n\n    Args:\n        tensors (List[Tensor]): Input and output of the collective. The function\n            operates in-place.\n        op (Optional[ReduceOp]): One of the values from\n            ``torch.distributed.ReduceOp`` enum. Specifies an operation used for\n            element-wise reductions.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (Optional[bool]): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group.\n\n    \"\"\"\n    _check_tensor_list(tensors, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_reduce_coalesced\")\n        return\n\n    if any([t.is_complex() for t in tensors]) and not supports_complex(op):\n        raise RuntimeError(f\"all_reduce does not support {op} on complex tensors\")\n\n    tensors = [t if not t.is_complex() else torch.view_as_real(t) for t in tensors]\n\n    opts = AllreduceCoalescedOptions()\n    opts.reduceOp = op\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.allreduce_coalesced(tensors, opts)\n    else:\n        work = group.allreduce_coalesced(tensors, opts)\n\n    if async_op:\n        return work.get_future()\n    else:\n        work.wait()\n\n\ndef reduce_multigpu(\n    tensor_list, dst, op=ReduceOp.SUM, group=None, async_op=False, dst_tensor=0\n):\n    \"\"\"\n    Reduces the tensor data on multiple GPUs across all machines. Each tensor\n    in ``tensor_list`` should reside on a separate GPU\n\n    Only the GPU of ``tensor_list[dst_tensor]`` on the process with rank ``dst``\n    is going to receive the final result.\n\n    Only nccl backend is currently supported\n    tensors should only be GPU tensors\n\n    Args:\n        tensor_list (List[Tensor]): Input and output GPU tensors of the\n            collective. The function operates in-place.\n            You also need to make sure that ``len(tensor_list)`` is the same for\n            all the distributed processes calling this function.\n        dst (int): Destination rank\n        op (optional): One of the values from\n            ``torch.distributed.ReduceOp``\n            enum.  Specifies an operation used for element-wise reductions.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n        dst_tensor (int, optional): Destination tensor rank within\n                                    ``tensor_list``\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, otherwise\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"reduce_multigpu\")\n        return\n\n    opts = ReduceOptions()\n    opts.reduceOp = op\n    opts.rootRank = dst\n    opts.rootTensor = dst_tensor\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        work = default_pg.reduce(tensor_list, opts)\n    else:\n        group_dst_rank = _get_group_rank(group, dst)\n        opts.rootRank = group_dst_rank\n        work = group.reduce(tensor_list, opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef reduce(tensor, dst, op=ReduceOp.SUM, group=None, async_op=False):\n    \"\"\"\n    Reduces the tensor data across all machines.\n\n    Only the process with rank ``dst`` is going to receive the final result.\n\n    Args:\n        tensor (Tensor): Input and output of the collective. The function\n            operates in-place.\n        dst (int): Destination rank\n        op (optional): One of the values from\n            ``torch.distributed.ReduceOp``\n            enum.  Specifies an operation used for element-wise reductions.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"reduce\")\n        return\n\n    opts = ReduceOptions()\n    opts.reduceOp = op\n    opts.rootRank = dst\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        work = default_pg.reduce([tensor], opts)\n    else:\n        group_dst_rank = _get_group_rank(group, dst)\n        opts.rootRank = group_dst_rank\n        work = group.reduce([tensor], opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef all_gather_multigpu(\n    output_tensor_lists, input_tensor_list, group=None, async_op=False\n):\n    \"\"\"\n    Gathers tensors from the whole group in a list.\n    Each tensor in ``tensor_list`` should reside on a separate GPU\n\n    Only nccl backend is currently supported\n    tensors should only be GPU tensors\n\n    Complex tensors are supported.\n\n    Args:\n        output_tensor_lists (List[List[Tensor]]): Output lists. It should\n            contain correctly-sized tensors on each GPU to be used for output\n            of the collective, e.g. ``output_tensor_lists[i]`` contains the\n            all_gather result that resides on the GPU of\n            ``input_tensor_list[i]``.\n\n            Note that each element of ``output_tensor_lists`` has the size of\n            ``world_size * len(input_tensor_list)``, since the function all\n            gathers the result from every single GPU in the group. To interpret\n            each element of ``output_tensor_lists[i]``, note that\n            ``input_tensor_list[j]`` of rank k will be appear in\n            ``output_tensor_lists[i][k * world_size + j]``\n\n            Also note that ``len(output_tensor_lists)``, and the size of each\n            element in ``output_tensor_lists`` (each element is a list,\n            therefore ``len(output_tensor_lists[i])``) need to be the same\n            for all the distributed processes calling this function.\n\n        input_tensor_list (List[Tensor]): List of tensors(on different GPUs) to\n            be broadcast from current process.\n            Note that ``len(input_tensor_list)`` needs to be the same for\n            all the distributed processes calling this function.\n\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_gather_multigpu\")\n        return\n\n    output_tensor_lists = [\n        [t if not t.is_complex() else torch.view_as_real(t) for t in l]\n        for l in output_tensor_lists\n    ]\n    input_tensor_list = [\n        t if not t.is_complex() else torch.view_as_real(t) for t in input_tensor_list\n    ]\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.allgather(output_tensor_lists, input_tensor_list)\n    else:\n        work = group.allgather(output_tensor_lists, input_tensor_list)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef _object_to_tensor(obj):\n    f = io.BytesIO()\n    _pickler(f).dump(obj)\n    byte_storage = torch.ByteStorage.from_buffer(f.getvalue())  # type: ignore[attr-defined]\n    # Do not replace `torch.ByteTensor` or `torch.LongTensor` with torch.tensor and specifying dtype.\n    # Otherwise, it will casue 100X slowdown.\n    # See: https://github.com/pytorch/pytorch/issues/65696\n    byte_tensor = torch.ByteTensor(byte_storage)\n    local_size = torch.LongTensor([byte_tensor.numel()])\n    return byte_tensor, local_size\n\n\ndef _tensor_to_object(tensor, tensor_size):\n    buf = tensor.numpy().tobytes()[:tensor_size]\n    return _unpickler(io.BytesIO(buf)).load()\n\ndef _check_for_nccl_backend(group):\n    pg = group or _get_default_group()\n    # It is not expected for PG to be wrapped many times, but support it just\n    # in case\n    while isinstance(pg, _ProcessGroupWrapper):\n        pg = pg.wrapped_pg\n\n    return (\n        is_nccl_available() and\n        isinstance(pg, ProcessGroupNCCL)\n    )\n\ndef all_gather_object(object_list, obj, group=None):\n    \"\"\"\n    Gathers picklable objects from the whole group into a list. Similar to\n    :func:`all_gather`, but Python objects can be passed in. Note that the object\n    must be picklable in order to be gathered.\n\n    Args:\n        object_list (list[Any]): Output list. It should be correctly sized as the\n            size of the group for this collective and will contain the output.\n        object (Any): Pickable Python object to be broadcast from current process.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used. Default is ``None``.\n\n    Returns:\n        None. If the calling rank is part of this group, the output of the\n        collective will be populated into the input ``object_list``. If the\n        calling rank is not part of the group, the passed in ``object_list`` will\n        be unmodified.\n\n    .. note:: Note that this API differs slightly from the :func:`all_gather`\n        collective since it does not provide an ``async_op`` handle and thus\n        will be a blocking call.\n\n    .. note:: For NCCL-based processed groups, internal tensor representations\n        of objects must be moved to the GPU device before communication takes\n        place. In this case, the device used is given by\n        ``torch.cuda.current_device()`` and it is the user's responsiblity to\n        ensure that this is set so that each rank has an individual GPU, via\n        ``torch.cuda.set_device()``.\n\n    .. warning::\n        :func:`all_gather_object` uses ``pickle`` module implicitly, which is\n        known to be insecure. It is possible to construct malicious pickle data\n        which will execute arbitrary code during unpickling. Only call this\n        function with data you trust.\n\n    Example::\n        >>> # Note: Process group initialization omitted on each rank.\n        >>> import torch.distributed as dist\n        >>> # Assumes world_size of 3.\n        >>> gather_objects = [\"foo\", 12, {1: 2}] # any picklable object\n        >>> output = [None for _ in gather_objects]\n        >>> dist.all_gather_object(output, gather_objects[dist.get_rank()])\n        >>> output\n        ['foo', 12, {1: 2}]\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_gather_object\")\n        return\n\n    input_tensor, local_size = _object_to_tensor(obj)\n    current_device = torch.device(\"cpu\")\n    is_nccl_backend = _check_for_nccl_backend(group)\n    if is_nccl_backend:\n        # See note about using torch.cuda.current_device() here in docstring.\n        # We cannot simply use my_rank since rank == device is not necessarily\n        # true.\n        current_device = torch.device(\"cuda\", torch.cuda.current_device())\n        input_tensor = input_tensor.to(current_device)\n        local_size = local_size.to(current_device)\n    # Gather all local sizes. This is so that we can find the max size, and index\n    # until the correct size when deserializing the tensors.\n    group_size = get_world_size(group=group)\n    object_sizes_tensor = torch.zeros(\n        group_size, dtype=torch.long, device=current_device\n    )\n    object_size_list = [\n        object_sizes_tensor[i].unsqueeze(dim=0) for i in range(group_size)\n    ]\n    # Allgather tensor sizes\n    all_gather(object_size_list, local_size, group=group)\n    max_object_size = int(max(object_size_list).item())  # type: ignore[type-var]\n    # Resize tensor to max size across all ranks.\n    input_tensor.resize_(max_object_size)\n    coalesced_output_tensor = torch.empty(\n        max_object_size * group_size, dtype=torch.uint8, device=current_device\n    )\n    # Output tensors are nonoverlapping views of coalesced_output_tensor\n    output_tensors = [\n        coalesced_output_tensor[max_object_size * i : max_object_size * (i + 1)]\n        for i in range(group_size)\n    ]\n    all_gather(output_tensors, input_tensor, group=group)\n    # Deserialize outputs back to object.\n    for i, tensor in enumerate(output_tensors):\n        tensor = tensor.type(torch.uint8)\n        if tensor.device != torch.device(\"cpu\"):\n            tensor = tensor.cpu()\n        tensor_size = object_size_list[i]\n        object_list[i] = _tensor_to_object(tensor, tensor_size)\n\n\ndef gather_object(obj, object_gather_list=None, dst=0, group=None):\n    \"\"\"\n    Gathers picklable objects from the whole group in a single process.\n    Similar to :func:`gather`, but Python objects can be passed in. Note that the\n    object must be picklable in order to be gathered.\n\n    Args:\n        obj (Any): Input object. Must be picklable.\n        object_gather_list (list[Any]): Output list. On the ``dst`` rank, it\n            should be correctly sized as the size of the group for this\n            collective and will contain the output. Must be ``None`` on non-dst\n            ranks. (default is ``None``)\n        dst (int, optional): Destination rank. (default is 0)\n        group: (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used. Default is ``None``.\n\n    Returns:\n        None. On the ``dst`` rank, ``object_gather_list`` will contain the\n        output of the collective.\n\n    .. note:: Note that this API differs slightly from the gather collective\n        since it does not provide an async_op handle and thus will be a blocking\n        call.\n\n    .. note:: For NCCL-based processed groups, internal tensor representations\n        of objects must be moved to the GPU device before communication takes\n        place. In this case, the device used is given by\n        ``torch.cuda.current_device()`` and it is the user's responsiblity to\n        ensure that this is set so that each rank has an individual GPU, via\n        ``torch.cuda.set_device()``.\n\n    .. warning::\n        :func:`gather_object` uses ``pickle`` module implicitly, which is\n        known to be insecure. It is possible to construct malicious pickle data\n        which will execute arbitrary code during unpickling. Only call this\n        function with data you trust.\n\n    Example::\n        >>> # Note: Process group initialization omitted on each rank.\n        >>> import torch.distributed as dist\n        >>> # Assumes world_size of 3.\n        >>> gather_objects = [\"foo\", 12, {1: 2}] # any picklable object\n        >>> output = [None for _ in gather_objects]\n        >>> dist.gather_object(\n                gather_objects[dist.get_rank()],\n                output if dist.get_rank() == 0 else None,\n                dst=0\n            )\n        >>> # On rank 0\n        >>> output\n        ['foo', 12, {1: 2}]\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"gather_object\")\n        return\n\n    # Ensure object_gather_list is specified appopriately.\n    my_rank = get_rank()\n    _validate_output_list_for_rank(my_rank, dst, object_gather_list)\n    input_tensor, local_size = _object_to_tensor(obj)\n    current_device = torch.device(\"cpu\")\n    is_nccl_backend = _check_for_nccl_backend(group)\n\n    if is_nccl_backend:\n        current_device = torch.device(\"cuda\", torch.cuda.current_device())\n        input_tensor = input_tensor.to(current_device)\n        local_size = local_size.to(current_device)\n    # Gather all local sizes. This is so that we can find the max size, and index\n    # until the correct size when deserializing the tensors.\n    group_size = get_world_size(group=group)\n    object_sizes_tensor = torch.zeros(\n        group_size, dtype=torch.long, device=current_device\n    )\n    object_size_list = [\n        object_sizes_tensor[i].unsqueeze(dim=0) for i in range(group_size)\n    ]\n    # Allgather tensor sizes. An all-gather is needed here despite this being a\n    # gather, since each rank needs to broadcast a tensor of the same (maximal)\n    # size.\n    all_gather(object_size_list, local_size, group=group)\n    max_object_size = int(max(object_size_list).item())  # type: ignore[type-var]\n    # Resize tensor to max size across all ranks.\n    input_tensor.resize_(max_object_size)\n    # Avoid populating output tensors if the result won't be gathered on this rank.\n    if my_rank == dst:\n        coalesced_output_tensor = torch.empty(\n            max_object_size * group_size, dtype=torch.uint8, device=current_device\n        )\n        # Output tensors are nonoverlapping views of coalesced_output_tensor\n        output_tensors = [\n            coalesced_output_tensor[max_object_size * i : max_object_size * (i + 1)]\n            for i in range(group_size)\n        ]\n    # All ranks call gather with equal-sized tensors.\n    gather(\n        input_tensor,\n        gather_list=output_tensors if my_rank == dst else None,\n        dst=dst,\n        group=group,\n    )\n    if my_rank != dst:\n        return\n    for i, tensor in enumerate(output_tensors):\n        tensor = tensor.type(torch.uint8)\n        if tensor.device != torch.device(\"cpu\"):\n            tensor = tensor.cpu()\n        tensor_size = object_size_list[i]\n        object_gather_list[i] = _tensor_to_object(tensor, tensor_size)\n\n\ndef broadcast_object_list(object_list, src=0, group=None, device=None):\n    \"\"\"\n    Broadcasts picklable objects in ``object_list`` to the whole group. Similar\n    to :func:`broadcast`, but Python objects can be passed in.\n    Note that all objects in ``object_list`` must be picklable in order to be\n    broadcasted.\n\n    Args:\n        object_list (List[Any]): List of input objects to broadcast.\n            Each object must be picklable. Only objects on the ``src`` rank will\n            be broadcast, but each rank must provide lists of equal sizes.\n        src (int): Source rank from which to broadcast ``object_list``.\n        group: (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used. Default is ``None``.\n        device (``torch.device``, optional): If not None, the objects are\n            serialized and converted to tensors which are moved to the\n            ``device`` before broadcasting. Default is ``None``.\n\n    Returns:\n        ``None``. If rank is part of the group, ``object_list`` will contain the\n        broadcasted objects from ``src`` rank.\n\n    .. note:: For NCCL-based processed groups, internal tensor representations\n        of objects must be moved to the GPU device before communication takes\n        place. In this case, the device used is given by\n        ``torch.cuda.current_device()`` and it is the user's responsiblity to\n        ensure that this is set so that each rank has an individual GPU, via\n        ``torch.cuda.set_device()``.\n\n    .. note:: Note that this API differs slightly from the :func:`all_gather`\n        collective since it does not provide an ``async_op`` handle and thus\n        will be a blocking call.\n\n    .. warning::\n        :func:`broadcast_object_list` uses ``pickle`` module implicitly, which\n        is known to be insecure. It is possible to construct malicious pickle\n        data which will execute arbitrary code during unpickling. Only call this\n        function with data you trust.\n\n    Example::\n        >>> # Note: Process group initialization omitted on each rank.\n        >>> import torch.distributed as dist\n        >>> if dist.get_rank() == 0:\n        >>>     # Assumes world_size of 3.\n        >>>     objects = [\"foo\", 12, {1: 2}] # any picklable object\n        >>> else:\n        >>>     objects = [None, None, None]\n        >>> # Assumes backend is not NCCL\n        >>> device = torch.device(\"cpu\")\n        >>> dist.broadcast_object_list(objects, src=0, device=device)\n        >>> objects\n        ['foo', 12, {1: 2}]\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"broadcast_object_list\")\n        return\n\n    my_rank = get_rank()\n    # Serialize object_list elements to tensors on src rank.\n    if my_rank == src:\n        tensor_list, size_list = zip(*[_object_to_tensor(obj) for obj in object_list])\n        object_sizes_tensor = torch.cat(size_list)\n    else:\n        object_sizes_tensor = torch.empty(len(object_list), dtype=torch.long)\n\n    # Current device selection.\n    # To preserve backwards compatibility, ``device`` is default to ``None``\n    # in which case we run current logic of device selection, i.e.\n    # ``current_device`` is CUDA if backend is NCCL otherwise CPU device. In the\n    # case it is not ``None`` we move the size and object tensors to be\n    # broadcasted to this device.\n    is_nccl_backend = _check_for_nccl_backend(group)\n    current_device = None\n    if device is not None:\n        if is_nccl_backend and device.type != \"cuda\":\n            raise ValueError(\"device type must be cuda for nccl backend\")\n        current_device = device\n    else:\n        current_device = torch.device(\"cpu\")\n        if is_nccl_backend:\n            # See note about using torch.cuda.current_device() here in\n            # docstring. We cannot simply use my_rank since rank == device is\n            # not necessarily true.\n            current_device = torch.device(\"cuda\", torch.cuda.current_device())\n    if is_nccl_backend:\n        object_sizes_tensor = object_sizes_tensor.to(current_device)\n\n    # Broadcast object sizes\n    broadcast(object_sizes_tensor, src=src, group=group)\n\n    # Concatenate and broadcast serialized object tensors\n    if my_rank == src:\n        object_tensor = torch.cat(tensor_list)\n    else:\n        object_tensor = torch.empty(\n            torch.sum(object_sizes_tensor).item(),  # type: ignore[arg-type]\n            dtype=torch.uint8,\n        )\n\n    if is_nccl_backend:\n        object_tensor = object_tensor.to(current_device)\n    broadcast(object_tensor, src=src, group=group)\n    # Deserialize objects using their stored sizes.\n    offset = 0\n    if my_rank != src:\n        for i, obj_size in enumerate(object_sizes_tensor):\n            obj_view = object_tensor[offset : offset + obj_size]\n            obj_view = obj_view.type(torch.uint8)\n            if obj_view.device != torch.device(\"cpu\"):\n                obj_view = obj_view.cpu()\n            offset += obj_size\n            object_list[i] = _tensor_to_object(obj_view, obj_size)\n\n\ndef scatter_object_list(\n    scatter_object_output_list, scatter_object_input_list, src=0, group=None\n):\n    \"\"\"\n    Scatters picklable objects in ``scatter_object_input_list`` to the whole\n    group. Similar to :func:`scatter`, but Python objects can be passed in. On\n    each rank, the scattered object will be stored as the first element of\n    ``scatter_object_output_list``. Note that all objects in\n    ``scatter_object_input_list`` must be picklable in order to be scattered.\n\n    Args:\n        scatter_object_output_list (List[Any]): Non-empty list whose first\n            element will store the object scattered to this rank.\n        scatter_object_input_list (List[Any]): List of input objects to scatter.\n            Each object must be picklable. Only objects on the ``src`` rank will\n            be scattered, and the argument can be ``None`` for non-src ranks.\n        src (int): Source rank from which to scatter\n            ``scatter_object_input_list``.\n        group: (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used. Default is ``None``.\n\n    Returns:\n        ``None``. If rank is part of the group, ``scatter_object_output_list``\n        will have its first element set to the scattered object for this rank.\n\n    .. note:: Note that this API differs slightly from the scatter collective\n        since it does not provide an ``async_op`` handle and thus will be a\n        blocking call.\n\n    .. note:: Note that this API does not support the NCCL backend, as the\n        tensor-based scatter collective is not supported by ProcessGroupNCCL.\n\n    .. warning::\n        :func:`scatter_object_list` uses ``pickle`` module implicitly, which\n        is known to be insecure. It is possible to construct malicious pickle\n        data which will execute arbitrary code during unpickling. Only call this\n        function with data you trust.\n\n    Example::\n        >>> # Note: Process group initialization omitted on each rank.\n        >>> import torch.distributed as dist\n        >>> if dist.get_rank() == 0:\n        >>>     # Assumes world_size of 3.\n        >>>     objects = [\"foo\", 12, {1: 2}] # any picklable object\n        >>> else:\n        >>>     # Can be any list on non-src ranks, elements are not used.\n        >>>     objects = [None, None, None]\n        >>> output_list = [None]\n        >>> dist.scatter_object_list(output_list, objects, src=0)\n        >>> # Rank i gets objects[i]. For example, on rank 2:\n        >>> output_list\n        [{1: 2}]\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"scatter_object_list\")\n        return\n\n    if (\n        not isinstance(scatter_object_output_list, list)\n        or len(scatter_object_output_list) < 1\n    ):\n        raise RuntimeError(\n            \"Expected argument scatter_object_output_list to be a list of size at least 1.\"\n        )\n\n    my_rank = get_rank(group)\n    if my_rank == src:\n        tensor_list, tensor_sizes = zip(\n            *[_object_to_tensor(obj) for obj in scatter_object_input_list]\n        )\n        tensor_list, tensor_sizes = list(tensor_list), list(tensor_sizes)\n\n    # Src rank broadcasts the maximum tensor size. This is because all ranks are\n    # expected to call into scatter() with equal-sized tensors.\n    if my_rank == src:\n        max_tensor_size = max(tensor_sizes)\n        for tensor in tensor_list:\n            tensor.resize_(max_tensor_size)\n    else:\n        max_tensor_size = torch.tensor([0], dtype=torch.long)\n    broadcast(max_tensor_size, src=src, group=group)\n\n    # Scatter actual serialized objects\n    output_tensor = torch.empty(max_tensor_size.item(), dtype=torch.uint8)\n    scatter(\n        output_tensor,\n        scatter_list=None if my_rank != src else tensor_list,\n        src=src,\n        group=group,\n    )\n\n    # Scatter per-object sizes to trim tensors when deserializing back to object\n    obj_tensor_size = torch.tensor([0], dtype=torch.long)\n    scatter(\n        obj_tensor_size,\n        scatter_list=None if my_rank != src else tensor_sizes,\n        src=src,\n        group=group,\n    )\n\n    # Deserialize back to object\n    scatter_object_output_list[0] = _tensor_to_object(output_tensor, obj_tensor_size)\n\n\ndef all_gather(tensor_list, tensor, group=None, async_op=False):\n    \"\"\"\n    Gathers tensors from the whole group in a list.\n\n    Complex tensors are supported.\n\n    Args:\n        tensor_list (list[Tensor]): Output list. It should contain\n            correctly-sized tensors to be used for output of the collective.\n        tensor (Tensor): Tensor to be broadcast from current process.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    Examples:\n        >>> # All tensors below are of torch.int64 dtype.\n        >>> # We have 2 process groups, 2 ranks.\n        >>> tensor_list = [torch.zeros(2, dtype=torch.int64) for _ in range(2)]\n        >>> tensor_list\n        [tensor([0, 0]), tensor([0, 0])] # Rank 0 and 1\n        >>> tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank\n        >>> tensor\n        tensor([1, 2]) # Rank 0\n        tensor([3, 4]) # Rank 1\n        >>> dist.all_gather(tensor_list, tensor)\n        >>> tensor_list\n        [tensor([1, 2]), tensor([3, 4])] # Rank 0\n        [tensor([1, 2]), tensor([3, 4])] # Rank 1\n\n        >>> # All tensors below are of torch.cfloat dtype.\n        >>> # We have 2 process groups, 2 ranks.\n        >>> tensor_list = [torch.zeros(2, dtype=torch.cfloat) for _ in range(2)]\n        >>> tensor_list\n        [tensor([0.+0.j, 0.+0.j]), tensor([0.+0.j, 0.+0.j])] # Rank 0 and 1\n        >>> tensor = torch.tensor([1+1j, 2+2j], dtype=torch.cfloat) + 2 * rank * (1+1j)\n        >>> tensor\n        tensor([1.+1.j, 2.+2.j]) # Rank 0\n        tensor([3.+3.j, 4.+4.j]) # Rank 1\n        >>> dist.all_gather(tensor_list, tensor)\n        >>> tensor_list\n        [tensor([1.+1.j, 2.+2.j]), tensor([3.+3.j, 4.+4.j])] # Rank 0\n        [tensor([1.+1.j, 2.+2.j]), tensor([3.+3.j, 4.+4.j])] # Rank 1\n\n    \"\"\"\n    _check_tensor_list(tensor_list, \"tensor_list\")\n    _check_single_tensor(tensor, \"tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_gather\")\n        return\n\n    tensor_list = [\n        t if not t.is_complex() else torch.view_as_real(t) for t in tensor_list\n    ]\n    tensor = tensor if not tensor.is_complex() else torch.view_as_real(tensor)\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.allgather([tensor_list], [tensor])\n    else:\n        work = group.allgather([tensor_list], [tensor])\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef _all_gather_base(output_tensor, input_tensor, group=None, async_op=False):\n    \"\"\"\n    Single tensor all gather. Gathers a single tensor from all ranks, and puts them in a single output tensor.\n\n    Args:\n        output_tensor (Tensor): Output tensor. It should contain\n            correctly-sized tensors to be used for output of the collective.\n        input_tensor (Tensor): Tensor to be broadcast from current process.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    Examples:\n        >>> # All tensors below are of torch.int64 dtype.\n        >>> # We have 2 process groups, 2 ranks.\n        >>> output_tensor = torch.zeros(2, dtype=torch.int64)\n        >>> output_tensor\n        [tensor([0, 0])] # Rank 0 and 1\n        >>> tensor = torch.arange(1, dtype=torch.int64) + 1 + rank\n        >>> tensor\n        tensor([1]) # Rank 0\n        tensor([2]) # Rank 1\n        >>> dist.all_gather_base(output_tensor, tensor)\n        >>> output_tensor\n        tensor([1,2]) # Rank 0\n        tensor([1,2]) # Rank 1\n\n    .. warning::\n        `_all_gather_base` is experimental and subject to change.\n        It is the caller's responsibility to ensure the output_tensor\n        is correctly sized.\n\n    \"\"\"\n    _check_single_tensor(input_tensor, \"input_tensor\")\n    _check_single_tensor(output_tensor, \"output_tensor\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"_all_gather_base\")\n        return\n\n    output_tensor = (\n        output_tensor\n        if not output_tensor.is_complex()\n        else torch.view_as_real(output_tensor)\n    )\n    input_tensor = (\n        input_tensor\n        if not input_tensor.is_complex()\n        else torch.view_as_real(input_tensor)\n    )\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg._allgather_base(output_tensor, input_tensor)\n    else:\n        work = group._allgather_base(output_tensor, input_tensor)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef all_gather_coalesced(\n    output_tensor_lists, input_tensor_list, group=None, async_op=False\n):\n    \"\"\"\n    Gathers input tensors from the whole group in a list in a coalesced manner.\n\n    Complex tensors are supported.\n\n    Args:\n        output_tensor_lists (list[list[Tensor]]): Output list. It should contain\n            correctly-sized tensors to be used for output of the collective.\n        input_tensor_list (list[Tensor]): Tensors to be broadcast from\n            current process. At least one tensor has to be non empty.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    Example:\n        we have 2 process groups, 2 ranks.\n        rank 0 passes:\n            input_tensor_list = [[[1, 1], [1, 1]], [2], [3, 3]]\n            output_tensor_lists =\n               [[[[-1, -1], [-1, -1]], [-1], [-1, -1]],\n                [[[-1, -1], [-1, -1]], [-1], [-1, -1]]]\n        rank 1 passes:\n            input_tensor_list = [[[3, 3], [3, 3]], [5], [1, 1]]\n            output_tensor_lists =\n               [[[[-1, -1], [-1, -1]], [-1], [-1, -1]],\n                [[[-1, -1], [-1, -1]], [-1], [-1, -1]]]\n        both rank 0 and 1 get:\n            output_tensor_lists =\n               [[[1, 1], [1, 1]], [2], [3, 3]],\n                [[3, 3], [3, 3]], [5], [1, 1]]].\n\n    WARNING: at this time individual shape checking is not implemented across nodes.\n    For example, if the rank 0 node passes [torch.rand(4), torch.rand(2)] and the\n    rank 1 node passes [torch.rand(2), torch.rand(2), torch.rand(2)], the\n    all_gather_coalesced operation will proceed without complaint and return\n    erroneous outputs. This lack of shape checking results in significant\n    performance improvements but users of this function should take extra care\n    to ensure that each node passes in tensors whose shapes match across nodes.\n    \"\"\"\n    # We only check basic compatibility with C++ params here, C++ code will\n    # do shape and type checking.\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_gather_coalesced\")\n        return\n    _check_tensor_list(input_tensor_list, \"tensor_list\")\n    if not isinstance(output_tensor_lists, list):\n        raise RuntimeError(\n            \"Invalid function argument: \" \"output_tensor_lists should be a list\"\n        )\n    for output_tensor_list in output_tensor_lists:\n        _check_tensor_list(output_tensor_list, \"output_tensor_lists\")\n\n    output_tensor_lists = [\n        [t if not t.is_complex() else torch.view_as_real(t) for t in l]\n        for l in output_tensor_lists\n    ]\n    input_tensor_list = [\n        t if not t.is_complex() else torch.view_as_real(t) for t in input_tensor_list\n    ]\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.allgather_coalesced(output_tensor_lists, input_tensor_list)\n    else:\n        work = group.allgather_coalesced(output_tensor_lists, input_tensor_list)\n\n    if async_op:\n        return work.get_future()\n    else:\n        work.wait()\n\n\ndef _validate_output_list_for_rank(my_rank, dst, gather_list):\n    if dst == my_rank:\n        if not gather_list:\n            raise ValueError(\n                \"Argument ``gather_list`` must be specified on destination rank.\"\n            )\n    elif gather_list:\n        raise ValueError(\n            \"Argument ``gather_list`` must NOT be specified \"\n            \"on non-destination ranks.\"\n        )\n\n\ndef gather(tensor, gather_list=None, dst=0, group=None, async_op=False):\n    \"\"\"\n    Gathers a list of tensors in a single process.\n\n    Args:\n        tensor (Tensor): Input tensor.\n        gather_list (list[Tensor], optional): List of appropriately-sized\n            tensors to use for gathered data (default is None, must be specified\n            on the destination rank)\n        dst (int, optional): Destination rank (default is 0)\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n\n    # Parameter ``gather_list`` may be left unspecified on non-dst ranks.\n    if gather_list:\n        _check_tensor_list(gather_list, \"gather_list\")\n    else:\n        gather_list = []\n\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"gather\")\n        return\n\n    my_rank = get_rank()\n    _validate_output_list_for_rank(my_rank, dst, gather_list)\n    output_tensors = [gather_list] if dst == my_rank else []\n    input_tensors = [tensor]\n\n    opts = GatherOptions()\n    opts.rootRank = dst\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        work = default_pg.gather(output_tensors, input_tensors, opts)\n    else:\n        group_dst_rank = _get_group_rank(group, dst)\n        opts.rootRank = group_dst_rank\n        work = group.gather(output_tensors, input_tensors, opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef scatter(tensor, scatter_list=None, src=0, group=None, async_op=False):\n    \"\"\"\n    Scatters a list of tensors to all processes in a group.\n\n    Each process will receive exactly one tensor and store its data in the\n    ``tensor`` argument.\n\n    Complex tensors are supported.\n\n    Args:\n        tensor (Tensor): Output tensor.\n        scatter_list (list[Tensor]): List of tensors to scatter (default is\n            None, must be specified on the source rank)\n        src (int): Source rank (default is 0)\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n\n    \"\"\"\n    _check_single_tensor(tensor, \"tensor\")\n\n    # Parameter ``scatter_list`` may be left unspecified on non-src ranks.\n    if scatter_list:\n        _check_tensor_list(scatter_list, \"scatter_list\")\n    else:\n        scatter_list = []\n\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"scatter\")\n        return\n    scatter_list = [\n        t if not t.is_complex() else torch.view_as_real(t) for t in scatter_list\n    ]\n    tensor = tensor if not tensor.is_complex() else torch.view_as_real(tensor)\n\n    my_rank = get_rank()\n    if src == my_rank:\n        if not scatter_list:\n            raise ValueError(\n                \"Argument ``scatter_list`` must be specified \" \"on source rank.\"\n            )\n        input_tensors = [scatter_list]\n        output_tensors = [tensor]\n    else:\n        if scatter_list:\n            raise ValueError(\n                \"Argument ``scatter_list`` must NOT be specified \"\n                \"on non-source ranks.\"\n            )\n        input_tensors = []\n        output_tensors = [tensor]\n\n    opts = ScatterOptions()\n    opts.rootRank = src\n\n    if group is None or group is GroupMember.WORLD:\n        default_pg = _get_default_group()\n        work = default_pg.scatter(output_tensors, input_tensors, opts)\n    else:\n        group_src_rank = _get_group_rank(group, src)\n        opts.rootRank = group_src_rank\n        work = group.scatter(output_tensors, input_tensors, opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef reduce_scatter_multigpu(\n    output_tensor_list, input_tensor_lists, op=ReduceOp.SUM, group=None, async_op=False\n):\n    \"\"\"\n    Reduce and scatter a list of tensors to the whole group.  Only nccl backend\n    is currently supported.\n\n    Each tensor in ``output_tensor_list`` should reside on a separate GPU, as\n    should each list of tensors in ``input_tensor_lists``.\n\n    Args:\n        output_tensor_list (List[Tensor]): Output tensors (on different GPUs)\n            to receive the result of the operation.\n\n            Note that ``len(output_tensor_list)`` needs to be the same for all\n            the distributed processes calling this function.\n\n        input_tensor_lists (List[List[Tensor]]): Input lists.  It should\n            contain correctly-sized tensors on each GPU to be used for input of\n            the collective, e.g. ``input_tensor_lists[i]`` contains the\n            reduce_scatter input that resides on the GPU of\n            ``output_tensor_list[i]``.\n\n            Note that each element of ``input_tensor_lists`` has the size of\n            ``world_size * len(output_tensor_list)``, since the function\n            scatters the result from every single GPU in the group.  To\n            interpret each element of ``input_tensor_lists[i]``, note that\n            ``output_tensor_list[j]`` of rank k receives the reduce-scattered\n            result from ``input_tensor_lists[i][k * world_size + j]``\n\n            Also note that ``len(input_tensor_lists)``, and the size of each\n            element in ``input_tensor_lists`` (each element is a list,\n            therefore ``len(input_tensor_lists[i])``) need to be the same for\n            all the distributed processes calling this function.\n\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group.\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"reduce_scatter_multigpu\")\n        return\n\n    opts = ReduceScatterOptions()\n    opts.reduceOp = op\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.reduce_scatter(output_tensor_list, input_tensor_lists, opts)\n    else:\n        work = group.reduce_scatter(output_tensor_list, input_tensor_lists, opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef reduce_scatter(output, input_list, op=ReduceOp.SUM, group=None, async_op=False):\n    \"\"\"\n    Reduces, then scatters a list of tensors to all processes in a group.\n\n    Args:\n        output (Tensor): Output tensor.\n        input_list (list[Tensor]): List of tensors to reduce and scatter.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group.\n\n    \"\"\"\n    _check_single_tensor(output, \"output\")\n    _check_tensor_list(input_list, \"input_list\")\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"reduce_scatter\")\n        return\n\n    opts = ReduceScatterOptions()\n    opts.reduceOp = op\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.reduce_scatter([output], [input_list], opts)\n    else:\n        work = group.reduce_scatter([output], [input_list], opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef _reduce_scatter_base(output, input, op=ReduceOp.SUM, group=None, async_op=False):\n    \"\"\"\n    Reduces, then scatters a flattened tensor to all processes in a group.\n\n    Args:\n        output (Tensor): Output tensor.\n        input (Tensor): Input tensor that is of size output tensor size times world size\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group.\n\n    \"\"\"\n    _check_single_tensor(output, \"output\")\n    _check_single_tensor(input, \"input\")\n\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"_reduce_scatter_base\")\n        return\n\n    opts = ReduceScatterOptions()\n    opts.reduceOp = op\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg._reduce_scatter_base(output, input, opts)\n    else:\n        work = group._reduce_scatter_base(output, input, opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef all_to_all_single(\n    output,\n    input,\n    output_split_sizes=None,\n    input_split_sizes=None,\n    group=None,\n    async_op=False,\n):\n    \"\"\"\n    Each process splits input tensor and then scatters the split list\n    to all processes in a group. Then concatenate the received tensors from all\n    the processes in the group and return single output tensor.\n\n    Complex tensors are supported.\n\n    Args:\n        output (Tensor): Gathered cancatenated output tensor.\n        input (Tensor): Input tensor to scatter.\n        output_split_sizes: (list[Int], optional): Output split sizes for dim 0\n            if specified None or empty, dim 0 of ``output`` tensor must divide\n            equally by ``world_size``.\n        input_split_sizes: (list[Int], optional): Input split sizes for dim 0\n            if specified None or empty, dim 0 of ``input`` tensor must divide\n            equally by ``world_size``.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group.\n\n    .. warning::\n        `all_to_all_single` is experimental and subject to change.\n\n    Examples:\n        >>> input = torch.arange(4) + rank * 4\n        >>> input\n        tensor([0, 1, 2, 3])     # Rank 0\n        tensor([4, 5, 6, 7])     # Rank 1\n        tensor([8, 9, 10, 11])   # Rank 2\n        tensor([12, 13, 14, 15]) # Rank 3\n        >>> output = torch.empty([4], dtype=torch.int64)\n        >>> dist.all_to_all_single(output, input)\n        >>> output\n        tensor([0, 4, 8, 12])    # Rank 0\n        tensor([1, 5, 9, 13])    # Rank 1\n        tensor([2, 6, 10, 14])   # Rank 2\n        tensor([3, 7, 11, 15])   # Rank 3\n\n        >>> # Essentially, it is similar to following operation:\n        >>> scatter_list = list(input.chunk(world_size))\n        >>> gather_list  = list(output.chunk(world_size))\n        >>> for i in range(world_size):\n        >>>   dist.scatter(gather_list[i], scatter_list if i == rank else [], src = i)\n\n        >>> # Another example with uneven split\n        >>> input\n        tensor([0, 1, 2, 3, 4, 5])                                       # Rank 0\n        tensor([10, 11, 12, 13, 14, 15, 16, 17, 18])                     # Rank 1\n        tensor([20, 21, 22, 23, 24])                                     # Rank 2\n        tensor([30, 31, 32, 33, 34, 35, 36])                             # Rank 3\n        >>> input_splits\n        [2, 2, 1, 1]                                                     # Rank 0\n        [3, 2, 2, 2]                                                     # Rank 1\n        [2, 1, 1, 1]                                                     # Rank 2\n        [2, 2, 2, 1]                                                     # Rank 3\n        >>> output_splits\n        [2, 3, 2, 2]                                                     # Rank 0\n        [2, 2, 1, 2]                                                     # Rank 1\n        [1, 2, 1, 2]                                                     # Rank 2\n        [1, 2, 1, 1]                                                     # Rank 3\n        >>> output = ...\n        >>> dist.all_to_all_single(output, input, output_splits, input_splits)\n        >>> output\n        tensor([ 0,  1, 10, 11, 12, 20, 21, 30, 31])                     # Rank 0\n        tensor([ 2,  3, 13, 14, 22, 32, 33])                             # Rank 1\n        tensor([ 4, 15, 16, 23, 34, 35])                                 # Rank 2\n        tensor([ 5, 17, 18, 24, 36])                                     # Rank 3\n\n\n        >>> # Another example with tensors of torch.cfloat type.\n        >>> input = torch.tensor([1+1j, 2+2j, 3+3j, 4+4j], dtype=torch.cfloat) + 4 * rank * (1+1j)\n        >>> input\n        tensor([1+1j, 2+2j, 3+3j, 4+4j])                                # Rank 0\n        tensor([5+5j, 6+6j, 7+7j, 8+8j])                                # Rank 1\n        tensor([9+9j, 10+10j, 11+11j, 12+12j])                          # Rank 2\n        tensor([13+13j, 14+14j, 15+15j, 16+16j])                        # Rank 3\n        >>> output = torch.empty([4], dtype=torch.int64)\n        >>> dist.all_to_all_single(output, input)\n        >>> output\n        tensor([1+1j, 5+5j, 9+9j, 13+13j])                              # Rank 0\n        tensor([2+2j, 6+6j, 10+10j, 14+14j])                            # Rank 1\n        tensor([3+3j, 7+7j, 11+11j, 15+15j])                            # Rank 2\n        tensor([4+4j, 8+8j, 12+12j, 16+16j])                            # Rank 3\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_to_all_single\")\n        return\n\n    opts = AllToAllOptions()\n    _check_single_tensor(output, \"output\")\n    _check_single_tensor(input, \"input\")\n\n    if input.is_complex():\n        input = torch.view_as_real(input)\n    if output.is_complex():\n        output = torch.view_as_real(output)\n\n    output_split_sizes = [] if output_split_sizes is None else output_split_sizes\n    input_split_sizes = [] if input_split_sizes is None else input_split_sizes\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.alltoall_base(\n            output, input, output_split_sizes, input_split_sizes, opts\n        )\n    else:\n        work = group.alltoall_base(\n            output, input, output_split_sizes, input_split_sizes, opts\n        )\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef all_to_all(output_tensor_list, input_tensor_list, group=None, async_op=False):\n    \"\"\"\n    Each process scatters list of input tensors to all processes in a group and\n    return gathered list of tensors in output list.\n\n    Complex tensors are supported.\n\n    Args:\n        output_tensor_list (list[Tensor]): List of tensors to be gathered one\n            per rank.\n        input_tensor_list (list[Tensor]): List of tensors to scatter one per rank.\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group.\n\n    .. warning::\n        `all_to_all` is experimental and subject to change.\n\n    Examples:\n        >>> input = torch.arange(4) + rank * 4\n        >>> input = list(input.chunk(4))\n        >>> input\n        [tensor([0]), tensor([1]), tensor([2]), tensor([3])]     # Rank 0\n        [tensor([4]), tensor([5]), tensor([6]), tensor([7])]     # Rank 1\n        [tensor([8]), tensor([9]), tensor([10]), tensor([11])]   # Rank 2\n        [tensor([12]), tensor([13]), tensor([14]), tensor([15])] # Rank 3\n        >>> output = list(torch.empty([4], dtype=torch.int64).chunk(4))\n        >>> dist.all_to_all(output, input)\n        >>> output\n        [tensor([0]), tensor([4]), tensor([8]), tensor([12])]    # Rank 0\n        [tensor([1]), tensor([5]), tensor([9]), tensor([13])]    # Rank 1\n        [tensor([2]), tensor([6]), tensor([10]), tensor([14])]   # Rank 2\n        [tensor([3]), tensor([7]), tensor([11]), tensor([15])]   # Rank 3\n\n        >>> # Essentially, it is similar to following operation:\n        >>> scatter_list = input\n        >>> gather_list  = output\n        >>> for i in range(world_size):\n        >>>   dist.scatter(gather_list[i], scatter_list if i == rank else [], src = i)\n\n        >>> input\n        tensor([0, 1, 2, 3, 4, 5])                                       # Rank 0\n        tensor([10, 11, 12, 13, 14, 15, 16, 17, 18])                     # Rank 1\n        tensor([20, 21, 22, 23, 24])                                     # Rank 2\n        tensor([30, 31, 32, 33, 34, 35, 36])                             # Rank 3\n        >>> input_splits\n        [2, 2, 1, 1]                                                     # Rank 0\n        [3, 2, 2, 2]                                                     # Rank 1\n        [2, 1, 1, 1]                                                     # Rank 2\n        [2, 2, 2, 1]                                                     # Rank 3\n        >>> output_splits\n        [2, 3, 2, 2]                                                     # Rank 0\n        [2, 2, 1, 2]                                                     # Rank 1\n        [1, 2, 1, 2]                                                     # Rank 2\n        [1, 2, 1, 1]                                                     # Rank 3\n        >>> input = list(input.split(input_splits))\n        >>> input\n        [tensor([0, 1]), tensor([2, 3]), tensor([4]), tensor([5])]                   # Rank 0\n        [tensor([10, 11, 12]), tensor([13, 14]), tensor([15, 16]), tensor([17, 18])] # Rank 1\n        [tensor([20, 21]), tensor([22]), tensor([23]), tensor([24])]                 # Rank 2\n        [tensor([30, 31]), tensor([32, 33]), tensor([34, 35]), tensor([36])]         # Rank 3\n        >>> output = ...\n        >>> dist.all_to_all(output, input)\n        >>> output\n        [tensor([0, 1]), tensor([10, 11, 12]), tensor([20, 21]), tensor([30, 31])]   # Rank 0\n        [tensor([2, 3]), tensor([13, 14]), tensor([22]), tensor([32, 33])]           # Rank 1\n        [tensor([4]), tensor([15, 16]), tensor([23]), tensor([34, 35])]              # Rank 2\n        [tensor([5]), tensor([17, 18]), tensor([24]), tensor([36])]                  # Rank 3\n\n        >>> # Another example with tensors of torch.cfloat type.\n        >>> input = torch.tensor([1+1j, 2+2j, 3+3j, 4+4j], dtype=torch.cfloat) + 4 * rank * (1+1j)\n        >>> input = list(input.chunk(4))\n        >>> input\n        [tensor([1+1j]), tensor([2+2j]), tensor([3+3j]), tensor([4+4j])]            # Rank 0\n        [tensor([5+5j]), tensor([6+6j]), tensor([7+7j]), tensor([8+8j])]            # Rank 1\n        [tensor([9+9j]), tensor([10+10j]), tensor([11+11j]), tensor([12+12j])]      # Rank 2\n        [tensor([13+13j]), tensor([14+14j]), tensor([15+15j]), tensor([16+16j])]    # Rank 3\n        >>> output = list(torch.empty([4], dtype=torch.int64).chunk(4))\n        >>> dist.all_to_all(output, input)\n        >>> output\n        [tensor([1+1j]), tensor([5+5j]), tensor([9+9j]), tensor([13+13j])]          # Rank 0\n        [tensor([2+2j]), tensor([6+6j]), tensor([10+10j]), tensor([14+14j])]        # Rank 1\n        [tensor([3+3j]), tensor([7+7j]), tensor([11+11j]), tensor([15+15j])]        # Rank 2\n        [tensor([4+4j]), tensor([8+8j]), tensor([12+12j]), tensor([16+16j])]        # Rank 3\n\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"all_to_all\")\n        return\n\n    opts = AllToAllOptions()\n    _check_tensor_list(output_tensor_list, \"output_tensor_list\")\n    _check_tensor_list(input_tensor_list, \"input_tensor_list\")\n\n    input_tensor_list = [\n        t if not t.is_complex() else torch.view_as_real(t) for t in input_tensor_list\n    ]\n    output_tensor_list = [\n        t if not t.is_complex() else torch.view_as_real(t) for t in output_tensor_list\n    ]\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.alltoall(output_tensor_list, input_tensor_list, opts)\n    else:\n        work = group.alltoall(output_tensor_list, input_tensor_list, opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef barrier(group=GroupMember.WORLD, async_op=False, device_ids=None):\n\n    \"\"\"\n    Synchronizes all processes.\n\n    This collective blocks processes until the whole group enters this function,\n    if async_op is False, or if async work handle is called on wait().\n\n    Args:\n        group (ProcessGroup, optional): The process group to work on. If None,\n            the default process group will be used.\n        async_op (bool, optional): Whether this op should be an async op\n        device_ids ([int], optional): List of device/GPU ids.\n                                      Valid only for NCCL backend.\n\n    Returns:\n        Async work handle, if async_op is set to True.\n        None, if not async_op or if not part of the group\n    \"\"\"\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"barrier\")\n        return\n\n    opts = BarrierOptions()\n    if device_ids is not None:\n        if get_backend(group) != Backend.NCCL:\n            raise RuntimeError(\n                \"Function argument device_ids not supported \"\n                \"for the selected backend {}\".format(get_backend(group))\n            )\n        if isinstance(device_ids, list):\n            opts.device_ids = device_ids\n        else:\n            raise RuntimeError(\n                \"Invalid function argument: \" \"device_ids type should be List[int]\"\n            )\n\n    if group is None:\n        default_pg = _get_default_group()\n        work = default_pg.barrier(opts=opts)\n    else:\n        work = group.barrier(opts=opts)\n\n    if async_op:\n        return work\n    else:\n        work.wait()\n\n\ndef monitored_barrier(group=GroupMember.WORLD, timeout=None, wait_all_ranks=False):\n    \"\"\"\n    Synchronizes all processes similar to ``torch.distributed.barrier``, but takes\n    a configurable timeout and is able to report ranks that did not pass this\n    barrier within that timeout. Specifically, for non-zero ranks, will block\n    until a send/recv is processed from rank 0. Rank 0 will block until all send\n    /recv from other ranks are processed, and will report failures for ranks\n    that failed to respond in time. Note that if one rank does not reach the\n    monitored_barrier (for example due to a hang), all other ranks would fail\n    in monitored_barrier.\n\n    This collective will block all processes/ranks in the group, until the\n    whole group exits the function successfully, making it useful for debugging\n    and synchronizing. However, it can have a performance impact and should only\n    be used for debugging or scenarios that require full synchronization points\n    on the host-side. For debugging purposees, this barrier can be inserted\n    before the application's collective calls to check if any ranks are\n    desynchronized.\n\n    .. note:: Note that this collective is only supported with the GLOO backend.\n\n    Args:\n        group (ProcessGroup, optional): The process group to work on. If\n            ``None``, the default process group will be used.\n        timeout (datetime.timedelta, optional): Timeout for monitored_barrier.\n            If ``None``, the default process group timeout will be used.\n        wait_all_ranks (bool, optional): Whether to collect all failed ranks or\n            not. By default, this is ``False`` and ``monitored_barrier`` on rank 0\n            will throw on the first failed rank it encounters in order to fail\n            fast. By setting ``wait_all_ranks=True`` ``monitored_barrier`` will\n            collect all failed ranks and throw an error containing information\n            about all failed ranks.\n\n    Returns:\n        ``None``.\n\n    Example::\n        >>> # Note: Process group initialization omitted on each rank.\n        >>> import torch.distributed as dist\n        >>> if dist.get_rank() != 1:\n        >>>     dist.monitored_barrier() # Raises exception indicating that\n        >>> # rank 1 did not call into monitored_barrier.\n        >>> # Example with wait_all_ranks=True\n        >>> if dist.get_rank() == 0:\n        >>>     dist.monitored_barrier(wait_all_ranks=True) # Raises exception\n        >>> # indicating that ranks 1, 2, ... world_size - 1 did not call into\n        >>> # monitored_barrier.\n    \"\"\"\n\n    # Need to call rank not in group before using the group, otherwise\n    # \"Invalid process group\" error is raised.\n    if _rank_not_in_group(group):\n        _warn_not_in_group(\"monitored_barrier\")\n        return\n\n    if get_backend(group) != Backend.GLOO:\n        raise RuntimeError(\"monitored_barrier is only implemented for GLOO backend.\")\n\n    if timeout is None:\n        timeout = default_pg_timeout\n\n    group_to_use = _get_default_group() if group is None else group\n    return group_to_use.monitored_barrier(timeout, wait_all_ranks=wait_all_ranks)\n\n\ndef _create_process_group_wrapper(\n    wrapped_pg: ProcessGroup,\n    store_prefix: str,\n    store: Store,\n    rank: int,\n    world_size: int,\n    timeout: timedelta = default_pg_timeout,\n):\n    # Create a separate prefix store for the helper process group.\n    prefix = f\"{PG_WRAPPER_STORE_PREFIX}:{store_prefix}\"\n    store = PrefixStore(prefix, store)\n    helper_pg = ProcessGroupGloo(store, rank, world_size, timeout=timeout)\n    # Wrap the underlying pg with ProcessGroupWrapper.\n    wrapped_pg = _ProcessGroupWrapper(wrapped_pg, helper_pg)\n    return wrapped_pg\n\n\ndef new_group(ranks=None, timeout=default_pg_timeout, backend=None, pg_options=None):\n    \"\"\"\n    Creates a new distributed group.\n\n    This function requires that all processes in the main group (i.e. all\n    processes that are part of the distributed job) enter this function, even\n    if they are not going to be members of the group. Additionally, groups\n    should be created in the same order in all processes.\n\n    .. warning::\n        Using multiple process groups with the ``NCCL`` backend concurrently\n        is not safe and the user should perform explicit synchronization in\n        their application to ensure only one process group is used at a time.\n        This means collectives from one process group should have completed\n        execution on the device (not just enqueued since CUDA execution is\n        async) before collectives from another process group are enqueued.\n        See `Using multiple NCCL communicators concurrently <https://docs.nvid\n        ia.com/deeplearning/nccl/user-guide/docs/usage/communicators.html#using\n        -multiple-nccl-communicators-concurrently>`_ for more details.\n\n    Args:\n        ranks (list[int]): List of ranks of group members. If ``None``, will be\n            set to all ranks. Default is ``None``.\n        timeout (timedelta, optional): Timeout for operations executed against\n            the process group. Default value equals 30 minutes.\n            This is applicable for the ``gloo`` backend. For ``nccl``, this is\n            applicable only if the environment variable ``NCCL_BLOCKING_WAIT``\n            or ``NCCL_ASYNC_ERROR_HANDLING`` is set to 1. When\n            ``NCCL_BLOCKING_WAIT`` is set, this is the duration for which the\n            process will block and wait for collectives to complete before\n            throwing an exception. When ``NCCL_ASYNC_ERROR_HANDLING`` is set,\n            this is the duration after which collectives will be aborted\n            asynchronously and the process will crash. ``NCCL_BLOCKING_WAIT``\n            will provide errors to the user which can be caught and handled,\n            but due to its blocking nature, it has a performance overhead. On\n            the other hand, ``NCCL_ASYNC_ERROR_HANDLING`` has very little\n            performance overhead, but crashes the process on errors. This is\n            done since CUDA execution is async and it is no longer safe to\n            continue executing user code since failed async NCCL operations\n            might result in subsequent CUDA operations running on corrupted\n            data. Only one of these two environment variables should be set.\n        backend (str or Backend, optional): The backend to use. Depending on\n            build-time configurations, valid values are ``gloo`` and ``nccl``.\n            By default uses the same backend as the global group. This field\n            should be given as a lowercase string (e.g., ``\"gloo\"``), which can\n            also be accessed via :class:`Backend` attributes (e.g.,\n            ``Backend.GLOO``). If ``None`` is passed in, the backend\n            corresponding to the default process group will be used. Default is\n            ``None``.\n        pg_options (ProcessGroupOptions, optional): process group options\n            specifying what additional options need to be passed in during\n            the construction of specific process groups. i.e. for the ``nccl``\n            backend, ``is_high_priority_stream`` can be specified so that\n            process group can pick up high priority cuda streams.\n\n    Returns:\n        A handle of distributed group that can be given to collective calls.\n    \"\"\"\n\n    global _pg_group_ranks\n\n    default_pg = _get_default_group()\n    default_backend, default_store = _pg_map[default_pg]\n    global_rank = default_pg.rank()\n    global_world_size = default_pg.size()\n\n    # Default to the same backend as the global process group\n    # if the backend is not specified.\n    if not backend:\n        backend = default_backend\n\n    # checks the input ranks\n    if ranks is not None:\n        ranks = sorted(ranks)\n        group_world_size = len(ranks)\n        if group_world_size > global_world_size:\n            raise RuntimeError(\n                \"the new group's world size should be less or \"\n                \"equal to the world size set by \"\n                \"init_process_group\"\n            )\n        # check ranks' sanity\n        for rank in ranks:\n            if rank < 0 or rank >= global_world_size:\n                raise RuntimeError(\n                    \"The new group's rank should be within the \"\n                    \"the world_size set by init_process_group\"\n                )\n        if global_rank in ranks:\n            group_rank = ranks.index(global_rank)\n        else:\n            group_rank = None\n    else:\n        ranks = list(range(global_world_size))\n        group_world_size = global_world_size\n        group_rank = global_rank\n\n    backend = Backend(backend)\n    pg = _new_process_group_helper(\n        group_world_size,\n        group_rank,\n        ranks,\n        backend,\n        default_store,\n        pg_options=pg_options,\n        timeout=timeout,\n    )\n\n    # Create the global rank to group rank mapping\n    _pg_group_ranks[pg] = {\n        global_rank: group_rank for group_rank, global_rank in enumerate(ranks)\n    }\n\n    # barrier at the end to ensure that once we return from this method, all\n    # process groups including global variables are updated correctly on all\n    # ranks.\n    if backend == Backend.MPI:\n        # MPI doesn't have store.\n        barrier()\n    else:\n        # Use store based barrier here since barrier() used a bunch of\n        # default devices and messes up NCCL internal state.\n        _store_based_barrier(global_rank, default_store, timeout)\n        # Set sequence numbers for gloo and nccl process groups.\n        if pg != GroupMember.NON_GROUP_MEMBER and get_backend(pg) in [\n            Backend.GLOO,\n            Backend.NCCL,\n        ]:\n            pg._set_sequence_number_for_group()\n\n    return pg\n\n\ndef new_subgroups(\n    group_size=None,\n    group=None,\n    timeout=default_pg_timeout,\n    backend=None,\n    pg_options=None,\n):\n    \"\"\"\n    Creates GPU subgroups of equal size. By default, it creates intra-machine subgroups,\n    where each of which contains all the ranks of a machine, based on the assumption\n    that each machine has the same number of CUDA devices.\n\n    This is a convenience API that calls ``new_group`` to generate multiple subgroups.\n    It requires that all processes in the main group (i.e. all\n    processes that are part of the distributed job) enter this function, even\n    if they are not going to be members of the group.\n\n    .. warning::\n        This API only works when CUDA is available.\n\n    .. warning::\n        If ``group_size`` is passed in, the world size must be divisible by ``group_size``.\n        If no ``group_size`` is passed in, and not all the machines have the same number\n        of devices, the subgroup division will be different across nodes and can cause\n        unexpected behaviors.\n\n    .. warning::\n        Using multiple process groups with the ``NCCL`` backend concurrently\n        is not safe and the user should perform explicit synchronization in\n        their application to ensure only one process group is used at a time.\n        This means collectives from one process group should have completed\n        execution on the device (not just enqueued since CUDA execution is\n        async) before collectives from another process group are enqueued.\n        See `Using multiple NCCL communicators concurrently <https://docs.nvid\n        ia.com/deeplearning/nccl/user-guide/docs/usage/communicators.html#using\n        -multiple-nccl-communicators-concurrently>`_ for more details.\n\n    Args:\n        group_size (int, optional): The size of each subgroup. If ``None``,\n            the default subgroup size is equal to the number of devices on each machine,\n            based on the assumption that each machine has exactly the same\n            number of devices. Default is ``None``.\n        timeout (timedelta, optional): Timeout for operations executed against\n            the process group. Default value equals 30 minutes.\n            This is applicable for the ``gloo`` backend. For ``nccl``, this is\n            applicable only if the environment variable ``NCCL_BLOCKING_WAIT``\n            or ``NCCL_ASYNC_ERROR_HANDLING`` is set to 1. When\n            ``NCCL_BLOCKING_WAIT`` is set, this is the duration for which the\n            process will block and wait for collectives to complete before\n            throwing an exception. When ``NCCL_ASYNC_ERROR_HANDLING`` is set,\n            this is the duration after which collectives will be aborted\n            asynchronously and the process will crash. ``NCCL_BLOCKING_WAIT``\n            will provide errors to the user which can be caught and handled,\n            but due to its blocking nature, it has a performance overhead. On\n            the other hand, ``NCCL_ASYNC_ERROR_HANDLING`` has very little\n            performance overhead, but crashes the process on errors. This is\n            done since CUDA execution is async and it is no longer safe to\n            continue executing user code since failed async NCCL operations\n            might result in subsequent CUDA operations running on corrupted\n            data. Only one of these two environment variables should be set.\n        backend (str or Backend, optional): The backend to use. Depending on\n            build-time configurations, valid values are ``gloo`` and ``nccl``.\n            By default uses the same backend as the global group. This field\n            should be given as a lowercase string (e.g., ``\"gloo\"``), which can\n            also be accessed via :class:`Backend` attributes (e.g.,\n            ``Backend.GLOO``). If ``None`` is passed in, the backend\n            corresponding to the default process group will be used. Default is\n            ``None``.\n        pg_options (ProcessGroupOptions, optional): process group options\n            specifying what additional options need to be passed in during\n            the construction of specific process groups. i.e. for the ``nccl``\n            backend, ``is_high_priority_stream`` can be specified so that\n            process group can pick up high priority cuda streams.\n\n    Returns:\n        The subgroup containing the current rank, and all the subgroups used for cleanup.\n\n    Examples:\n        >>> # Create intra-machine subgroups.\n        >>> cur_subgroup, subgroups = dist.new_subgroups()\n        >>> # Allreduce within the machine.\n        >>> rank = dist.get_rank()\n        >>> tensor = torch.ones(1, device=rank) * rank\n        >>> dist.all_reduce(tensor, group=cur_subgroup)\n        >>> tensor\n        tensor([8])     # Assume 8 is the number of CUDA devices per machine.\n        >>> # Cleanup.\n        >>> for subgroup in subgroups:\n        >>>     dist.destroy_process_group(subgroup)\n    \"\"\"\n    if not torch.cuda.is_available():\n        raise ValueError(\"Subgroups can only be created when CUDA is available\")\n\n    if group_size is None:\n        group_size = torch.cuda.device_count()\n    world_size = get_world_size()\n    if world_size < group_size:\n        raise ValueError(\"The arg 'group_size' must not exceed the world size\")\n    if world_size % group_size != 0:\n        raise ValueError(\"The world size must be divisible by 'group_size'\")\n\n    subgroups = []\n    cur_subgroup = None\n\n    for subgroup_id in range(world_size // group_size):\n        start_rank = subgroup_id * group_size\n        end_rank = start_rank + group_size\n        ranks_in_subgroup = list(range(start_rank, end_rank))\n        subgroup = new_group(\n            ranks=ranks_in_subgroup,\n            timeout=timeout,\n            backend=backend,\n            pg_options=pg_options,\n        )\n        subgroups.append(subgroup)\n\n        rank = get_rank()\n        if rank in ranks_in_subgroup:\n            cur_subgroup = subgroup\n            logger.info(\n                \"Rank {} is assigned to subgroup {}\".format(rank, ranks_in_subgroup)\n            )\n\n    return cur_subgroup, subgroups\n\n\ndef new_subgroups_by_enumeration(\n    ranks_per_subgroup_list,\n    timeout=default_pg_timeout,\n    backend=None,\n    pg_options=None,\n):\n    \"\"\"\n    Creates GPU subgroups by dividing the global world, where the division is specified by\n    a nested list of ranks. The subgroups cannot have overlap, and some ranks may not have\n    to be in any subgroup.\n\n    This is a convenience API that calls ``new_group`` to generate multiple subgroups.\n    It requires that all processes in the main group (i.e. all\n    processes that are part of the distributed job) enter this function, even\n    if they are not going to be members of the group.\n\n    .. warning::\n        Using multiple process groups with the ``NCCL`` backend concurrently\n        is not safe and the user should perform explicit synchronization in\n        their application to ensure only one process group is used at a time.\n        This means collectives from one process group should have completed\n        execution on the device (not just enqueued since CUDA execution is\n        async) before collectives from another process group are enqueued.\n        See `Using multiple NCCL communicators concurrently <https://docs.nvid\n        ia.com/deeplearning/nccl/user-guide/docs/usage/communicators.html#using\n        -multiple-nccl-communicators-concurrently>`_ for more details.\n\n    Args:\n        ranks_per_subgroup_list (list[list[int]]): A nested list of ranks of\n            group members.\n        timeout (timedelta, optional): Timeout for operations executed against\n            the process group. Default value equals 30 minutes.\n            This is applicable for the ``gloo`` backend. For ``nccl``, this is\n            applicable only if the environment variable ``NCCL_BLOCKING_WAIT``\n            or ``NCCL_ASYNC_ERROR_HANDLING`` is set to 1. When\n            ``NCCL_BLOCKING_WAIT`` is set, this is the duration for which the\n            process will block and wait for collectives to complete before\n            throwing an exception. When ``NCCL_ASYNC_ERROR_HANDLING`` is set,\n            this is the duration after which collectives will be aborted\n            asynchronously and the process will crash. ``NCCL_BLOCKING_WAIT``\n            will provide errors to the user which can be caught and handled,\n            but due to its blocking nature, it has a performance overhead. On\n            the other hand, ``NCCL_ASYNC_ERROR_HANDLING`` has very little\n            performance overhead, but crashes the process on errors. This is\n            done since CUDA execution is async and it is no longer safe to\n            continue executing user code since failed async NCCL operations\n            might result in subsequent CUDA operations running on corrupted\n            data. Only one of these two environment variables should be set.\n         backend (str or Backend, optional): The backend to use. Depending on\n             build-time configurations, valid values are ``gloo`` and ``nccl``.\n             By default uses the same backend as the global group. This field\n             should be given as a lowercase string (e.g., ``\"gloo\"``), which can\n             also be accessed via :class:`Backend` attributes (e.g.,\n             ``Backend.GLOO``). If ``None`` is passed in, the backend\n             corresponding to the default process group will be used. Default is\n             ``None``.\n        pg_options (ProcessGroupOptions, optional): process group options\n            specifying what additional options need to be passed in during\n            the construction of specific process groups. i.e. for the ``nccl``\n            backend, ``is_high_priority_stream`` can be specified so that\n            process group can pick up high priority cuda streams.\n\n    Returns:\n        The subgroup containing the current rank, and all the subgroups used for cleanup.\n\n    Examples:\n        >>> # Create two subgroups, where each has 2 processes.\n        >>> cur_subgroup, subgroups = dist.new_subgroups(ranks=[[0, 2], [1, 3]])\n        >>> rank = dist.get_rank()\n        >>> tensor = torch.ones(1, device=rank) * rank\n        >>> dist.all_reduce(tensor, group=cur_subgroup)\n        >>> tensor\n        tensor([2])     # Subgroup 0: ranks 0 and 2\n        tensor([4])     # Subgroup 1: ranks 1 and 3\n    \"\"\"\n    if not torch.cuda.is_available():\n        raise ValueError(\"Subgroups can only be created when CUDA is available\")\n    if ranks_per_subgroup_list is None or len(ranks_per_subgroup_list) == 0:\n        raise ValueError(\"The arg 'ranks_per_subgroup_list' cannot be empty\")\n\n    world_size = get_world_size()\n\n    subgroups = []\n    cur_subgroup = None\n    # Create a mapping from rank to subgroup to check if there is any subgroup overlap.\n    rank_to_ranks_dict = {}  # type: ignore[var-annotated]\n    for ranks in ranks_per_subgroup_list:\n        subgroup = new_group(\n            ranks=ranks,\n            timeout=timeout,\n            backend=backend,\n            pg_options=pg_options,\n        )\n        subgroups.append(subgroup)\n        my_rank = get_rank()\n        for rank in ranks:\n            if rank in rank_to_ranks_dict:\n                raise ValueError(\n                    \"Rank {} has appeared in both subgroup {} and {}\".format(\n                        rank, rank_to_ranks_dict[rank], ranks\n                    )\n                )\n            rank_to_ranks_dict[rank] = ranks\n            if my_rank == rank:\n                cur_subgroup = subgroup\n                logging.info(\"Rank {} is assigned to subgroup {}\".format(rank, ranks))\n\n    return cur_subgroup, subgroups\n", 3234], "/root/Project/TCRGraph/src/type/CSRGraph.py": ["\"\"\"\nA Graph type implemented with CSR (compressed sparse row) type.\n\"\"\"\nimport torch\nimport numpy as np\nfrom .Graph import Graph\nfrom torch.nn.utils.rnn import pad_sequence\nfrom src.framework.helper import batched_csr_selection, batched_adj_selection\n\nclass CSRGraph(Graph):\n    \"\"\"\n    CSR implementation of Graph. Provides efficient access to out_nbrs.\n    \"\"\"\n    def __init__(self,\n                 columns: torch.Tensor=None, \n                 row_ptr: torch.Tensor=None, \n                 directed=False,\n                 vertex_attrs_list=[],\n                 vertex_attrs_tensor: torch.Tensor=None,\n                 vertex_attrs_mask: torch.Tensor=None,\n                 edge_attrs_list=[],\n                 edge_attrs_tensor: torch.Tensor=None,\n                 edge_attrs_mask: torch.Tensor=None):\n        \"\"\"\n        Initialize a CSRGraph object with according datatypes (tensors).\n        \n        :param Tensor columns: out-neighbors of vertex (arranged in order)\n        :param Tensor row_ptr: pointers of each vertex for val and col_ind\n        :param bool directed: whether the graph is directed\n        :param list vertex_attrs_list: list of vertex attributes names\n        :param Tensor vertex_attrs_tensor: tensor of vertex attributes that stores data\n        :param Tensor vertex_attrs_mask: mask of vertex attributes\n        :param list edge_attrs_list: list of edge attributes names\n        :param Tensor edge_attrs_tensor: tensor of edge attributes that stores data\n        :param Tensor edge_attrs_mask: mask of edge attributes\n        :return: None\n        \"\"\"\n        super().__init__(directed=directed)\n        self.columns = columns\n        self.row_ptr = row_ptr\n        self.out_degrees = torch.diff(self.row_ptr)\n        # process attributes\n        self.vertex_attrs_list = vertex_attrs_list\n        self.vertex_attrs_map = {attr: i for i, attr in enumerate(vertex_attrs_list)}\n        self.edge_attrs_list = edge_attrs_list\n        self.edge_attrs_map = {attr: i for i, attr in enumerate(edge_attrs_list)}\n        if vertex_attrs_tensor is not None and vertex_attrs_mask is not None:\n            self.vertex_attrs_tensor = vertex_attrs_tensor\n            self.vertex_attrs_mask = vertex_attrs_mask\n        else:\n            self.vertex_attrs_tensor = torch.zeros((self.num_vertices, len(vertex_attrs_list)), dtype=torch.float32)\n            self.vertex_attrs_mask = torch.zeros((self.num_vertices, len(vertex_attrs_list)), dtype=torch.bool)\n        if edge_attrs_tensor is not None and edge_attrs_mask is not None:\n            self.edge_attrs_tensor = edge_attrs_tensor\n            self.edge_attrs_mask = edge_attrs_mask\n        else:\n            self.edge_attrs_tensor = torch.zeros((self.num_edges, len(edge_attrs_list)), dtype=torch.float32)\n            self.edge_attrs_mask = torch.zeros((self.num_edges, len(edge_attrs_list)), dtype=torch.bool)\n            \n    @property\n    def num_vertices(self):\n        \"\"\"\u8fd4\u56deGraph\u7684\u8282\u70b9\u6570\u76ee\n\n        Returns:\n            (int): the num of vertices\n\n        \"\"\"\n        if hasattr(self.row_ptr, 'shape'):\n            return self.row_ptr.shape[0] - 1\n        else:\n            return 0\n        \n    @property\n    def num_edges(self):\n        \"\"\"number of edges.\"\"\"\n        if hasattr(self.columns, 'shape'):\n            return self.columns.shape[0]\n        else:\n            return 0\n    \n    def out_degree(self, vertices):\n        \"\"\"Get the number of out neighbors. (if undirected, #out_nbrs = #in_nbrs)\n        for every vertex in arg \"vertices\", return their own out_degree\n\n        Args:\n            vertices: torch.Tensor(1*n)--\u9700\u8981\u67e5\u8be2\u7684\u51fa\u5ea6\u7684\u8282\u70b9\u5217\u8868\n\n        Returns:\n            torch.Tensor\uff081*n\uff09 -- \u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u7684\u51fa\u5ea6\n\n\n        \"\"\"\n        assert torch.all(vertices < self.num_vertices)\n        return self.out_degrees[vertices]\n    \n    def in_degree(self, vertices):\n        \"\"\"\u83b7\u53d6\u8282\u70b9\u7684\u51fa\u5ea6\n        CSR\u5b58\u50a8\u683c\u5f0f\u53ef\u4ee5\u5feb\u901f\u83b7\u53d6\u8282\u70b9\u7684\u51fa\u5ea6\uff0c\u83b7\u53d6\u5165\u5ea6\u89c1CSCGraph\n        Args:\n            vertices:\n\n        Returns:\n\n        \"\"\"\n        raise NotImplementedError('Not implemented for CSRGraph.')\n    \n    def out_nbrs(self, vertices):\n        \"\"\"\u8fd4\u56de\u6307\u5b9a\u8282\u70b9\u7684\u51fa\u5ea6\u90bb\u5c45\n\n        Args\uff1a\n            vertices\uff1a torch.Tensor(1*n) -- \u9700\u8981\u67e5\u8be2\u51fa\u5ea6\u90bb\u5c45\u7684\u8282\u70b9\u5217\u8868\n\n        Returns:\n            result: torch.Tensor(n * m) -- \u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u7684\u51fa\u5ea6\u90bb\u5c45\u5217\u8868 n:vertices\u957f\u5ea6  m: graph\u3002num_vertices - 1\n            mask: torch.Tensor(n * m) -- \u5217\u8868\u63a9\u7801\uff0c\u5bf9\u5e94\u4f4d\u7f6e\u662f\u90bb\u5c45\u4e3aTrue \u5426\u5219\u4e3aFalse\n\n        Examples:\n            graph: [0,1] [0,2] [0,3] [1,2] [1,3] [2,3]\n            result: tensor([[ 1,  2,  3],    mask: tensor([[ True,  True,  True],\n                           [ 2,  3, -1],                   [ True,  True, False],\n                           [ 3, -1, -1]])                  [ True, False, False]])\n        \"\"\"\n        assert torch.all(vertices < self.num_vertices)\n        starts = self.row_ptr[vertices]\n        ends = self.row_ptr[vertices + 1]\n        result, mask = batched_adj_selection(starts, ends)\n        result = torch.where(mask, self.columns[result], torch.ones_like(result) * -1)\n        return result, mask\n    \n    def out_nbrs_csr(self, vertices):\n        \"\"\"\u8fd4\u56de\u6307\u5b9a\u8282\u70b9\u7684\u51fa\u5ea6\u90bb\u5c45\n        \u4ee5CSR \u5b58\u50a8\u7684\u5f62\u5f0f\u8fd4\u56de\u6307\u5b9a\u8282\u70b9\u7684\u51fa\u5ea6\u90bb\u5c45, \u8fd4\u56de\u503c\u4e3a columns, row_ptr\n\n        Args:\n            vertices\uff1a torch.Tensor(1*n) -- \u9700\u8981\u67e5\u8be2\u51fa\u5ea6\u90bb\u5c45\u7684\u8282\u70b9\u5217\u8868\n\n        Returns:\n            result: torch.Tensor -- \u5bf9\u5e94\u8282\u70b9CSR\u683c\u5f0f\u4e0b\u7684columns\n            prt: torch.Tensor  --  \u5bf9\u5e94\u8282\u70b9CSR\u683c\u5f0f\u4e0b\u7684row-ptr\n        \"\"\"\n        assert torch.all(vertices < self.num_vertices)\n        starts = self.row_ptr[vertices]\n        ends = self.row_ptr[vertices + 1]\n        result, ptr = batched_csr_selection(starts, ends)\n        result = self.columns[result]\n        return result, ptr\n    \n    def all_out_nbrs_csr(self):\n        \"\"\"\u8fd4\u56de\u6240\u6709\u8282\u70b9\u7684CSR\u683c\u5f0f\u7684\u51fa\u5ea6\u90bb\u5c45\n\n        Args:\n\n        Returns:\n            columns: torch.Tensor\n            row_ptr: torch.Tensor\n        \"\"\"\n        return self.columns, self.row_ptr\n\n    def in_nbrs(self, vertices):\n        raise NotImplementedError('Not implemented for CSRGraph.')\n    \n    def in_nbrs_csr(self, vertices):\n        raise NotImplementedError('Not implemented for CSRGraph.')\n    \n    def all_in_nbrs_csr(self):\n        raise NotImplementedError('Not implemented for CSRGraph.')\n     \n    def out_edges(self, vertices):\n        \"\"\"\u83b7\u53d6\u6307\u5b9a\u8282\u70b9\u7684\u51fa\u8fb9\n\n         Args\uff1a\n        vertices\uff1a torch.Tensor(1*n) -- \u9700\u8981\u67e5\u8be2\u51fa\u8fb9\u7684\u8282\u70b9\u5217\u8868\n\n        Returns:\n            result: torch.Tensor(n * m) -- \u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u7684\u51fa\u8fb9\u5217\u8868 n:vertices\u957f\u5ea6  m: graph\u3002num_vertices - 1\n            mask: torch.Tensor(n * m) -- \u5217\u8868\u63a9\u7801\uff0c\u5bf9\u5e94\u4f4d\u7f6e\u662f\u4e00\u6761\u51fa\u8fb9\u4e3a True \u5426\u5219\u4e3a False\n\n        Examples:\n            graph: [0,1] [0,2] [0,3] [1,2] [1,3] [2,3]\n            result: tensor([[ 0, 1, 2],    mask: tensor([[ True,  True,  True],\n                            [ 3, 4, -1],                 [ True,  True, False],\n                            [ 5, -1, -1]])               [ True, False, False]])\n        \"\"\"\n        assert torch.all(vertices < self.num_vertices)\n        starts = self.row_ptr[vertices]\n        ends = self.row_ptr[vertices + 1]\n        result, mask = batched_adj_selection(starts, ends)\n        return result, mask\n    \n    def all_out_edges_csr(self):\n        \"\"\"\u8fd4\u56de\u6240\u6709\u8282\u70b9\u7684\u51fa\u8fb9\n\n        \u8fd4\u56de\u4ee5CSR\u683c\u5f0f\u8868\u793a\u7684\u6240\u6709\u8282\u70b9\u7684\u51fa\u8fb9\n\n        Returns:\n            columns: torch.Tensor\n            row_ptr: torch.Tensor\n        \"\"\"\n        return torch.arange(self.num_edges, device=self.device), self.row_ptr\n    \n    def out_edges_csr(self, vertices):\n        \"\"\"\u8fd4\u56de\u6307\u5b9a\u8282\u70b9\u7684CSR\u5b58\u50a8\u683c\u5f0f\n        \u4ee5CSR \u5b58\u50a8\u7684\u5f62\u5f0f\u8fd4\u56de\u6307\u5b9a\u8282\u70b9\u7684\u51fa\u5ea6\u90bb\u5c45, \u8fd4\u56de\u503c\u4e3a columns, row_ptr\n\n        Args:\n            vertices\uff1a torch.Tensor(1*n) -- \u9700\u8981\u67e5\u8be2\u51fa\u5ea6\u90bb\u5c45\u7684\u8282\u70b9\u5217\u8868\n\n        Returns:\n            result: torch.Tensor -- \u5bf9\u5e94\u8282\u70b9CSR\u683c\u5f0f\u4e0b\u7684columns\n            prt: torch.Tensor  --  \u5bf9\u5e94\u8282\u70b9CSR\u683c\u5f0f\u4e0b\u7684row-ptr\n\n        \"\"\"\n        assert torch.all(vertices < self.num_vertices)\n        starts = self.row_ptr[vertices]\n        ends = self.row_ptr[vertices + 1]\n        result, ptr = batched_csr_selection(starts, ends)\n        return result, ptr\n    \n    def in_edges(self, vertices):\n        raise NotImplementedError('Not implemented for CSRGraph.')\n    \n    def in_edges_csr(self, vertices):\n        raise NotImplementedError('Not implemented for CSRGraph.')\n    \n    def all_in_edges_csr(self):\n        raise NotImplementedError('Not implemented for CSRGraph.')\n    \n    @property\n    def device(self):\n        \"\"\"\n        return the device where the graph resides.\n        :return: device\n        \"\"\"\n        col_ind_dev = self.columns.device\n        row_ind_dev = self.row_ptr.device\n        assert col_ind_dev == row_ind_dev, \"Graph is not on the same device.\"\n        \n        return col_ind_dev\n        \n    def to(self, *args, **kwargs):\n        \"\"\"\n        Move the graph to the specified device.\n        \n        :return: None\n        \"\"\"\n        self.columns = self.columns.to(*args, **kwargs)\n        self.row_ptr = self.row_ptr.to(*args, **kwargs)\n        self.out_degrees = self.out_degrees.to(*args, **kwargs)\n        # check\n        if self.vertices_t != None:\n            self.vertices_t = self.vertices_t.to(*args, **kwargs)\n        \n    def pin_memory(self):\n        \"\"\"\u9501\u9875\u673a\u5236\n        \u9501\u9875\u673a\u5236\uff0c\u5c06\u6570\u636e\u6307\u5b9a\u5b58\u50a8\u5728\u5185\u5b58\u4e2d, \u6307\u5b9aos\u4e0d\u4f1a\u5c06\u8be5\u6570\u636e\u6362\u51fa\u5230\u865a\u62df\u5185\u5b58\u4e2d\n        \u8282\u7701\u6570\u636e\u6362\u5165\u6362\u51fa\u65f6\u95f4\uff0c\u63d0\u9ad8\u6267\u884c\u6548\u7387\n\n        \"\"\"\n        self.columns = self.columns.pin_memory()\n        self.row_ptr = self.row_ptr.pin_memory()\n    \n    def csr_subgraph(self, vertices: torch.Tensor):\n        \"\"\"\u83b7\u53d6CSR\u683c\u5f0f\u5b50\u56fe\n        \u6839\u636e\u4f20\u5165\u7684\u8282\u70b9\u96c6\u5408, \u751f\u6210\u5b50\u56fe. \u751f\u6210\u7684\u5b50\u56fe\u4e2d\u5305\u542b\u8282\u70b9\u96c6\u5408\u4e2d\u6bcf\u4e00\u4e2a\u8282\u70b9\u7684\u6240\u6709\u90bb\u5c45\u8282\u70b9\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5728\u8282\u70b9\u96c6\u5408\u4e2d\u7684\u90bb\u5c45\u8282\u70b9\u3002\n        \u8fd9\u6837\u7684\u5b50\u56fe\u5206\u5272\u65b9\u5f0f\u4fbf\u4e8e\u540e\u7eed\u7684\u5206\u5272\u8ba1\u7b97\n\n        Args:\n            vertices: torch.Tensor -- \u8282\u70b9\u96c6\u5408\n\n        Returns:\n            subgraph: CSRGraph -- \u6839\u636e\u8282\u70b9\u96c6\u5408\u5f97\u5230\u7684CSR\u683c\u5f0f\u7684\u5b50\u56fe\n            indices:\n        \"\"\"\n        sub_degrees = self.out_degrees[vertices]\n        sub_row_ptr = torch.cat([torch.tensor([0], dtype=torch.int64, device=self.device), sub_degrees.cumsum(0)])\n        # fetch sub_columns\n        # starts, ends = sub_row_ptr[:-1], sub_row_ptr[1:]\n        # starts, ends = starts[vertices], ends[vertices]\n\n        # \u83b7\u53d6\u6bcf\u4e2a\u8282\u70b9\u6240\u5bf9\u5e94columns\u7d22\u5f15\u7684\u8d77\u59cb\u4f4d\u7f6e\u548c\u7ec8\u6b62\u4f4d\u7f6e\n        starts, ends = self.row_ptr[vertices], self.row_ptr[vertices + 1]\n        # size: torch.Tensor\n        sizes = (ends - starts)\n        # size.sum \u5373\u4e3a\u6240\u6709\u8282\u70b9\u8fb9\u7684\u603b\u6570\n        ranges = torch.arange(sizes.sum(), device=self.device)\n        # \u83b7\u53d6 indices subgraph \u4e2d\u7684columns\u5230 original graph\u7684columns\u4e2d\u7684\u6620\u5c04\n        indices = ranges + starts.repeat_interleave(sizes) - (sub_row_ptr[:-1]).repeat_interleave(sizes)\n        sub_columns = self.columns[indices]\n        \n        # fetch attributes  \u6839\u636e\u7d22\u5f15\u6620\u5c04 indices \u83b7\u53d6subgraph\u4e2d\u7684\u8fb9\u5c5e\u6027\u548c\u70b9\u5c5e\u6027\n        sub_vertex_attrs_tensor, sub_vertex_attrs_mask = None, None\n        if self.vertex_attrs_tensor is not None:\n            sub_vertex_attrs_tensor = self.vertex_attrs_tensor[vertices]\n            sub_vertex_attrs_mask = self.vertex_attrs_mask[vertices]\n        sub_edge_attrs_tensor, sub_edge_attrs_mask = None, None\n        if self.edge_attrs_tensor is not None:\n            sub_edge_attrs_tensor = self.edge_attrs_tensor[indices]\n            sub_edge_attrs_mask = self.edge_attrs_mask[indices]\n        \n        return CSRGraph(sub_columns, sub_row_ptr, self.directed, self.vertex_attrs_list,\n                        sub_vertex_attrs_tensor, sub_vertex_attrs_mask,\n                        self.edge_attrs_list, sub_edge_attrs_tensor, sub_edge_attrs_mask), indices\n        \n    def subgraph(self, vertices: torch.Tensor):\n        \"\"\"\n\n        Args:\n            vertices: torch.Tensor -- \u5b50\u56fe\u6240\u542b\u6709\u7684\u8282\u70b9\n\n        Returns:\n            subgraph: CSRGraph -- \u6839\u636e\u5b50\u56fe\u8282\u70b9\u751f\u6210\u7684CSR\u683c\u5f0f\u5b58\u50a8\u7684Graph\n            new_vertices_to_od:\n        \"\"\"\n        # map\n        # new_vertices_to_old = vertices.sort().unique_consecutive()\n        # \u5148\u53bb\u91cd\uff0c\u518d\u6392\u5e8f\n        new_vertices_to_old = vertices.unique_consecutive().sort()[0]\n        print(new_vertices_to_old)\n        old_vertices_to_new = {}\n        for i, v in enumerate(new_vertices_to_old):\n            old_vertices_to_new[v] = i\n        # to LIL\n        all_nbrs = []\n        new_nbrs_list = []\n        lengths = [0]\n        for i in range(len(self.row_ptr) - 1):\n            all_nbrs = self.columns[self.row_ptr[i]:self.row_ptr[i+1]]\n        # leave specified vertices in LIL\n        for nbrs in all_nbrs:\n            nbrs = nbrs[torch.where(nbrs in vertices)[0]]\n            for i, e in enumerate(nbrs):\n                nbrs[i] = old_vertices_to_new[e]\n            new_nbrs_list.append(nbrs)\n            lengths.append(len(nbrs))\n        # LIL to CSR\n        new_nbrs = torch.cat(new_nbrs_list)\n        ptr = torch.tensor(lengths, dtype=torch.int64, device=self.device).cumsum(0)\n        return CSRGraph(new_nbrs, ptr), new_vertices_to_old\n\n    def get_vertex_attr(self, vertices, attr):\n        assert torch.all(vertices < self.num_vertices)\n        attr_id = self.vertex_attrs_map[attr]\n        return self.vertex_attrs[attr_id][vertices]\n    \n    def select_vertex_by_attr(self, attr, cond):\n        attr_id = self.vertex_attrs_map[attr]\n        return torch.where(cond(self.vertex_attrs[attr_id]))[0]\n    \n    def set_vertex_attr(self, vertices, attr, value, mask):\n        assert torch.all(vertices < self.num_vertices)\n        attr_id = self.vertex_attrs_map[attr]\n        self.vertex_attrs[attr_id][vertices] = torch.where(mask, value, self.vertex_attrs[attr_id][vertices])\n    \n    def get_edge_attr(self, edges, attr):\n        assert torch.all(edges < self.num_edges)\n        attr_id = self.edge_attrs_map[attr]\n        return self.edge_attrs[attr_id][edges]\n    \n    def select_edge_by_attr(self, attr, cond):\n        attr_id = self.edge_attrs_map[attr]\n        return torch.where(cond(self.edge_attrs[attr_id]))[0]\n    \n    def set_edge_attr(self, edges, attr, value, mask):\n        assert torch.all(edges < self.num_edges)\n        attr_id = self.edge_attrs_map[attr]\n        self.edge_attrs[attr_id][edges] = torch.where(mask, value, self.edge_attrs[attr_id][edges])\n\n    @staticmethod\n    def edge_list_to_Graph(edge_starts, edge_ends, directed=False, vertices=None, edge_attrs=None, edge_attrs_list=[], vertex_attrs=None, vertex_attrs_list=[]):\n        \"\"\"\u5c06edge_list\u7684\u56fe\u8868\u793a\u5f62\u5f0f\u8f6c\u6362\u4e3a CSRGraph\u683c\u5f0f\n\n        Read edge_lists and return an according CSRGraph.\n        \n        :param np.array edge_starts: starting points of edges\n        :param np.array edge_ends: ending points of edges\n        :param bool directed: whether the graph is directed\n        :param np.array vertices: vertices. can be None\n        :param List[np.array] edge_attrs: a list data for each edge\n        :param List edge_attrs_list: a list of edge attributes (preferably strings, like names of the attributes)\n        :param List[np.array] vertex_attrs: a list data for each vertex (in the same order as vertices. please don't set vertices=None if you use this)\n        :param List vertex_attrs_list: a list of vertex attributes (preferably strings, like names of the attributes)\n        :return: CSRGraph, a dictionary of vertex to index, and a list of edge data in Tensor and CSR order\n\n        Returns:\n            graph: CSRGraph -- \u751f\u6210\u7684CSR\u5b58\u50a8\u683c\u5f0f\u7684\u56fe\n            vertex_to_index: dictionary -- map vertex to index\n        \"\"\"\n        if vertices is None:\n            vertices = np.array([], dtype=np.int64)\n            for s, d in zip(edge_starts, edge_ends):\n                vertices = np.append(vertices, s)\n                vertices = np.append(vertices, d)\n            vertices = np.unique(np.sort(vertices))\n            \n        # get vertex to index mapping\n        vertex_to_index = {}\n        # vertex_data_list = [[], [], []]\n        vertex_data_list = [[] for _ in range(len(vertex_attrs_list))]\n        # \u5efa\u7acb\u8282\u70b9\u5230\u7d22\u5f15\u7684\u6620\u5c04, \u7d22\u5f15\u4ece0\u5f00\u59cb\n        for vertex, index in zip(vertices, range(len(vertices))):\n            vertex_to_index[vertex] = index\n            if vertex_attrs is not None:\n                for data_index, data in enumerate(vertex_attrs):\n                    vertex_data_list[data_index].append(data[vertex])  # maybe it should be:\n                    # vertex_data_list[data_index].append(data[index])\n\n        # sort edge lists into val, col_ind, and row_ind\n        num_vertices = len(vertices)\n        num_data = len(edge_attrs)\n        col_ind_list = [[] for _ in range(num_vertices)]\n        data_list = [[[] for _ in range(num_vertices)] for _ in range(num_data)]\n        for start, end, *data in zip(edge_starts, edge_ends, *edge_attrs):\n            start_v = vertex_to_index[start]\n            end_v = vertex_to_index[end]\n            col_ind_list[start_v].append(end_v)\n            if not directed: # undirected\n                col_ind_list[end_v].append(start_v)\n            for d in range(num_data):\n                data_list[d][start_v].append(data[d])\n                if not directed:\n                    data_list[d][end_v].append(data[d])  \n                      \n        if not directed:  # unique\n            for i in range(len(col_ind_list)):\n                col_ind_list[i] = np.unique(col_ind_list[i]).tolist()\n\n        col_ind = torch.zeros(sum([len(l) for l in col_ind_list]), dtype=torch.int64)\n        row_ind = torch.zeros(num_vertices + 1, dtype=torch.int64)\n        data_tensor = [torch.zeros(sum([len(l) for l in col_ind_list]), dtype=torch.int64) for _ in range(num_data)]\n        curr_index = 0\n        for l, v, *d in zip(col_ind_list, range(num_vertices), *data_list):\n            col_ind[curr_index:curr_index + len(l)] = torch.tensor(l, dtype=torch.int64)\n            row_ind[v] = curr_index\n            for d2 in range(num_data):\n                data_tensor[d2][curr_index:curr_index + len(l)] = torch.tensor(d[d2], dtype=torch.float32)\n            curr_index += len(l)\n        row_ind[-1] = curr_index\n        if len(data_tensor) != 0:\n            edge_attrs_tensor = torch.stack(data_tensor, dim=0)\n            edge_attrs_mask = torch.ones(edge_attrs_tensor.shape, dtype=torch.bool)\n        else:\n            edge_attrs_tensor, edge_attrs_mask = None, None\n        if vertex_attrs is not None:\n            vertex_attrs_tensor = torch.stack([torch.tensor(l, dtype=torch.float32) for l in vertex_data_list], dim=0)\n            vertex_attrs_mask = torch.ones(vertex_attrs_tensor.shape, dtype=torch.bool)\n        else:\n            vertex_attrs_tensor = None\n            vertex_attrs_mask = None\n        return CSRGraph(col_ind, row_ind, directed, vertex_attrs_list, \n                        vertex_attrs_tensor, vertex_attrs_mask, edge_attrs_list,\n                        edge_attrs_tensor, edge_attrs_mask), vertex_to_index\n        \n    @staticmethod\n    def read_graph(f, split=None, directed=False, edge_attrs_list=[]):\n        \"\"\"\n        Read an edgelist file and return an according CSRGraph.\n        Edge lists should has the following format:\n        v_0[split]v_1\n        values will default to .0.\n        By default, graphs are stored in CPU.\n        \n        :param str f: filename for edge list\n        :param str split: split string for each line\n        :param bool directed: whether the graph is directed\n        :return: CSRGraph and a dictionary of vertex to index   `\n        \"\"\"\n        edge_starts, edge_ends, vertices, data = Graph.read_edgelist(f, split)\n        return CSRGraph.edge_list_to_Graph(edge_starts, edge_ends, directed, vertices, edge_attrs=data, edge_attrs_list=edge_attrs_list)\n", 468], "/root/Project/TCRGraph/src/type/CSCGraph.py": ["\"\"\"\nA Graph type implemented with CSC (compressed sparse column) type.\n\"\"\"\n\nimport torch\nfrom .CSRGraph import CSRGraph\nfrom .Graph import Graph\nimport numpy as np\n\nclass CSCGraph(Graph):\n    \"\"\"\n    CSC (compressed sparse column) implementation of graphs. Efficient access to in_nbrs. This is implemented as an adapter to CSRGraph.\n    \"\"\"\n    def __init__(self,\n                 rows: torch.Tensor=None,\n                 column_ptr: torch.Tensor=None,\n                 csr: CSRGraph=None,\n                 directed=False,\n                 vertex_attrs_list=[],\n                 vertex_attrs_tensor: torch.Tensor=None,\n                 vertex_attrs_mask: torch.Tensor=None,\n                 edge_attrs_list=[],\n                 edge_attrs_tensor: torch.Tensor=None,\n                 edge_attrs_mask: torch.Tensor=None):\n        \"\"\"\n        Initialize a CSCGraph object with according datatypes (tensors).\n        \n        :param Tensor rows: in-neighbors of vertex (arranged in order)\n        :param Tensor column_ptr: pointers of each vertex for val and row_ind\n        :param bool directed: whether the graph is directed\n        :param list vertex_attrs_list: list of vertex attributes names\n        :param Tensor vertex_attrs_tensor: tensor of vertex attributes that stores data\n        :param Tensor vertex_attrs_mask: mask of vertex attributes\n        :param list edge_attrs_list: list of edge attributes names\n        :param Tensor edge_attrs_tensor: tensor of edge attributes that stores data\n        :param Tensor edge_attrs_mask: mask of edge attributes\n        :return: None\n        \"\"\"\n        super().__init__(directed)\n        if csr is not None:\n            self.csr = csr\n        else:\n            self.csr = CSRGraph(columns=rows, \n                                row_ptr=column_ptr, \n                                directed=directed,\n                                vertex_attrs_list=vertex_attrs_list,\n                                vertex_attrs_tensor=vertex_attrs_tensor,\n                                vertex_attrs_mask=vertex_attrs_mask,\n                                edge_attrs_list=edge_attrs_list,\n                                edge_attrs_tensor=edge_attrs_tensor,\n                                edge_attrs_mask=edge_attrs_mask,)\n        \n    @property\n    def num_vertices(self):\n        return self.csr.num_vertices\n    \n    @property\n    def num_edges(self):\n        return self.csr.num_edges\n    \n    def out_degree(self, vertices):\n        return self.csr.in_degree(vertices)\n    \n    def in_degree(self, vertices):\n        return self.csr.out_degree(vertices)\n    \n    def out_nbrs(self, vertices):\n        raise NotImplementedError('Not implemented for CSCGraph.')\n    \n    def out_nbrs_csr(self, vertices):\n        return self.csr.in_nbrs_csr(vertices)\n    \n    def all_out_nbrs_csr(self):\n        return self.csr.all_in_nbrs_csr()\n    \n    def in_nbrs(self, vertices):\n        return self.csr.out_nbrs(vertices)\n    \n    def in_nbrs_csr(self, vertices):\n        return self.csr.out_nbrs_csr(vertices)\n    \n    def all_in_nbrs_csr(self):\n        return self.csr.all_out_nbrs_csr()\n    \n    def out_edges(self, vertices):\n        raise NotImplementedError('Not implemented for CSCGraph.')\n    \n    def out_edges_csr(self, vertices):\n        return self.csr.in_edges_csr(vertices)\n    \n    def all_out_edges_csr(self):\n        return self.csr.all_in_edges_csr()\n    \n    def in_edges(self, vertices):\n        return self.csr.out_edges(vertices)\n    \n    def in_edges_csr(self, vertices):\n        return self.csr.out_edges_csr(vertices)\n    \n    def all_in_edges_csr(self):\n        return self.csr.all_out_edges_csr()\n    \n    @property\n    def device(self):\n        return self.csr.device\n    \n    def to(self, *args, **kwargs):\n        self.csr.to(*args, **kwargs)\n        \n    def pin_memory(self):\n        self.csr.pin_memory()\n        \n    def subgraph(self, vertices):\n        csr, n_to_o, _ = self.csr.subgraph(vertices)\n        return CSCGraph(csr=csr, directed=csr.directed), n_to_o\n    \n    def csr_subgraph(self, vertices: torch.Tensor):\n        csr, indices = self.csr.csr_subgraph(vertices)\n        return CSCGraph(csr=csr, directed=csr.directed), indices\n    \n    def get_vertex_attr(self, vertices, attr):\n        return self.csr.get_vertex_attr(vertices, attr)\n    \n    def select_vertex_by_attr(self, attr, cond):\n        return self.csr.select_vertex_by_attr(attr, cond)\n    \n    def set_vertex_attr(self, vertices, attr, value, mask):\n        return self.csr.set_vertex_attr(vertices, attr, value, mask)\n    \n    def get_edge_attr(self, edges, attr):\n        return self.csr.get_edge_attr(edges, attr)\n    \n    def select_edge_by_attr(self, attr, cond):\n        return self.csr.select_edge_by_attr(attr, cond)\n    \n    def set_edge_attr(self, edges, attr, value, mask):\n        return self.csr.set_edge_attr(edges, attr, value, mask)\n        \n    @staticmethod\n    def edge_list_to_Graph(edge_starts, edge_ends, directed=False, vertices=None, edge_attrs=None, edge_attrs_list=[], vertex_attrs=None, vertex_attrs_list=[]):\n        csr, vtid, tensors = CSRGraph.edge_list_to_Graph(edge_ends, edge_starts, directed=directed, vertices=vertices, edge_attrs=edge_attrs,\n                                                         edge_attrs_list=edge_attrs_list, vertex_attrs=vertex_attrs, vertex_attrs_list=vertex_attrs_list)\n        return CSCGraph(csr=csr, directed=directed), vtid, tensors\n        \n    @staticmethod\n    def read_graph(f, split=' ', directed=False):\n        edge_starts, edge_ends, vertices, data = Graph.read_edgelist(f, split)\n        return CSCGraph.edge_list_to_Graph(edge_starts, edge_ends, directed=directed, vertices=vertices)\n    ", 148], "/root/Project/TCRGraph/src/type/CSRCGraph.py": ["\"\"\"\nA Graph type implemented with CSRC (CSR + CSC).\n\"\"\"\nfrom .Graph import Graph\nfrom .CSRGraph import CSRGraph\nfrom .CSCGraph import CSCGraph\nimport torch\nimport numpy as np\n\nclass CSRCGraph(Graph):\n    \"\"\"\n    CSR + CSC implementation of Graph. Efficient access to out_nbrs and in_nbrs. Assume the graph is directed. (otherwise use CSRGraph). Provides a mapping from CSC row indices to CSR column indices.\n    \"\"\"\n    def __init__(self,\n                 shuffle_ptr: torch.Tensor,\n                 columns: torch.Tensor=None,\n                 row_ptr: torch.Tensor=None,\n                 rows: torch.Tensor=None,\n                 column_ptr: torch.Tensor=None,\n                 csr: CSRGraph=None,\n                 csc: CSCGraph=None,\n                 vertex_attrs_list=[],\n                 vertex_attrs_tensor: torch.Tensor=None,\n                 vertex_attrs_mask: torch.Tensor=None,\n                 edge_attrs_list=[],\n                 edge_attrs_tensor: torch.Tensor=None,\n                 edge_attrs_mask: torch.Tensor=None):\n        \"\"\"\n        Initialize a CSRCGraph object with according datatypes (tensors).\n        \n        :param Tensor columns: out-neighbors of vertex (arranged in order) (for CSR)\n        :param Tensor row_ptr: pointers of each vertex for val and col_ind (for CSR)\n        :param Tensor rows: in-neighbors of vertex\n        (arranged in order) (for CSC)\n        :param Tensor column_ptr: pointers of each vertex for val and row_ind (for CSC)\n        :param Tensor shuffle_ptr: pointers from CSC rows to CSR columns.  rows = edge_start[shuffle_ptr] (edge_start = rows.sort())\n        :param list vertex_attrs_list: list of vertex attributes names\n        :param Tensor vertex_attrs_tensor: tensor of vertex attributes that stores data\n        :param Tensor vertex_attrs_mask: mask of vertex attributes\n        :param list edge_attrs_list: list of edge attributes names\n        :param Tensor edge_attrs_tensor: tensor of edge attributes that stores data\n        :param Tensor edge_attrs_mask: mask of edge attributes\n        \"\"\"\n        # \u4f7f\u7528 CSR-C \u683c\u5f0f\u9ed8\u8ba4\u4e3a\u6709\u5411\u56fe, \u5426\u5219\u76f4\u63a5\u4f7f\u7528CSR\u683c\u5f0f, \u51fa\u8fb9\u5373\u4e3a\u5165\u8fb9,\n        super().__init__(directed=True)\n        if csr is not None:\n            self.csr = csr\n        else:\n            self.csr = CSRGraph(columns=columns, row_ptr=row_ptr, directed=True,\n                                vertex_attrs_list=vertex_attrs_list, vertex_attrs_tensor=vertex_attrs_tensor, vertex_attrs_mask=vertex_attrs_mask,\n                                edge_attrs_list=edge_attrs_list, edge_attrs_tensor=edge_attrs_tensor, edge_attrs_mask=edge_attrs_mask,)\n        if csc is not None:\n            self.csc = csc\n        else:\n            self.csc = CSCGraph(rows=rows, column_ptr=column_ptr, directed=True)\n        self.shuffle_ptr = shuffle_ptr\n                    \n    @property\n    def num_vertices(self):\n        return self.csr.num_vertices\n    \n    @property\n    def num_edges(self):\n        return self.csr.num_edges\n    \n    def out_degree(self, vertices):\n        return self.csr.out_degree(vertices)\n    \n    def in_degree(self, vertices):\n        return self.csc.in_degree(vertices)\n    \n    def out_nbrs(self, vertices):\n        return self.csr.out_nbrs(vertices)\n    \n    def out_nbrs_csr(self, vertices):\n        return self.csr.out_nbrs_csr(vertices)\n    \n    def all_out_nbrs_csr(self):\n        return self.csr.all_out_nbrs_csr()\n    \n    def in_nbrs(self, vertices):\n        return self.csc.in_nbrs(vertices)\n    \n    def in_nbrs_csr(self, vertices):\n        return self.csc.in_nbrs_csr(vertices)\n    \n    def all_in_nbrs_csr(self):\n        return self.csc.all_in_nbrs_csr()\n    \n    def out_edges(self, vertices):\n        return self.csr.out_edges(vertices)\n    \n    def out_edges_csr(self, vertices):\n        return self.csr.out_edges_csr(vertices)\n    \n    def all_out_edges_csr(self):\n        return self.csr.all_out_edges_csr()\n    \n    def in_edges(self, vertices):\n        csc_in_edges, csc_masks = self.csc.in_edges(vertices)\n        # in_edges = self.shuffle_ptr[csc_in_edges]\n        in_edges = torch.where(csc_masks, self.shuffle_ptr[csc_in_edges], torch.ones_like(csc_in_edges) * -1)\n        return in_edges, csc_masks\n    \n    def in_edges_csr(self, vertices):\n        csc_in_edges, ptr = self.csc.in_edges_csr(vertices)\n        in_edges = self.shuffle_ptr[csc_in_edges]\n        return in_edges, ptr\n    \n    def all_in_edges_csr(self, vertices):\n        return self.shuffle_ptr, self.csc.csr.row_ptr\n    \n    @property\n    def device(self):\n        return self.csr.device\n    \n    def to(self, *args, **kwargs):\n        if self.vertices_t is not None:\n            self.vertices_t = self.vertices_t.to(*args, **kwargs)\n        if self.edges_t is not None:\n            self.edges_t = self.edges_t.to(*args, **kwargs)\n        self.csr.to(*args, **kwargs)\n        self.csc.to(*args, **kwargs)\n        self.shuffle_ptr = self.shuffle_ptr.to(*args, **kwargs)\n        \n    def pin_memory(self):\n        self.csr.pin_memory()\n        self.csc.pin_memory()\n        self.shuffle_ptr = self.shuffle_ptr.pin_memory()\n        \n    def subgraph(self, vertices: torch.Tensor):\n        \"\"\"\n        Get a subgraph induced by the given vertices.\n        \"\"\"\n        # First convert to edge list, then convert to CSRCGraph\n        edge_starts = []\n        edge_ends = []\n        for v in vertices:\n            for nbr in self.out_nbrs(v):\n                if nbr in vertices:\n                    edge_starts.append(v)\n                    edge_ends.append(nbr)\n        return CSRCGraph.edge_list_to_Graph(edge_starts, edge_ends)\n    \n    def csr_subgraph(self, vertices: torch.Tensor):\n        new_csr, indices_csr = self.csr.csr_subgraph(vertices)\n        new_csc, indices_csc = self.csc.csr_subgraph(vertices)\n        new_shuffle_ptr = self.shuffle_ptr[indices_csc]\n        return CSRCGraph(csr=new_csr, csc=new_csc, shuffle_ptr=new_shuffle_ptr), \\\n            indices_csr\n    \n    def get_vertex_attr(self, vertices, attr):\n        return self.csr.get_vertex_attr(vertices, attr)\n    \n    def select_vertex_by_attr(self, attr, cond):\n        return self.csr.select_vertex_by_attr(attr, cond)\n    \n    def set_vertex_attr(self, vertices, attr, value, mask):\n        return self.csr.set_vertex_attr(vertices, attr, value, mask)\n    \n    def get_edge_attr(self, edges, attr):\n        return self.csr.get_edge_attr(edges, attr)\n    \n    def select_edge_by_attr(self, attr, cond):\n        return self.csr.select_edge_by_attr(attr, cond)\n    \n    def set_edge_attr(self, edges, attr, value, mask):\n        return self.csr.set_edge_attr(edges, attr, value, mask)\n        \n    @staticmethod\n    def edge_list_to_Graph(edge_starts, edge_ends, vertices=None, edge_attrs=None, edge_attrs_list=[], vertex_attrs=None, vertex_attrs_list=[]):\n        # get vertex to index mapping  \u6ce8\u610f\u6b64\u65f6\u7684Vertex\u672c\u8eab\u6709\u5e8f\u4e14\u4e3aUnique\n        vertex_to_index = {}\n        vertex_data_list = [[] for _ in range(len(vertex_attrs_list))]\n        for vertex, index in zip(vertices, range(len(vertices))):\n            if index == 0:\n                import logging\n                logging.info(vertex)\n            vertex_to_index[vertex] = index\n            if vertex_attrs is not None:\n                for data_index, data in enumerate(vertex_attrs):\n                    vertex_data_list[data_index].append(data[vertex])\n        # Change edge_starts and edge_ends to indices by dictionary 'vertex_to_index'\n        edge_starts = torch.LongTensor([vertex_to_index[i] for i in edge_starts])\n        edge_ends = torch.LongTensor([vertex_to_index[i] for i in edge_ends])\n        # print(\"edge_starts: {}\".format(edge_starts))\n        # print(\"edge_ends: {}\".format(edge_ends))\n        data_tensors = [torch.FloatTensor(i) for i in edge_attrs]\n        # Conduct counter sort\n        row_ptr, pos_sources = CSRCGraph.counter_sort(edge_starts, len(vertices))\n        columns = edge_ends[pos_sources]\n\n        # \u6839\u636epos_sources \u6765\u518d\u6b21\u66f4\u65b0 edge_start  edge_end\n        # \u6b64\u65f6edge_ends = columns\n        edge_starts = edge_starts[pos_sources]\n        edge_ends = edge_ends[pos_sources]\n        for t in data_tensors:\n            t = t[pos_sources]\n        column_ptr, pos_targets = CSRCGraph.counter_sort(edge_ends, len(vertices))\n        rows = edge_starts[pos_targets]\n        \n        if len(data_tensors) != 0:\n            edge_attrs_tensor = torch.stack(data_tensors, dim=0)\n            edge_attrs_mask = torch.ones(edge_attrs_tensor.shape, dtype=torch.bool)\n        else:\n            edge_attrs_tensor, edge_attrs_mask = None, None\n        if vertex_attrs is not None:\n            vertex_attrs_tensor = torch.stack([torch.tensor(l, dtype=torch.float32) for l in vertex_data_list], dim=0)\n            vertex_attrs_mask = torch.ones(vertex_attrs_tensor.shape, dtype=torch.bool)\n        else:\n            vertex_attrs_tensor = None\n            vertex_attrs_mask = None\n        return CSRCGraph(\n            shuffle_ptr=pos_targets,\n            columns=columns,\n            row_ptr=row_ptr,\n            rows=rows,\n            column_ptr=column_ptr,\n            vertex_attrs_tensor=vertex_attrs_tensor,\n            vertex_attrs_list=vertex_attrs_list,\n            vertex_attrs_mask=vertex_attrs_mask,\n            edge_attrs_tensor=edge_attrs_tensor,\n            edge_attrs_list=edge_attrs_list,\n            edge_attrs_mask=edge_attrs_mask\n        ), vertex_to_index, data_tensors\n    \n    @staticmethod\n    def read_graph(f, split=None):\n        edge_starts, edge_ends, vertices, data = Graph.read_edgelist(f, split)\n        return CSRCGraph.edge_list_to_Graph(edge_starts, edge_ends, vertices=vertices, edge_attrs=data)\n    \n    @staticmethod\n    def counter_sort(tensor: torch.Tensor, num_vertices):\n        \"\"\"\n        Implements counter sort. counts[i] is the number of elements in tensor that are less than or equal to i. pos[i] is the position of the i-th smallest element in tensor.\n        \"\"\"\n        counts = torch.cumsum(torch.bincount(tensor, minlength=num_vertices), dim=-1)\n        counts = torch.cat((torch.tensor([0]), counts))\n        # \u83b7\u53d6\u7d22\u5f15\u503c\u6570\u7ec4\n        \"\"\"\n        \u4ee5 tensor = edge_start \u6765\u4e3e\u4f8b\u8bf4\u660e torch.argsort() \u5728\u8fd9\u91cc\u7684\u4f5c\u7528:\n        \u5728\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u83b7\u53d6\u5230 columns, \u6211\u4eec\u77e5\u9053\u6211\u4eec\u9700\u8981\u7684 columns \u53ef\u4ee5\u901a\u8fc7 edge_end[pos] \u8fd9\u79cd\u6620\u5c04\u6765\u83b7\u53d6, \u6620\u5c04\u6570\u7ec4 pos \u5373\u4e3a\u6211\u4eec\u6240\u6c42\n        >>> edge_start = torch.LongTensor([0, 0, 0, 2, 1, 1])\n        >>> edge_end   = torch.LongTensor([1, 2, 3, 3, 2, 3])\n        >>> pos = torch.argsort(edge_start)\n            pos = tensor([0, 1, 2, 4, 5, 3])\n        \u6b64\u65f6pos\u4e2d\u7684\u503c\u4e3aedge_start \u6570\u7ec4\u7684\u7d22\u5f15, \u6309\u7167\u7d22\u5f15\u5728edge_start\u6570\u7ec4\u4e2d\u5bf9\u5e94\u503c\u7684\u5927\u5c0f\u4ece\u5c0f\u5230\u5927\u6392\u5217\n        \u800c columns \u4e2d\u7684\u503c\u4e5f\u662f\u6309\u7167 row \u503c\u5927\u5c0f\u7684\u987a\u5e8f\u8fdb\u884c\u6392\u5217, \u548c edge_start\u76f8\u5bf9\u5e94\n        columns = edge_end[pos]\n        \"\"\"\n        pos = torch.argsort(tensor)\n        return counts, pos\n", 252], "/root/Project/TCRGraph/src/type/Subgraph.py": ["import sys\nfrom src.type.Graph import Graph\nimport torch\nimport logging\n\nclass Subgraph(Graph):\n    \"\"\"\n    Subgraph only stores part of the original graph (a part of vertices and their neighbors), but has same return values on those vertices as the original graph.\n    \"\"\"\n    def __init__(self, subgraph: Graph, sub_vertices: torch.Tensor, sub_edges: torch.Tensor, \n                 # sub_out_degrees: torch.Tensor, sub_in_degrees: torch.Tensor, \n                 orig_to_sub_vertices: torch.Tensor):\n        super().__init__(subgraph.directed)\n        self.sub_vertices = sub_vertices\n        self.sub_edges = sub_edges\n        self.subgraph = subgraph\n        \n        # stored in CPU, shared between processes\n        # self.sub_out_degrees = sub_out_degrees\n        # self.sub_in_degrees = sub_in_degrees\n        \n        # stored as sparse tensor to prevent memory explosion\n        self.orig_to_sub_vertices = orig_to_sub_vertices\n        \n    def orig_to_sub(self, vertices):\n        # return self.orig_to_sub_vertices.index_select(0, vertices).to_dense()\n        \"\"\"\u83b7\u53d6\u4e0e\u539f\u56fe\u4e2d\u5bf9\u5e94\u7684\u5b50\u56fe\u8282\u70b9\u96c6\u5408\n\n        Args:\n            vertices: torch.Tensor -- \u539f\u56fe\u4e2d\u7684\u8282\u70b9\u96c6\u5408\n\n        Returns:\n            vertices: torch.Tensor -- \u5b50\u56fe\u4e2d\u4e0e\u4e4b\u5bf9\u5e94\u7684\u8282\u70b9\u96c6\u5408\n\n        \"\"\"\n        return self.orig_to_sub_vertices[vertices]\n    \n    @property\n    def num_vertices(self):\n        return self.sub_vertices.numel()\n    \n    @property\n    def device(self):\n        return self.subgraph.device\n    \n    @property\n    def vertices(self):\n        return self.sub_vertices\n    \n    @property\n    def num_edges(self):\n        return self.sub_edges.numel()\n    \n    @property\n    def edges(self):\n        return self.sub_edges\n    \n    def out_degree(self, vertices):\n        # if self.sub_out_degrees is None:\n        #     raise NotImplementedError\n        # return self.sub_out_degrees[vertices.cpu()].to(self.subgraph.device)\n        \"\"\"\u67e5\u8be2\u6307\u5b9a\u8282\u70b9\u51fa\u5ea6\n\n        Args:\n            vertices: \u539f\u56fe\u4e2d\u7684\u8282\u70b9\u96c6\u5408\n\n        Returns:\n            out_degree: torch.Tensor -- \u5148\u8f6c\u6362\u4e3a\u5b50\u56fe\u4e2d\u5bf9\u5e94\u8282\u70b9\u96c6, \u7136\u540e\u5728\u5b50\u56fe\u4e2d\u627e\u5bf9\u5e94\u8282\u70b9\u51fa\u5ea6\n        \"\"\"\n        return self.subgraph.out_degree(self.orig_to_sub(vertices))\n    \n    def in_degree(self, vertices):\n        # if self.sub_in_degrees is None:\n        #     raise NotImplementedError\n        # return self.sub_in_degrees[vertices.cpu()].to(self.subgraph.device)\n        return self.subgraph.in_degree(self.orig_to_sub(vertices))\n    \n    def out_nbrs(self, vertices):\n        return self.subgraph.out_nbrs(self.orig_to_sub(vertices))\n        \n    def in_nbrs(self, vertices):\n        return self.subgraph.in_nbrs(self.orig_to_sub(vertices))\n        \n    def out_nbrs_csr(self, vertices):\n        return self.subgraph.out_nbrs_csr(self.orig_to_sub(vertices))\n        \n    def all_out_nbrs_csr(self):\n        return self.subgraph.all_out_nbrs_csr()\n        \n    def in_nbrs_csr(self, vertices):\n        return self.subgraph.in_nbrs_csr(self.orig_to_sub(vertices))\n    \n    def all_in_nbrs_csr(self):\n        return self.subgraph.all_in_nbrs_csr()\n    \n    def out_edges(self, vertices):\n        return self.subgraph.out_edges(self.orig_to_sub(vertices))\n    \n    def out_edges_csr(self, vertices):\n        return self.subgraph.out_edges_csr(self.orig_to_sub(vertices))\n    \n    def all_out_edges_csr(self):\n        return self.subgraph.all_out_edges_csr()\n    \n    def in_edges(self, vertices):\n        return self.subgraph.in_edges(self.orig_to_sub(vertices))\n    \n    def in_edges_csr(self, vertices):\n        return self.subgraph.in_edges_csr(self.orig_to_sub(vertices))\n    \n    def all_in_edges_csr(self):\n        return self.subgraph.all_in_edges_csr()\n    \n    def to(self, *args, **kwargs):\n        self.sub_vertices = self.sub_vertices.to(*args, **kwargs)\n        self.sub_edges = self.sub_edges.to(*args, **kwargs)\n        self.subgraph.to(*args, **kwargs)\n        # self.sub_out_degrees = self.sub_out_degrees.to(*args, **kwargs)\n        # self.sub_in_degrees = self.sub_in_degrees.to(*args, **kwargs)\n        # self.orig_to_sub_vertices = self.orig_to_sub_vertices.to_sparse().to(*args, **kwargs)\n        self.orig_to_sub_vertices = self.orig_to_sub_vertices.to(*args, **kwargs)\n        # self.orig_to_sub_edges = self.orig_to_sub_edges.to(*args, **kwargs)\n        \n    def pin_memory(self):\n        self.sub_vertices = self.sub_vertices.pin_memory()\n        self.sub_edges = self.sub_edges.pin_memory()\n        self.subgraph.pin_memory()\n        # self.sub_out_degrees = self.sub_out_degrees.pin_memory()\n        # self.sub_in_degrees = self.sub_in_degrees.pin_memory()\n        self.orig_to_sub_vertices = self.orig_to_sub_vertices.pin_memory()\n        # self.orig_to_sub_edges = self.orig_to_sub_edges.pin_memory()\n        \n    def subgraph(self, vertices):\n        raise NotImplementedError\n    \n    def get_vertex_attr(self, vertices, attr):\n        return self.subgraph.get_vertex_attr(self.orig_to_sub(vertices), attr)\n    \n    def select_vertex_by_attr(self, attr, cond):\n        return self.subgraph.select_vertex_by_attr(attr, cond)\n    \n    def set_vertex_attr(self, vertices, attr, value, mask):\n        self.subgraph.set_vertex_attr(self.orig_to_sub(vertices), attr, value, mask)\n    \n    def get_edge_attr(self, edges, attr):\n        # return self.subgraph.get_edge_attr(self.orig_to_sub_edges[edges], attr)\n        raise NotImplementedError\n    \n    def select_edge_by_attr(self, attr, cond):\n        return self.subgraph.select_edge_by_attr(attr, cond)\n    \n    def set_edge_attr(self, edges, attr, value, mask):\n        # self.subgraph.set_edge_attr(self.orig_to_sub_edges[edges], attr, value, mask)\n        raise NotImplementedError\n    \n    def csr_subgraph(self, vertices: torch.Tensor):\n        return self.subgraph.csr_subgraph(self.orig_to_sub(vertices))\n    ", 157], "/root/Project/TCRGraph/src/demo/PageRank.py": ["\"\"\"\nImplementation of PageRank algorithm using the GAS framework.\n\"\"\"\n\nimport sys\nimport torch\nimport argparse\nimport time\nimport logging\nfrom torch_scatter import segment_csr\nsys.path.append('/root/Project/TCRGraph/')\nfrom src.framework.GASProgram import GASProgram\nfrom src.type.CSRCGraph import CSRCGraph\nfrom src.framework.helper import batched_csr_selection\nfrom src.framework.strategy.SimpleStrategy import SimpleStrategy\nfrom src.framework.partition.GeminiPartition import GeminiPartition\nfrom src.framework.strategy.MultiGPUStrategyByNCCL import MultiGPUStrategyByNCCL\nfrom src.framework.strategy.MultiGPUStrategyByCupyAndNCCL import MultiGPUStrategyByCupyAndNCCL\nlogging.basicConfig(format='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s',\n                    level=logging.INFO)\nfrom viztracer import VizTracer\n\nclass PageRank(GASProgram):\n    def __init__(self, graph: CSRCGraph, vertex_data_type=torch.float32, edge_data_type=torch.float32, num_iter=25,\n                 **kwargs):\n        # vertex_data: [num_vertices, 2]. rank and delta\n        vertex_data = torch.ones((graph.num_vertices, 2), dtype=vertex_data_type)\n        # vertex_data /= graph.num_vertices\n        self.UPDATE_THRESHOLD = 0.001\n        self.ITER_THRESHOLD = num_iter\n        self.out_degree = None\n        super().__init__(graph, vertex_data=vertex_data, vertex_data_type=vertex_data_type,\n                         edge_data_type=edge_data_type, **kwargs)\n\n    def gather(self, vertices, nbrs, edges, ptr):\n        if self.nbr_update_freq == 0:\n            if self.out_degree is None:\n                self.out_degree = 1 / self.graph.out_degree(nbrs).to(self.device)\n        else:\n            self.out_degree = 1 / self.graph.out_degree(nbrs).to(self.device)\n        # print('data: {} out_degree: {}'.format(self.vertex_data[nbrs, 0], self.out_degree))\n        data = self.vertex_data[nbrs, 0] * self.out_degree\n        return data, ptr\n\n    def sum(self, gathered_data, ptr):\n        return segment_csr(gathered_data, ptr, reduce='sum')\n\n    def apply(self, vertices, gathered_sum):\n        \"\"\"\n        Returns:\n            apply_data: \n            apply_mask: \n        \"\"\"\n        # logging.info('gathered_sum: {}'.format(gathered_sum))\n        # logging.info('vertices: {}'.format(vertices))\n        \n        rnew = 0.15 + 0.85 * gathered_sum\n        delta = torch.abs(rnew - self.vertex_data[vertices, 0])\n        self.vertex_data[vertices, 0] = rnew\n        self.vertex_data[vertices, 1] = delta\n        return None, None\n        # return torch.stack([rnew, delta], dim=-1), torch.ones(vertices.shape + (2,), dtype=torch.bool,\n        #                                                       device=self.device)\n\n    def scatter(self, vertices, nbrs, edges, ptr, apply_data):\n        if self.nbr_update_freq > 0:\n            delta = self.vertex_data[vertices, 1]\n            selected = torch.where(delta > self.UPDATE_THRESHOLD)[0]\n            if selected.shape[0] > 0 and self.curr_iter < self.ITER_THRESHOLD - 1:\n                # get neighbors of selected\n                starts, ends = ptr[selected], ptr[selected + 1]\n                result, ptr = batched_csr_selection(starts, ends)\n                all_neighbors = nbrs[result]\n                self.activate(all_neighbors)\n        else:\n            if self.curr_iter < self.ITER_THRESHOLD - 1:\n                self.not_change_activated_next_iter()\n        return None, None\n\n    def gather_nbrs(self, vertices):\n        if self.nbr_update_freq == 0:\n            in_nbrs, ptr = self.graph.all_in_nbrs_csr()\n        else:\n            in_nbrs, ptr = self.graph.in_nbrs_csr(vertices)\n        return in_nbrs, None, ptr\n\n    def scatter_nbrs(self, vertices):\n        if self.nbr_update_freq == 0:\n            out_nbrs, ptr = self.graph.all_out_nbrs_csr()\n        else:\n            out_nbrs, ptr = self.graph.out_nbrs_csr(vertices)\n        return out_nbrs, None, ptr\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--graph', type=str, help='path to graph', required=True)\n    parser.add_argument('--output', type=str, help='output path to vertex results', required=True)\n    parser.add_argument('--cuda', action='store_true', help='use cuda')\n    args = parser.parse_args()\n\n    print('reading graph...', end=' ', flush=True)\n    graph, _, _ = CSRCGraph.read_graph(args.graph)\n    graph.pin_memory()\n    print('Done!')\n\n    # partition = VertexPartition(graph, num_partitions=1)\n    partition = GeminiPartition(graph, num_partitions=1, alpha=8 * graph.num_vertices - 1)\n    # strategy = MultiGPUOncePartition(partition, max_subgraphs_in_gpu=2)\n    pr = PageRank(graph)\n    # strategy = SimpleStrategy(partition, pr)\n    strategy = MultiGPUStrategyByNCCL(pr, partition, device_num=2)\n    # strategy = MultiGPUStrategyByCupyAndNCCL(pr, partition, device_num=2)\n    # strategy = SimpleStrategy(pr)\n    if args.cuda:\n        # \u8ba1\u7b97\u7b56\u7565\u4e2d \u79fb\u81f3\u5bf9\u5e94\u8bbe\u5907\n        pr.to('cuda')\n        print('use cuda')\n    \n    # tracer = VizTracer()\n    t1 = time.time()\n    # tracer.start()\n    v_data, _ = pr.compute(strategy)\n    # tracer.stop()\n    t2 = time.time()\n    # tracer.save()\n    print(v_data)\n    print('Completed! {}s time elapsed. Outputting results...'.format(t2 - t1))\n    # output results\n    # with open(args.output, 'w') as f:\n    #     for i in range(len(v_data[:, 0])):\n    #         f.write(str(v_data[i, 0].item()) + '\\n')\n\n\nif __name__ == '__main__':\n    main()", 135], "/root/Project/TCRGraph/src/framework/GASProgram.py": ["\"\"\"\nImplementation of the framework of the GAS (Gather-Apply-Scatter) structure.\nAPIs are modeled after the PowerGraph framework.\n\"\"\"\nimport sys\nimport abc\nimport torch\nfrom src.type.Graph import Graph\nimport random\nfrom .strategy import Strategy, SimpleStrategy\n\nclass GASProgram(abc.ABC):\n    def __init__(self, graph: Graph, vertex_data_type=torch.float32, edge_data_type=torch.float32, vertex_data=None, edge_data=None, start_from=None, num_iter = 0, nbr_update_freq=0):\n        \"\"\"\n        Initialize a GASProgram object. Provides an interface for the GAS structure. Since PyTorch custom data types are hard to implement, users can specify the data shape to support multiple data. (more stress on the user side)\n        \n        :param Graph graph: graph to be processed\n        :param nbr_update_freq: frequency for the update of gather_nbrs and scatter_nbrs. 0 means no update. 1 means update every iteration. 2 means update every other iteration. etc.\n\n        :param start_from torch.Tensor -- \u521d\u59cb\u8ba1\u7b97\u8282\u70b9\n        \"\"\"\n        super().__init__()\n        self.graph = graph\n        self.vertex_data_type = vertex_data_type\n        self.edge_data_type = edge_data_type\n        # \u5982\u679c `start_from` \u6ca1\u6709\u88ab\u521d\u59cb\u5316, \u5219\u5176\u503c\u4e3a\u56fe\u4e2d\u6240\u6709\u8282\u70b9,\u5373\u521d\u59cb\u72b6\u6001\u6240\u6709\u8282\u70b9\u53c2\u4e0e\u8fd0\u7b97\n        if start_from is None:\n            start_from = self.graph.vertices\n        self.activated_vertex_mask = torch.zeros(graph.num_vertices, dtype=torch.bool)\n        # \u521d\u59cb\u6fc0\u6d3b\u8282\u70b9\u4e3a `start_from` \u6240\u6307\u5b9a\u7684\u8282\u70b9\n        self.activated_vertex_mask[start_from] = 1\n        # \u4e0b\u4e00\u8f6e\u6b21\u7684\u6fc0\u6d3b\u8282\u70b9\u63a9\u7801, True\u4ee3\u8868\u8be5\u8282\u70b9\u4e3a\u6fc0\u6d3b\u8282\u70b9\n        self.next_activated_vertex_mask = torch.zeros(graph.num_vertices, dtype=torch.bool)\n        if vertex_data is None:\n            self.vertex_data = torch.zeros(self.graph.num_vertices, dtype=self.vertex_data_type)\n        else:\n            assert isinstance(vertex_data, torch.Tensor), \"vertex_data_shape must be a Tmnsor.\"\n            assert vertex_data.shape[0] == self.graph.num_vertices\n            self.vertex_data = vertex_data\n            \n        if edge_data is None:\n            self.edge_data = torch.zeros(self.graph.num_edges, dtype=self.edge_data_type)\n        else:\n            assert isinstance(edge_data, torch.Tensor), \"edge_data must be a Tensor.\"\n            assert edge_data.shape[0] == self.graph.num_edges\n            self.edge_data = edge_data\n            \n        self.nbr_update_freq = nbr_update_freq\n        self.curr_iter = 0  # curr_iter: \u5f53\u524d\u8fed\u4ee3\u8f6e\u6b21\n        self.not_change_activated = False  # \u6fc0\u6d3b\u8282\u70b9\u662f\u5426\u6ca1\u6709\u6539\u53d8, False: \u6fc0\u6d3b\u8282\u70b9\u9700\u8981\u66f4\u65b0, True: \u6fc0\u6d3b\u8282\u70b9\u4e0d\u9700\u8981\u66f4\u65b0\n        self.is_quit = False  # \u662f\u5426\u9000\u51fa\u8fed\u4ee3, True: \u9000\u51fa\u8fed\u4ee3, False: \u7ee7\u7eed\u8fed\u4ee3\n\n    @abc.abstractmethod\n    def gather(self, vertices, nbrs, edges, ptr):\n        \"\"\"\n        Gather information from the neighbors of vertex_u.\n        \n        :param Tensor<N> vertices: vertices to gather information from\n        :param Tensor<M> nbrs: neighbors of vertices\n        :param Tensor<M> edges: edges between vertices and nbrs\n        :param Tensor<N+1> ptr: nbrs and edges are arranged in CSR order, where ptr is the pointer\n        :return: Tensor<M, d> or Tensor<M> gathered data, Tensor<N+1> CSR pointer\n        \"\"\"\n        pass\n    \n    @abc.abstractmethod\n    def sum(self, gathered_data, ptr):\n        \"\"\"\n        Sum the gathered information.\n        \n        :param Tensor<M, d> or Tensor<M> gathered_data: Tensor of gathered information\n        :param Tensor<N+1> ptr: CSR pointer\n        :return: Tensor<N> or Tensor<N, d> gathered sum\n        \"\"\"\n        pass\n    \n    @abc.abstractmethod\n    def apply(self, vertices, gathered_sum):\n        \"\"\"\n        Apply the gathered information to vertices.\n        \n        :param Tensor<N> vertices: vertices to apply information to\n        :param Tensor<N> or Tensor<N, d>: gathered sum\n        :return: Tensor<N> or Tensor<N, d> or None new data for vertex_u, later to be applied to the vertex, Tensor<N> or Tensor<N, d> or None mask\n        \"\"\"\n        pass\n    \n    @abc.abstractmethod\n    def scatter(self, vertices, nbrs, edges, ptr, apply_data):\n        \"\"\"\n        Scatter the gathered information to the neighbors of vertices.\n        \n        :param Tensor<N> vertices: vertices to scatter information to\n        :param Tensor<M> nbrs: neighbors of vertices\n        :param Tensor<M> edges: edges between vertices and nbrs\n        :param Tensor<N+1> ptr: CSR-style pointer for vertices and nbrs\n        :param Tensor<N> or Tensor<N, d> apply_data: results from apply (not found a use case yet)\n        :return: Tensor<M> or Tensor<M, d> or None new data, later to be applied to the edges; Tensor<M> or None mask\n        \"\"\"\n        pass\n    \n    @abc.abstractmethod\n    def gather_nbrs(self, vertices):\n        \"\"\"\n        The neighbors for gathering. Users may specify this to be in-neighbors, out-neighbors, or others.\n        \n        :param Tensor<N> vertices: vertices\n        :return: Tensor<M> neighbors of the vertex, Tensor<M> related edges, Tensor<N+1> CSR pointer\n        \"\"\"\n        pass\n    \n    @abc.abstractmethod\n    def scatter_nbrs(self, vertex):\n        \"\"\"\n        The neighbors for scattering. Users may specify this to be in-neighbors, out-neighbors, or others.\n        \n        :param Tensor<N> vertices: vertices\n        :return: Tensor<M> neighbors of the vertex, Tensor<M> related edges, Tensor<N+1> CSR pointer\n        \"\"\"\n        pass\n    \n    @property\n    def device(self):\n        \"\"\"\n        return the device where the vertex/edge data reside.\n        :return: device\n        \"\"\"\n        assert self.vertex_data.device == self.edge_data.device, \"Vertex/edge data is not on the same device.\"\n        return self.vertex_data.device\n    \n    def to(self, *args, **kwargs):\n        \"\"\"\n        Move the vertex/edge data to the specified device.\n        \n        :return: None\n        \"\"\"\n        self.vertex_data = self.vertex_data.to(*args, **kwargs)\n        self.edge_data = self.edge_data.to(*args, **kwargs)\n        self.activated_vertex_mask = self.activated_vertex_mask.to(*args, **kwargs)\n        self.next_activated_vertex_mask = self.next_activated_vertex_mask.to(*args, **kwargs)\n        \n    def activate(self, vertices):\n        \"\"\"\n        Activate a vertex in the GAS model, so pyththat it is put in the queue of vertices to be processed.\n        \n        :param vertices: vertex to activate\n        :return: None\n        \"\"\"\n        self.next_activated_vertex_mask[vertices] = 1\n        \n    def not_change_activated_next_iter(self):\n        \"\"\"\n        (For cases nbr_update_freq == 0) For optimization, you can specify not to change the activated vertices next iteration to avoid repetitive computation.\n        \"\"\"\n        self.not_change_activated = True\n         \n    def compute(self, strategy):\n        \"\"\"\n        Run computation on the graph and data.\n        \n        :return: None. check the vertex/edge data after computation.\n        \"\"\"\n        # check basic assumptions\n        assert self.graph.num_vertices == self.vertex_data.shape[0], \"Number of vertices in graph and vertex data do not match.\"\n        \n        return strategy.compute()\n        \n    def set_graph(self, graph):\n        self.graph = graph\n            ", 169], "/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py": ["from collections import OrderedDict\nimport enum\nimport functools\nfrom numbers import Number\nfrom typing import Any, Dict, Optional, Tuple, Union\nimport warnings\nimport copyreg\nfrom copy import deepcopy\n\nimport torch\nimport torch._C as _C\nfrom torch._namedtensor_internals import (\n    update_names, check_serializing_named_tensor, resolve_ellipsis,\n    unzip_namedshape, single_ellipsis_index, is_ellipsis)\nfrom torch.overrides import (\n    has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n    handle_torch_function, get_default_nowrap_functions)\nimport torch.utils.hooks as hooks\n\n\ndef _wrap_type_error_to_not_implemented(f):\n    # functools.wraps doesn't work well with methods in python 2\n    method_assignments = ('__name__', '__doc__')\n    assigned = functools.WRAPPER_ASSIGNMENTS\n\n    @functools.wraps(f, assigned=assigned)\n    def wrapped(*args, **kwargs):\n        if has_torch_function(args):\n            return handle_torch_function(wrapped, args, *args, **kwargs)\n        try:\n            return f(*args, **kwargs)\n        except TypeError:\n            return NotImplemented\n    return wrapped\n\n# Should not be used, this is kept only for BC of loading old serialized Tensor subclasses\ndef _rebuild_from_type(func, type, args, dict):\n    if type is Tensor:\n        return func(*args)\n\n    ret = func(*args).as_subclass(type)\n    ret.__dict__ = dict\n    return ret\n\ndef _rebuild_from_type_v2(func, new_type, args, state):\n    if new_type is Tensor:\n        return func(*args)\n\n    ret = func(*args).as_subclass(new_type)\n    # Tensor does define __setstate__ even though it doesn't define\n    # __getstate__. So only use __setstate__ if it is NOT the one defined\n    # on Tensor\n    if getattr(ret.__class__, \"__setstate__\", Tensor.__setstate__) is not Tensor.__setstate__:\n        ret.__setstate__(state)\n    else:\n        if isinstance(state, tuple):\n            if not len(state) == 2:\n                raise RuntimeError(f\"Invalid serialized state: {state}\")\n            dict_state = state[0]\n            slots_state = state[1]\n        else:\n            dict_state = state\n            slots_state = None\n\n        for k, v in dict_state.items():\n            setattr(ret, k, v)\n\n        if slots_state:\n            for k, v in slots_state.items():\n                setattr(ret, k, v)\n    return ret\n\n\n# NB: If you subclass Tensor, and want to share the subclassed class\n# across processes, you must also update torch/multiprocessing/reductions.py\n# to define a ForkingPickler serialization mode for the class.\n#\n# NB: If you add a new method to Tensor, you must update\n# torch/__init__.py.in to add a type annotation for your method;\n# otherwise, it will not show up in autocomplete.\nclass Tensor(torch._C._TensorBase):\n    def __deepcopy__(self, memo):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__deepcopy__, (self,), self, memo)\n        if not self.is_leaf:\n            raise RuntimeError(\"Only Tensors created explicitly by the user \"\n                               \"(graph leaves) support the deepcopy protocol at the moment\")\n        if id(self) in memo:\n            return memo[id(self)]\n        with torch.no_grad():\n            # TODO: skipping storage copy is wrong for meta, as meta\n            # does accurate alias tracking; however, the code below\n            # doesn't work because of\n            # https://github.com/pytorch/pytorch/issues/47442\n            if self.is_sparse or self.device.type in ['xla', 'mlc', 'ort', 'meta', 'hpu']:\n                new_tensor = self.clone()\n            else:\n                new_storage = self.storage().__deepcopy__(memo)\n                if self.is_quantized:\n                    # quantizer_params can be different type based on torch attribute\n                    quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[torch.qscheme, Tensor, Tensor, int]]\n                    if self.qscheme() == torch.per_tensor_affine:\n                        quantizer_params = self.qscheme(), self.q_scale(), self.q_zero_point()\n                    elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n                        quantizer_params = self.qscheme(), \\\n                            self.q_per_channel_scales(), \\\n                            self.q_per_channel_zero_points(), \\\n                            self.q_per_channel_axis()\n                    else:\n                        raise RuntimeError(f\"Unsupported qscheme {self.qscheme()} in deepcopy\")\n                    # TODO: Once we decide to break serialization FC, no longer\n                    # need to wrap with _TypedStorage\n                    new_tensor = torch._utils._rebuild_qtensor(\n                        torch.storage._TypedStorage(\n                            wrap_storage=new_storage._untyped(),\n                            dtype=self.dtype),\n                        self.storage_offset(),\n                        self.size(),\n                        self.stride(),\n                        quantizer_params,\n                        self.requires_grad,\n                        self._backward_hooks)\n                else:\n                    new_tensor = self.new_empty([])\n                    new_tensor.set_(new_storage, self.storage_offset(), self.size(), self.stride())\n                    if self.is_conj():\n                        new_tensor = new_tensor.conj_physical()\n                    if self.is_neg():\n                        new_tensor = new_tensor.neg()\n                    new_tensor.requires_grad = self.requires_grad\n            if self.grad is not None:\n                new_tensor.grad = self.grad.__deepcopy__(memo)\n\n            if not type(self) is Tensor:\n                new_tensor = new_tensor.as_subclass(type(self))  # type: ignore[arg-type]\n\n                # Plain Tensors don't have slots\n                slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]\n                for slot in slots_to_save:\n                    if hasattr(self, slot):\n                        setattr(new_tensor, slot, deepcopy(getattr(self, slot), memo))\n\n            new_tensor.__dict__ = deepcopy(self.__dict__, memo)\n\n            memo[id(self)] = new_tensor\n            return new_tensor\n\n    def __reduce_ex__(self, proto):\n        if type(self) is Tensor:\n            return self._reduce_ex_internal(proto)\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__reduce_ex__, (self,), self, proto)\n        func, args = self._reduce_ex_internal(proto)\n        # Get the state of the python subclass\n        # This loosely mimicks the function on the object class but since Tensor do not inherit\n        # from it, we cannot call that function directly\n        # https://github.com/python/cpython/blob/c83919bd635f4433f1c6ae8504996a9fe3c215e5/Objects/typeobject.c#L4891\n        getstate_fn = getattr(self, \"__getstate__\", None)\n        if getstate_fn:\n            state = getstate_fn()\n        else:\n            slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]\n            if slots_to_save:\n                state = (self.__dict__, {name: getattr(self, name) for name in slots_to_save if hasattr(self, name)})\n            else:\n                state = self.__dict__\n        return (_rebuild_from_type_v2, (func, type(self), args, state))\n\n    def storage(self):\n        r\"\"\"\n        storage() -> torch.Storage\n\n        Returns the underlying storage.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.storage, (self,), self)\n\n        if self.dtype not in torch.storage._dtype_to_storage_type_map():\n            raise RuntimeError(f'unsupported Storage type: {self.dtype}')\n\n        storage = self._storage()\n        storage_name = torch.storage._dtype_to_storage_type_map()[self.dtype]\n        storage_class = eval(type(storage).__module__ + '.' + storage_name)\n        storage = storage_class(wrap_storage=storage)\n        return storage\n\n    def _reduce_ex_internal(self, proto):\n        check_serializing_named_tensor(self)\n        # See Note [Don't serialize hooks]\n        torch.utils.hooks.warn_if_has_hooks(self)\n        backward_hooks: Dict[Any, Any] = OrderedDict()\n        # Note: Numpy array is chosen to be the rebuild component for XLA, ORT, MLC Tensors.\n        # We considered a few options:\n        # 1. CPU tensor can't be used here.\n        #    Otherwise in torch.load CPU storage is reconstructed with randomly\n        #    initialized data, moved onto backend device, and then storage is updated\n        #    to the serialized content. This works perfectly for CPU/CUDA but not these backends;\n        #    their tensors are disconnected with storage so they don't get the update.\n        # 2. Python list is not a good fit due to performance reason.\n        #    `tolist()` converts every single element in the tensor into python objects\n        #    and serialize them one by one.\n        if self.device.type in ['xla', 'ort', 'mlc']:\n            return (torch._utils._rebuild_device_tensor_from_numpy, (self.cpu().numpy(),\n                                                                     self.dtype,\n                                                                     str(self.device),\n                                                                     self.requires_grad))\n        if self.device.type == 'meta':\n            # NB: This implementation BREAKS storage sharing.  Current\n            # hypothesis is that no one cares for meta tensors.\n            arg_meta = (\n                self.dtype,\n                tuple(self.size()),\n                self.stride(),\n                self.requires_grad,\n            )\n            return (torch._utils._rebuild_meta_tensor_no_storage, arg_meta)\n        if self.is_quantized:\n            # quantizer_params can be different type based on torch attribute\n            quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[Any, Tensor, Tensor, int]]\n            if self.qscheme() == torch.per_tensor_affine:\n                quantizer_params = (torch.per_tensor_affine,\n                                    self.q_scale(),\n                                    self.q_zero_point())\n            elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n                # convert scales and zero points to tuple to avoid recursive calls\n                # when/if we get multi-axis quantized tensors in the future, the shape\n                # is recoverable from the main tensor shape\n                quantizer_params = (torch.per_channel_affine,\n                                    self.q_per_channel_scales(),\n                                    self.q_per_channel_zero_points(),\n                                    self.q_per_channel_axis())\n            else:\n                raise RuntimeError(f\"Serialization is not supported for tensors of type {self.qscheme()}\")\n            # TODO: Once we decide to break serialization FC, no longer\n            # need to wrap with _TypedStorage\n            args_qtensor = (\n                torch.storage._TypedStorage(\n                    wrap_storage=self.storage()._untyped(),\n                    dtype=self.dtype),\n                self.storage_offset(),\n                tuple(self.size()),\n                self.stride(),\n                quantizer_params,\n                self.requires_grad,\n                backward_hooks)\n            return (torch._utils._rebuild_qtensor, args_qtensor)\n        elif self.is_sparse:\n            if self.layout == torch.sparse_coo:\n                args_sparse = (self.layout,\n                               (self._indices(),\n                                self._values(),\n                                self.size()))\n            else:\n                raise NotImplementedError(\n                    'sparse tensor __reduce_ex__ for layout `%s`' % (self.layout))\n            return (torch._utils._rebuild_sparse_tensor, args_sparse)\n        elif self.is_sparse_csr:\n            if self.layout == torch.sparse_csr:\n                args_sparse_csr = (self.layout,\n                                   (self.crow_indices(),\n                                    self.col_indices(),\n                                    self.values(),\n                                    self.size()))\n            else:\n                raise NotImplementedError(\n                    'sparse csr tensor __reduce_ex__ for layout `%s`' % (self.layout))\n            return (torch._utils._rebuild_sparse_csr_tensor, args_sparse_csr)\n        else:\n            # TODO: Once we decide to break serialization FC, no longer\n            # need to wrap with _TypedStorage\n            args = (\n                torch.storage._TypedStorage(\n                    wrap_storage=self.storage()._untyped(),\n                    dtype=self.dtype),\n                self.storage_offset(),\n                tuple(self.size()),\n                self.stride(),\n                self.requires_grad,\n                backward_hooks)  # previously was self._backward_hooks\n            return (torch._utils._rebuild_tensor_v2, args)\n\n    def __setstate__(self, state):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__setstate__, (self,), self, state)\n        # Warning: this method is NOT called when you torch.load() a tensor;\n        # that is managed by _rebuild_tensor_v2\n        if not self.is_leaf:\n            raise RuntimeError('__setstate__ can be only called on leaf Tensors')\n        if len(state) == 4:\n            # legacy serialization of Tensor\n            self.set_(*state)\n            return\n        elif len(state) == 5:\n            # legacy serialization of Variable\n            self.data = state[0]\n            state = (state[3], state[4], state[2])\n        # The setting of _backward_hooks is expected to be a no-op.\n        # See Note [Don't serialize hooks]\n        self.requires_grad, _, self._backward_hooks = state\n\n    def __repr__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__repr__, (self,), self)\n        # All strings are unicode in Python 3.\n        return torch._tensor_str._str(self)\n\n    def backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None):\n        r\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\n\n        The graph is differentiated using the chain rule. If the tensor is\n        non-scalar (i.e. its data has more than one element) and requires\n        gradient, the function additionally requires specifying ``gradient``.\n        It should be a tensor of matching type and location, that contains\n        the gradient of the differentiated function w.r.t. ``self``.\n\n        This function accumulates gradients in the leaves - you might need to zero\n        ``.grad`` attributes or set them to ``None`` before calling it.\n        See :ref:`Default gradient layouts<default-grad-layouts>`\n        for details on the memory layout of accumulated gradients.\n\n        .. note::\n\n            If you run any forward ops, create ``gradient``, and/or call ``backward``\n            in a user-specified CUDA stream context, see\n            :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n\n        .. note::\n\n            When ``inputs`` are provided and a given input is not a leaf,\n            the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n            It is an implementation detail on which the user should not rely.\n            See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n\n        Args:\n            gradient (Tensor or None): Gradient w.r.t. the\n                tensor. If it is a tensor, it will be automatically converted\n                to a Tensor that does not require grad unless ``create_graph`` is True.\n                None values can be specified for scalar Tensors or ones that\n                don't require grad. If a None value would be acceptable then\n                this argument is optional.\n            retain_graph (bool, optional): If ``False``, the graph used to compute\n                the grads will be freed. Note that in nearly all cases setting\n                this option to True is not needed and often can be worked around\n                in a much more efficient way. Defaults to the value of\n                ``create_graph``.\n            create_graph (bool, optional): If ``True``, graph of the derivative will\n                be constructed, allowing to compute higher order derivative\n                products. Defaults to ``False``.\n            inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n                accumulated into ``.grad``. All other Tensors will be ignored. If not\n                provided, the gradient is accumulated into all the leaf Tensors that were\n                used to compute the attr::tensors.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.backward,\n                (self,),\n                self,\n                gradient=gradient,\n                retain_graph=retain_graph,\n                create_graph=create_graph,\n                inputs=inputs)\n        torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n\n    def register_hook(self, hook):\n        r\"\"\"Registers a backward hook.\n\n        The hook will be called every time a gradient with respect to the\n        Tensor is computed. The hook should have the following signature::\n\n            hook(grad) -> Tensor or None\n\n\n        The hook should not modify its argument, but it can optionally return\n        a new gradient which will be used in place of :attr:`grad`.\n\n        This function returns a handle with a method ``handle.remove()``\n        that removes the hook from the module.\n\n        Example::\n\n            >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n            >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n            >>> v.backward(torch.tensor([1., 2., 3.]))\n            >>> v.grad\n\n             2\n             4\n             6\n            [torch.FloatTensor of size (3,)]\n\n            >>> h.remove()  # removes the hook\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.register_hook, (self,), self, hook)\n        if not self.requires_grad:\n            raise RuntimeError(\"cannot register a hook on a tensor that \"\n                               \"doesn't require gradient\")\n        if self._backward_hooks is None:\n            self._backward_hooks = OrderedDict()\n            if self.grad_fn is not None:\n                self.grad_fn._register_hook_dict(self)\n        handle = hooks.RemovableHandle(self._backward_hooks)\n        self._backward_hooks[handle.id] = hook\n        return handle\n\n    def reinforce(self, reward):\n        def trim(str):\n            return '\\n'.join([line.strip() for line in str.split('\\n')])\n\n        raise RuntimeError(trim(r\"\"\"reinforce() was removed.\n            Use torch.distributions instead.\n            See https://pytorch.org/docs/master/distributions.html\n\n            Instead of:\n\n            probs = policy_network(state)\n            action = probs.multinomial()\n            next_state, reward = env.step(action)\n            action.reinforce(reward)\n            action.backward()\n\n            Use:\n\n            probs = policy_network(state)\n            # NOTE: categorical is equivalent to what used to be called multinomial\n            m = torch.distributions.Categorical(probs)\n            action = m.sample()\n            next_state, reward = env.step(action)\n            loss = -m.log_prob(action) * reward\n            loss.backward()\n        \"\"\"))\n\n    detach = _C._add_docstr(_C._TensorBase.detach, r\"\"\"\n    Returns a new Tensor, detached from the current graph.\n\n    The result will never require gradient.\n\n    This method also affects forward mode AD gradients and the result will never\n    have forward mode AD gradients.\n\n    .. note::\n\n      Returned Tensor shares the same storage with the original one.\n      In-place modifications on either of them will be seen, and may trigger\n      errors in correctness checks.\n      IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n      also update the original tensor. Now, these in-place changes will not update the\n      original tensor anymore, and will instead trigger an error.\n      For sparse tensors:\n      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n      returned tensor will not update the original tensor anymore, and will instead\n      trigger an error.\n    \"\"\")\n\n    detach_ = _C._add_docstr(_C._TensorBase.detach_, r\"\"\"\n    Detaches the Tensor from the graph that created it, making it a leaf.\n    Views cannot be detached in-place.\n\n    This method also affects forward mode AD gradients and the result will never\n    have forward mode AD gradients.\n    \"\"\")\n\n    def is_shared(self):\n        r\"\"\"Checks if tensor is in shared memory.\n\n        This is always ``True`` for CUDA tensors.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.is_shared, (self,), self)\n        return self.storage().is_shared()\n\n    def share_memory_(self):\n        r\"\"\"Moves the underlying storage to shared memory.\n\n        This is a no-op if the underlying storage is already in shared memory\n        and for CUDA tensors. Tensors in shared memory cannot be resized.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.share_memory_, (self,), self)\n        self.storage().share_memory_()\n        return self\n\n    def __reversed__(self):\n        r\"\"\"Reverses the tensor along dimension 0.\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__reversed__, (self,), self)\n        if self.dim() == 0:\n            return self\n        else:\n            return self.flip(0)\n\n    def norm(self, p=\"fro\", dim=None, keepdim=False, dtype=None):\n        r\"\"\"See :func:`torch.norm`\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.norm, (self,), self, p=p, dim=dim, keepdim=keepdim, dtype=dtype)\n        return torch.norm(self, p, dim, keepdim, dtype=dtype)\n\n    def lu(self, pivot=True, get_infos=False):\n        r\"\"\"See :func:`torch.lu`\"\"\"\n        # If get_infos is True, then we don't need to check for errors and vice versa\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.lu, (self,), self, pivot=pivot, get_infos=get_infos)\n\n        LU, pivots, infos = torch._lu_with_info(self, pivot=pivot, check_errors=(not get_infos))\n        if get_infos:\n            return LU, pivots, infos\n        else:\n            return LU, pivots\n\n    def stft(self, n_fft: int, hop_length: Optional[int] = None,\n             win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n             center: bool = True, pad_mode: str = 'reflect', normalized: bool = False,\n             onesided: Optional[bool] = None, return_complex: Optional[bool] = None):\n        r\"\"\"See :func:`torch.stft`\n\n        .. warning::\n          This function changed signature at version 0.4.1. Calling with\n          the previous signature may cause error or return incorrect result.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.stft, (self,), self, n_fft, hop_length=hop_length,\n                win_length=win_length, window=window, center=center, pad_mode=pad_mode, normalized=normalized,\n                onesided=onesided, return_complex=return_complex\n            )\n        return torch.stft(self, n_fft, hop_length, win_length, window, center,\n                          pad_mode, normalized, onesided, return_complex=return_complex)\n\n    def istft(self, n_fft: int, hop_length: Optional[int] = None,\n              win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n              center: bool = True, normalized: bool = False,\n              onesided: Optional[bool] = None, length: Optional[int] = None,\n              return_complex: bool = False):\n        r\"\"\"See :func:`torch.istft`\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.istft, (self,), self, n_fft, hop_length=hop_length, win_length=win_length,\n                window=window, center=center, normalized=normalized, onesided=onesided, length=length,\n                return_complex=return_complex\n            )\n        return torch.istft(self, n_fft, hop_length, win_length, window, center,\n                           normalized, onesided, length, return_complex=return_complex)\n\n    def resize(self, *sizes):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.resize, (self,), self, *sizes)\n        warnings.warn(\"non-inplace resize is deprecated\")\n        from torch.autograd._functions import Resize\n        return Resize.apply(self, sizes)\n\n    def resize_as(self, tensor):\n        if has_torch_function_variadic(self, tensor):\n            return handle_torch_function(Tensor.resize_as, (self, tensor), self, tensor)\n        warnings.warn(\"non-inplace resize_as is deprecated\")\n        from torch.autograd._functions import Resize\n        return Resize.apply(self, tensor.size())\n\n    def split(self, split_size, dim=0):\n        r\"\"\"See :func:`torch.split`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.split, (self,), self, split_size, dim=dim)\n        if isinstance(split_size, int):\n            return super(Tensor, self).split(split_size, dim)\n        elif isinstance(split_size, Tensor):\n            try:\n                split_size = int(split_size)\n                return super(Tensor, self).split(split_size, dim)\n            except ValueError:\n                return super(Tensor, self).split_with_sizes(split_size, dim)\n        else:\n            return super(Tensor, self).split_with_sizes(split_size, dim)\n\n    def unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None):\n        r\"\"\"Returns the unique elements of the input tensor.\n\n        See :func:`torch.unique`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.unique, (self,), self, sorted=sorted, return_inverse=return_inverse,\n                return_counts=return_counts, dim=dim\n            )\n        return torch.unique(self, sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n\n    def unique_consecutive(self, return_inverse=False, return_counts=False, dim=None):\n        r\"\"\"Eliminates all but the first element from every consecutive group of equivalent elements.\n\n        See :func:`torch.unique_consecutive`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.unique_consecutive, (self,), self, return_inverse=return_inverse,\n                return_counts=return_counts, dim=dim\n            )\n        return torch.unique_consecutive(self, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n\n    @_wrap_type_error_to_not_implemented\n    def __rsub__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rsub__, (self, other), self, other)\n        return _C._VariableFunctions.rsub(self, other)\n\n    @_wrap_type_error_to_not_implemented\n    def __rdiv__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rdiv__, (self, other), self, other)\n        return self.reciprocal() * other\n\n    __rtruediv__ = __rdiv__\n    __itruediv__ = _C._TensorBase.__idiv__\n\n    __pow__ = _wrap_type_error_to_not_implemented(_C._TensorBase.pow)\n\n    @_wrap_type_error_to_not_implemented\n    def __rmod__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rmod__, (self, other), self, other)\n        return torch.remainder(other, self)\n\n    def __format__(self, format_spec):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__format__, (self,), self, format_spec)\n        if self.dim() == 0:\n            return self.item().__format__(format_spec)\n        return object.__format__(self, format_spec)\n\n    def __ipow__(self, other):  # type: ignore[misc]\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__ipow__, (self, other), self, other)\n        return NotImplemented\n\n    @_wrap_type_error_to_not_implemented\n    def __rpow__(self, other):\n        dtype = torch.result_type(other, self)\n        return torch.tensor(other, dtype=dtype, device=self.device) ** self\n\n    @_wrap_type_error_to_not_implemented\n    def __floordiv__(self, other):\n        warnings.warn(\"__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n                      \"This results in incorrect rounding for negative values. \"\n                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n        return torch.div(self, other, rounding_mode='trunc')\n\n    @_wrap_type_error_to_not_implemented\n    def __rfloordiv__(self, other):\n        warnings.warn(\"__rfloordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n                      \"This results in incorrect rounding for negative values. \"\n                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n        return torch.div(other, self, rounding_mode='trunc')\n\n    @_wrap_type_error_to_not_implemented\n    def __rlshift__(self, other):\n        return torch.bitwise_left_shift(other, self)\n\n    @_wrap_type_error_to_not_implemented\n    def __rrshift__(self, other):\n        return torch.bitwise_right_shift(other, self)\n\n    @_wrap_type_error_to_not_implemented\n    def __rmatmul__(self, other):\n        if has_torch_function_variadic(self, other):\n            return handle_torch_function(Tensor.__rmatmul__, (self, other), self, other)\n        return torch.matmul(other, self)\n\n    __pos__ = _C._TensorBase.positive\n    __neg__ = _C._TensorBase.neg\n    __abs__ = _C._TensorBase.abs\n\n    def __len__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__len__, (self,), self)\n        if self.dim() == 0:\n            raise TypeError(\"len() of a 0-d tensor\")\n        if torch._C._get_tracing_state():\n            warnings.warn('Using len to get tensor shape might cause the trace to be incorrect. '\n                          'Recommended usage would be tensor.shape[0]. '\n                          'Passing a tensor of different shape might lead to errors or silently give '\n                          'incorrect results.', category=torch.jit.TracerWarning, stacklevel=2)\n        return self.shape[0]\n\n    def __iter__(self):\n        # NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\n        # generator and don't eagerly perform all the indexes.  This could\n        # save us work, and also helps keep trace ordering deterministic\n        # (e.g., if you zip(*hiddens), the eager map will force all the\n        # indexes of hiddens[0] before hiddens[1], while the generator\n        # map will interleave them.)\n        # NB: We have intentionally skipped __torch_function__ dispatch here.\n        # See gh-54457\n        if self.dim() == 0:\n            raise TypeError('iteration over a 0-d tensor')\n        if torch._C._get_tracing_state():\n            warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n                          'Passing a tensor of different shape won\\'t change the number of '\n                          'iterations executed (and might lead to errors or silently give '\n                          'incorrect results).', category=torch.jit.TracerWarning, stacklevel=2)\n        return iter(self.unbind(0))\n\n    def __hash__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__hash__, (self,), self)\n        return id(self)\n\n    def __dir__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dir__, (self,), self)\n        tensor_methods = dir(self.__class__)\n        tensor_methods.remove('volatile')  # deprecated\n        attrs = list(self.__dict__.keys())\n        keys = tensor_methods + attrs\n\n        # property only available dense, cuda tensors\n        if (not self.is_cuda) or self.is_sparse:\n            keys.remove(\"__cuda_array_interface__\")\n\n        return sorted(keys)\n\n    # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n    __array_priority__ = 1000    # prefer Tensor ops over numpy ones\n\n    def __array__(self, dtype=None):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__array__, (self,), self, dtype=dtype)\n        if dtype is None:\n            return self.numpy()\n        else:\n            return self.numpy().astype(dtype, copy=False)\n\n    # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n    # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n    def __array_wrap__(self, array):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__array_wrap__, (self,), self, array=array)\n        if array.dtype == bool:\n            # Workaround, torch has no built-in bool tensor\n            array = array.astype('uint8')\n        return torch.from_numpy(array)\n\n    def __contains__(self, element):\n        r\"\"\"Check if `element` is present in tensor\n\n        Args:\n            element (Tensor or scalar): element to be checked\n                for presence in current tensor\"\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__contains__, (self,), self, element)\n        if isinstance(element, (torch.Tensor, Number)):\n            # type hint doesn't understand the __contains__ result array\n            return (element == self).any().item()  # type: ignore[union-attr]\n\n        raise RuntimeError(\n            \"Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s.\" %\n            type(element)\n        )\n\n    @property\n    def __cuda_array_interface__(self):\n        \"\"\"Array view description for cuda tensors.\n\n        See:\n        https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n        \"\"\"\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.__cuda_array_interface__.__get__, (self,), self)  # type: ignore[attr-defined]\n\n        # raise AttributeError for unsupported tensors, so that\n        # hasattr(cpu_tensor, \"__cuda_array_interface__\") is False.\n        if not self.is_cuda:\n            raise AttributeError(\n                \"Can't get __cuda_array_interface__ on non-CUDA tensor type: %s \"\n                \"If CUDA data is required use tensor.cuda() to copy tensor to device memory.\" %\n                self.type()\n            )\n\n        if self.is_sparse:\n            raise AttributeError(\n                \"Can't get __cuda_array_interface__ on sparse type: %s \"\n                \"Use Tensor.to_dense() to convert to a dense tensor first.\" %\n                self.type()\n            )\n\n        # RuntimeError, matching tensor.__array__() behavior.\n        if self.requires_grad:\n            raise RuntimeError(\n                \"Can't get __cuda_array_interface__ on Variable that requires grad. \"\n                \"If gradients aren't required, use var.detach() to get Variable that doesn't require grad.\"\n            )\n\n        # CUDA devices are little-endian and tensors are stored in native byte\n        # order. 1-byte entries are endian-agnostic.\n        typestr = {\n            torch.complex64: \"<c8\",\n            torch.complex128: \"<c16\",\n            torch.float16: \"<f2\",\n            torch.float32: \"<f4\",\n            torch.float64: \"<f8\",\n            torch.uint8: \"|u1\",\n            torch.int8: \"|i1\",\n            torch.int16: \"<i2\",\n            torch.int32: \"<i4\",\n            torch.int64: \"<i8\",\n        }[self.dtype]\n\n        itemsize = self.storage().element_size()\n\n        shape = tuple(self.shape)\n        if self.is_contiguous():\n            # __cuda_array_interface__ v2 requires the strides to be omitted\n            # (either not set or set to None) for C-contiguous arrays.\n            strides = None\n        else:\n            strides = tuple(s * itemsize for s in self.stride())\n        data_ptr = self.data_ptr() if self.numel() > 0 else 0\n        data = (data_ptr, False)  # read-only is false\n\n        return dict(typestr=typestr, shape=shape, strides=strides, data=data, version=2)\n\n    def storage_type(self):\n        r\"\"\"storage_type() -> type\n\n        Returns the type of the underlying storage.\n\n        \"\"\"\n        # NB: this returns old fashioned _TypedStorage, e.g., FloatStorage, as it\n        # would be pretty pointless otherwise (it would always return\n        # _UntypedStorage)\n        return type(self.storage())\n\n    def refine_names(self, *names):\n        r\"\"\"Refines the dimension names of :attr:`self` according to :attr:`names`.\n\n        Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n        A ``None`` dim can be refined to have any name; a named dim can only be\n        refined to have the same name.\n\n        Because named tensors can coexist with unnamed tensors, refining names\n        gives a nice way to write named-tensor-aware code that works with both\n        named and unnamed tensors.\n\n        :attr:`names` may contain up to one Ellipsis (``...``).\n        The Ellipsis is expanded greedily; it is expanded in-place to fill\n        :attr:`names` to the same length as ``self.dim()`` using names from the\n        corresponding indices of ``self.names``.\n\n        Python 2 does not support Ellipsis but one may use a string literal\n        instead (``'...'``).\n\n        Args:\n            names (iterable of str): The desired names of the output tensor. May\n                contain up to one Ellipsis.\n\n        Examples::\n\n            >>> imgs = torch.randn(32, 3, 128, 128)\n            >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n            >>> named_imgs.names\n            ('N', 'C', 'H', 'W')\n\n            >>> tensor = torch.randn(2, 3, 5, 7, 11)\n            >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n            >>> tensor.names\n            ('A', None, None, 'B', 'C')\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.refine_names, (self,), self, *names)\n        names = resolve_ellipsis(names, self.names, 'refine_names')\n        return super(Tensor, self).refine_names(names)\n\n    def align_to(self, *names):\n        r\"\"\"Permutes the dimensions of the :attr:`self` tensor to match the order\n        specified in :attr:`names`, adding size-one dims for any new names.\n\n        All of the dims of :attr:`self` must be named in order to use this method.\n        The resulting tensor is a view on the original tensor.\n\n        All dimension names of :attr:`self` must be present in :attr:`names`.\n        :attr:`names` may contain additional names that are not in ``self.names``;\n        the output tensor has a size-one dimension for each of those new names.\n\n        :attr:`names` may contain up to one Ellipsis (``...``).\n        The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n        that are not mentioned in :attr:`names`, in the order that they appear\n        in :attr:`self`.\n\n        Python 2 does not support Ellipsis but one may use a string literal\n        instead (``'...'``).\n\n        Args:\n            names (iterable of str): The desired dimension ordering of the\n                output tensor. May contain up to one Ellipsis that is expanded\n                to all unmentioned dim names of :attr:`self`.\n\n        Examples::\n\n            >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n            >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n\n            # Move the F and E dims to the front while keeping the rest in order\n            >>> named_tensor.align_to('F', 'E', ...)\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.align_to, (self,), self, *names)\n        ellipsis_idx = single_ellipsis_index(names, 'align_to')\n        if ellipsis_idx is None:\n            return super(Tensor, self).align_to(names)\n        return super(Tensor, self).align_to(\n            [name for name in names if not is_ellipsis(name)],\n            ellipsis_idx)\n\n    def unflatten(self, dim, sizes):\n        r\"\"\"Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n        of sizes given by :attr:`sizes`.\n\n        * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n          as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n          if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n          of elements in the original dim being unflattened.\n\n        Args:\n            dim (Union[int, str]): Dimension to unflatten\n            sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n\n        Examples:\n            >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n            torch.Size([3, 2, 2, 1])\n            >>> torch.randn(3, 4, 1).unflatten(1, (-1, 2)).shape # the size -1 is inferred from the size of dimension 1\n            torch.Size([3, 2, 2, 1])\n            >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n            tensor([[[-1.1772,  0.0180],\n                    [ 0.2412,  0.1431]],\n                    [[-1.1819, -0.8899],\n                    [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n            >>> torch.randn(2, names=('A',)).unflatten('A', (('B1', -1), ('B2', 1)))\n            tensor([[-0.8591],\n                    [ 0.3100]], names=('B1', 'B2'))\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.unflatten, (self,), self, dim, sizes)\n\n        if not sizes:\n            raise RuntimeError(\"unflatten: sizes must be non-empty\")\n\n        names = None\n        if isinstance(sizes, OrderedDict) or (isinstance(sizes, (tuple, list)) and isinstance(sizes[0], (tuple, list))):\n            names, sizes = unzip_namedshape(sizes)\n        return super(Tensor, self).unflatten(dim, sizes, names)\n\n\n    def rename_(self, *names, **rename_map):\n        \"\"\"In-place version of :meth:`~Tensor.rename`.\"\"\"\n\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.rename_, (self,), self, *names, **rename_map)\n\n        # Note [rename_ / rename API]\n        # The Python API for these is different from the C++ API. In Python:\n        # 1) tensor.rename(*names) takes a vararglist of names\n        # 2) tensor.rename(**rename_map) takes a map of names to rename.\n        # C++ is static, making it difficult to implement similar behavior.\n        return update_names(self, names, rename_map, inplace=True)\n\n    def rename(self, *names, **rename_map):\n        \"\"\"Renames dimension names of :attr:`self`.\n\n        There are two main usages:\n\n        ``self.rename(**rename_map)`` returns a view on tensor that has dims\n        renamed as specified in the mapping :attr:`rename_map`.\n\n        ``self.rename(*names)`` returns a view on tensor, renaming all\n        dimensions positionally using :attr:`names`.\n        Use ``self.rename(None)`` to drop names on a tensor.\n\n        One cannot specify both positional args :attr:`names` and keyword args\n        :attr:`rename_map`.\n\n        Examples::\n\n            >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n            >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n            >>> renamed_imgs.names\n            ('batch', 'channels', 'H', 'W')\n\n            >>> renamed_imgs = imgs.rename(None)\n            >>> renamed_imgs.names\n            (None,)\n\n            >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n            >>> renamed_imgs.names\n            ('batch', 'channel', 'height', 'width')\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.rename, (self,), self, *names, **rename_map)\n\n        # See Note [rename_ / rename API]\n        return update_names(self, names, rename_map, inplace=False)\n\n    def to_sparse_coo(self):\n        \"\"\" Convert a tensor to :ref:`coordinate format <sparse-coo-docs>`.\n\n       Examples::\n\n            >>> dense = torch.randn(5, 5)\n            >>> sparse = dense.to_sparse_coo()\n            >>> sparse._nnz()\n            25\n\n       \"\"\"\n        if self.is_sparse:\n            return self\n        if self.is_sparse_csr:\n            crow_indices = self.crow_indices()\n            col_indices = self.col_indices()\n            indices = torch._convert_indices_from_csr_to_coo(crow_indices, col_indices,\n                                                             out_int32=crow_indices.dtype == torch.int32)\n            return torch.sparse_coo_tensor(indices,\n                                           self.values(),\n                                           size=self.shape,\n                                           dtype=self.dtype,\n                                           device=self.device)\n        else:\n            return self.to_sparse()\n\n    def to_sparse_csr(self):\n        \"\"\" Convert a tensor to compressed row storage format. Only works with 2D tensors.\n\n        Examples::\n\n            >>> dense = torch.randn(5, 5)\n            >>> sparse = dense.to_sparse_csr()\n            >>> sparse._nnz()\n            25\n\n        \"\"\"\n        shape = self.size()\n        fill_value = 0\n        if len(shape) != 2:\n            raise RuntimeError(\"Only 2D tensors can be converted to the CSR format but got shape: \", shape)\n\n        if self.is_sparse:\n            coalesced_self = self.coalesce()\n            row_indices = coalesced_self.indices()[0]\n            device = coalesced_self.values().device\n            crow_indices = torch._convert_indices_from_coo_to_csr(\n                row_indices, self.shape[0], out_int32=row_indices.dtype == torch.int32)\n            return torch.sparse_csr_tensor(crow_indices,\n                                           coalesced_self.indices()[1].contiguous(),\n                                           coalesced_self.values(),\n                                           size=coalesced_self.shape,\n                                           dtype=coalesced_self.dtype,\n                                           device=device)\n        elif self.is_sparse_csr:\n            return self\n        else:\n            return self.to_sparse().to_sparse_csr()\n\n    def _update_names(self, names, inplace):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor._update_names, (self,), self, names, inplace)\n\n        # See Note [rename_ / rename API]\n        if inplace:\n            return super(Tensor, self).rename_(names)\n        else:\n            return super(Tensor, self).rename(names)\n\n    @property\n    def grad(self):\n        \"\"\"\n        This attribute is ``None`` by default and becomes a Tensor the first time a call to\n        :func:`backward` computes gradients for ``self``.\n        The attribute will then contain the gradients computed and future calls to\n        :func:`backward` will accumulate (add) gradients into it.\n        \"\"\"\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.grad.__get__, (self,), self)  # type: ignore[attr-defined]\n\n        return self._grad\n\n    @grad.setter\n    def grad(self, new_grad):\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.grad.__set__, (self,), self, new_grad)  # type: ignore[attr-defined]\n        self._grad = new_grad\n\n    @grad.deleter\n    def grad(self):\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.grad.__delete__, (self,), self)  # type: ignore[attr-defined]\n        del self._grad\n\n    @classmethod\n    def __torch_function__(cls, func, types, args=(), kwargs=None):\n        \"\"\"\n        This __torch_function__ implementation wraps subclasses such that\n        methods called on subclasses return a subclass instance instead of\n        a ``torch.Tensor`` instance.\n\n        One corollary to this is that you need coverage for torch.Tensor\n        methods if implementing __torch_function__ for subclasses.\n\n        We recommend always calling ``super().__torch_function__`` as the base\n        case when doing the above.\n\n        While not mandatory, we recommend making `__torch_function__` a classmethod.\n        \"\"\"\n        if kwargs is None:\n            kwargs = {}\n\n        if not all(issubclass(cls, t) for t in types):\n            return NotImplemented\n\n        with _C.DisableTorchFunction():\n            ret = func(*args, **kwargs)\n            if func in get_default_nowrap_functions():\n                return ret\n            else:\n                return _convert(ret, cls)\n\n    def __dlpack__(self, stream=None):\n        \"\"\"\n        Creates a DLpack `capsule https://data-apis.org/array-api/latest/design_topics/data_interchange.html#data-interchange`_\n        of the current tensor to be exported to other libraries.\n\n        This function will be called from the `from_dlpack` method\n        of the library that will consume the capsule. `from_dlpack` passes the current\n        stream to this method as part of the specification.\n\n        Args:\n            stream (integer or None): An optional Python integer representing a\n            pointer to a CUDA stream. The current stream is synchronized with\n            this stream before the capsule is created, and since the capsule\n            shares its storage with the tensor this make it safe to access from\n            both streams.  If None or -1 is passed then no synchronization is performed.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dlpack__, (self,), self, stream)\n\n        # DLPack capsules can't capture all of PyTorch's semantics,\n        # so we prohibit exporting tensors that would lose their properties like\n        # requires_grad and having the conjugate bit set.\n        if self.requires_grad:\n            raise RuntimeError('Can\\'t export tensors that require gradient, use tensor.detach()')\n        if self.is_conj():\n            raise RuntimeError('Can\\'t export tensors with the conjugate bit set')\n        if self.layout != torch.strided:\n            raise RuntimeError('Can\\'t export tensors with layout other than torch.strided')\n\n        if stream is not None and type(stream) is not int:\n            # Stream pointers in CUDA/ROCm are uniquely numbered and can\n            # be retrieved from their integer value.\n            raise TypeError('stream must be ``int`` or ``none``')\n        elif stream is not None and stream != -1:\n            if self.device.type == 'cuda':\n                stream = torch.cuda.ExternalStream(stream)\n                # Only synchronize on different streams\n                if stream != torch.cuda.current_stream:\n                    event = torch.cuda.Event()\n                    event.record(torch.cuda.current_stream())\n                    stream.wait_event(event)\n        return torch.to_dlpack(self)\n\n    def __dlpack_device__(self) -> Tuple[enum.IntEnum, int]:\n        # Avoid circular import\n        from torch.utils.dlpack import DLDeviceType\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dlpack_device__, (self,), self)\n        idx = self.device.index if self.device.index is not None else 0\n        if self.device.type == 'cuda' and torch.version.hip is not None:\n            device_type = DLDeviceType.kDLROCM\n        elif self.device.type == 'cpu' and self.is_pinned():\n            device_type = DLDeviceType.kDLCPUPinned\n        elif self.device.type == 'cuda':\n            device_type = DLDeviceType.kDLGPU\n        elif self.device.type == 'cpu':\n            device_type = DLDeviceType.kDLCPU\n        else:\n            raise ValueError('Unknown device type {} for Dlpack'.format(self.device.type))\n        return (device_type, idx)\n\n    __module__ = 'torch'\n\ndef _convert(ret, cls):\n    if cls is Tensor:\n        return ret\n\n    if isinstance(ret, Tensor) and not isinstance(ret, cls):\n        ret = ret.as_subclass(cls)\n\n    if isinstance(ret, (tuple, list)):\n        # Also handles things like namedtuples\n        ret = type(ret)(_convert(r, cls) for r in ret)\n\n    return ret\n", 1222], "/root/miniconda3/lib/python3.8/site-packages/torch/jit/_builtins.py": ["import math\nimport cmath\nimport warnings\n\nimport torch\nimport torch.backends.cudnn as cudnn\n\nfrom ..nn.modules.utils import _single, _pair, _triple, _quadruple, _list_with_default\n\nfrom collections import OrderedDict\nfrom typing import Dict, Optional\n\n_builtin_table: Optional[Dict[int, str]] = None\n\n_modules_containing_builtins = (torch, torch._C._nn, torch._C._fft, torch._C._linalg, torch._C._sparse, torch._C._special)  # type: ignore[attr-defined] # noqa: B950\n\n_builtin_ops = [\n    # Pairs of (function, op_name)\n    (_pair, \"aten::_pair\"),\n    (_quadruple, \"aten::_quadruple\"),\n    (_single, \"aten::_single\"),\n    (_triple, \"aten::_triple\"),\n    (_list_with_default, \"aten::list_with_default\"),\n    (OrderedDict, \"aten::dict\"),\n    (dict, \"aten::dict\"),\n    (cudnn.is_acceptable, \"aten::cudnn_is_acceptable\"),\n    (math.ceil, \"aten::ceil\"),\n    (math.copysign, \"aten::copysign\"),\n    (math.erf, \"aten::erf\"),\n    (math.erfc, \"aten::erfc\"),\n    (math.exp, \"aten::exp\"),\n    (math.expm1, \"aten::expm1\"),\n    (math.fabs, \"aten::fabs\"),\n    (math.floor, \"aten::floor\"),\n    (math.gamma, \"aten::gamma\"),\n    (math.lgamma, \"aten::lgamma\"),\n    (math.log, \"aten::log\"),\n    (math.log10, \"aten::log10\"),\n    (math.log1p, \"aten::log1p\"),\n    (math.pow, \"aten::pow\"),\n    (math.sqrt, \"aten::sqrt\"),\n    (math.isnan, \"aten::isnan\"),\n    (math.asinh, \"aten::asinh\"),\n    (math.atanh, \"aten::atanh\"),\n    (math.cosh, \"aten::cosh\"),\n    (math.sinh, \"aten::sinh\"),\n    (math.tanh, \"aten::tanh\"),\n    (math.acos, \"aten::acos\"),\n    (math.asin, \"aten::asin\"),\n    (math.atan, \"aten::atan\"),\n    (math.atan2, \"aten::atan2\"),\n    (math.cos, \"aten::cos\"),\n    (math.sin, \"aten::sin\"),\n    (math.tan, \"aten::tan\"),\n    (math.asinh, \"aten::asinh\"),\n    (math.atanh, \"aten::atanh\"),\n    (math.acosh, \"aten::acosh\"),\n    (math.fmod, \"aten::fmod\"),\n    (math.modf, \"aten::modf\"),\n    (math.factorial, \"aten::factorial\"),\n    (math.frexp, \"aten::frexp\"),\n    (math.isinf, \"aten::isinf\"),\n    (math.degrees, \"aten::degrees\"),\n    (math.radians, \"aten::radians\"),\n    (cmath.isnan, \"aten::isnan\"),\n    (cmath.isfinite, \"aten::isfinite\"),\n    (cmath.isinf, \"aten::isinf\"),\n    (cmath.phase, \"aten::angle\"),\n    (cmath.rect, \"aten::polar\"),\n    (cmath.log, \"aten::log\"),\n    (cmath.log10, \"aten::log10\"),\n    (cmath.sqrt, \"aten::sqrt\"),\n    (cmath.exp, \"aten::exp\"),\n    (cmath.sin, \"aten::sin\"),\n    (cmath.tan, \"aten::tan\"),\n    (cmath.cos, \"aten::cos\"),\n    (cmath.asin, \"aten::asin\"),\n    (cmath.acos, \"aten::acos\"),\n    (cmath.atan, \"aten::atan\"),\n    (cmath.sinh, \"aten::sinh\"),\n    (cmath.cosh, \"aten::cosh\"),\n    (cmath.tanh, \"aten::tanh\"),\n    (cmath.asinh, \"aten::asinh\"),\n    (cmath.acosh, \"aten::acosh\"),\n    (cmath.atanh, \"aten::atanh\"),\n    (math.ldexp, \"aten::ldexp\"),\n    (torch._assert, \"aten::_assert\"),\n    (torch.autograd.grad, \"aten::grad\"),\n    (torch.autograd.backward, \"aten::backward\"),\n    (torch._C._infer_size, \"aten::_infer_size\"),\n    (torch.nn.functional._no_grad_embedding_renorm_, \"aten::_no_grad_embedding_renorm_\"),  # type: ignore[attr-defined]\n    (torch.nn.functional.assert_int_or_pair, \"aten::_assert_int_or_pair\"),\n    (torch.nn.init._no_grad_fill_, \"aten::_no_grad_fill_\"),\n    (torch.nn.init._no_grad_normal_, \"aten::_no_grad_normal_\"),\n    (torch.nn.init._no_grad_uniform_, \"aten::_no_grad_uniform_\"),\n    (torch.nn.init._no_grad_zero_, \"aten::_no_grad_zero_\"),\n    (torch._C._get_tracing_state, \"aten::_get_tracing_state\"),\n    (warnings.warn, \"aten::warn\"),\n    (torch._VF.stft, \"aten::stft\"),  # type: ignore[attr-defined]\n    (torch._VF.istft, \"aten::istft\"),  # type: ignore[attr-defined]\n    (torch._VF.cdist, \"aten::cdist\"),  # type: ignore[attr-defined]\n    (torch._VF.norm, \"aten::norm\"),  # type: ignore[attr-defined]\n    (torch._VF.unique_dim, \"aten::unique_dim\"),\n    (torch._VF.unique_consecutive, \"aten::unique_consecutive\"),  # type: ignore[attr-defined]\n    (torch._VF.nuclear_norm, \"aten::nuclear_norm\"),\n    (torch._VF.frobenius_norm, \"aten::frobenius_norm\"),\n    (torch._VF.tensordot, \"aten::tensordot\"),  # type: ignore[attr-defined]\n]\n\n# ops in torch.functional are bound to torch\n# in these cases, we want to resolve the function to their python implementation\n# instead looking up a builtin \"aten::\" schema\n\ndef _gen_torch_functional_registered_ops():\n    # eventually ops should encompass all of torch/functional.py, (torch.functional.__all__)\n    # but we are currently only able to compile some of the functions. additionally,\n    # some functions directly map to their aten:: implementations.\n    # TODO: add support for more ops\n    ops = [\"stft\", \"istft\", \"lu\", \"cdist\", \"norm\", \"unique\", \"unique_consecutive\", \"tensordot\"]\n    return set(getattr(torch.functional, name) for name in ops)\n\n_functional_registered_ops = _gen_torch_functional_registered_ops()\n\ndef _is_special_functional_bound_op(fn):\n    return fn in _functional_registered_ops\n\n# lazily built to ensure the correct initialization order\ndef _get_builtin_table():\n    global _builtin_table\n    if _builtin_table is not None:\n        return _builtin_table\n    _builtin_table = {}\n\n    def register_all(mod):\n        for name in dir(mod):\n            v = getattr(mod, name)\n            if callable(v) and not _is_special_functional_bound_op(v) and v is not torch.no_grad and v is not torch.autocast:\n                _builtin_ops.append((v, \"aten::\" + name))\n    for mod in _modules_containing_builtins:\n        register_all(mod)\n\n    _builtin_ops.append((math.gcd, \"aten::gcd\"))\n    _builtin_ops.append((math.isfinite, \"aten::isfinite\"))\n    _builtin_ops.append((math.remainder, \"aten::mathremainder\"))  # type: ignore[attr-defined]\n\n    import torch.distributed.autograd as dist_autograd\n    if dist_autograd.is_available():\n        _builtin_ops.append((dist_autograd.get_gradients, \"aten::get_gradients\"))\n        _builtin_ops.append((dist_autograd.backward, \"aten::dist_backward\"))\n\n    # populate the _builtin_table from _builtin_ops\n    for builtin, aten_op in _builtin_ops:\n        _builtin_table[id(builtin)] = aten_op\n\n    return _builtin_table\n\n\ndef _register_builtin(fn, op):\n    _get_builtin_table()[id(fn)] = op\n\n\ndef _find_builtin(fn):\n    return _get_builtin_table().get(id(fn))\n", 163], "/root/miniconda3/lib/python3.8/site-packages/torch/_ops.py": ["import torch._C\n\nimport contextlib\nimport ctypes\nimport sys\nimport types\n\nimport torch.jit\nimport torch._utils_internal\n\n# Query `hasattr` only once.\n_SET_GLOBAL_FLAGS = hasattr(sys, 'getdlopenflags') and hasattr(sys, 'setdlopenflags')\n\n\n@contextlib.contextmanager\ndef dl_open_guard():\n    \"\"\"\n    Context manager to set the RTLD_GLOBAL dynamic linker flag while we open a\n    shared library to load custom operators.\n    \"\"\"\n    if _SET_GLOBAL_FLAGS:\n        old_flags = sys.getdlopenflags()\n        sys.setdlopenflags(old_flags | ctypes.RTLD_GLOBAL)\n    yield\n    if _SET_GLOBAL_FLAGS:\n        sys.setdlopenflags(old_flags)\n\n# Each OpOverload object contains pointer to a a specific operator overload, a pointer to the parent `OpOverloadPacket` object.\n# You can obtain an OpOverload object through attribute query on OpOverloadPacket.\nclass OpOverload:\n    def __init__(self, overloadpacket, op, schema):\n        self._op = op\n        self._schema = schema\n        self._overloadpacket = overloadpacket\n\n    # it's a no-op since OpOverload object is immutable and must be unique for a given op overload.\n    def __deepcopy__(self, memo=None):\n        return self\n\n    def __str__(self):\n        return \"OpOverload(op='{}.{}', overload='{}')\".format(*self._schema.name.split(\"::\"), self.overload_name)\n\n    def __call__(self, *args, **kwargs):\n        return self._op(*args, **kwargs or {})\n\n    def __getattr__(self, key):\n        return getattr(self._op, key)\n\n    # `my_namespace::my_op`\n    @property\n    def name(self):\n        return \"{}.{}\".format(*self._schema.name.split(\"::\"))\n\n    @property\n    def overload_name(self):\n        return self._schema.overload_name\n\n    @property\n    def overload_packet(self):\n        return self._overloadpacket\n\n    @property\n    def op(self):\n        return self._op\n\n    # TODO: add more methods to expose information about input and output arguments\n\n# OpOverloadPacket class contains pointer to a base unresolved operator that doesn't correspond to a specific operator\n# You can obtain an OpOverload object through attribute query.\nclass OpOverloadPacket:\n    def __init__(self, qualified_op_name, op_name, op):\n        # These attributes are accessible on the object through the properties\n        # defined below but are immutable\n        self._qualified_op_name = qualified_op_name\n        self._op_name = op_name\n        self._op = op\n\n    # it's a no-op since OpOverloadPacket object is immutable and must be unique for a given op.\n    def __deepcopy__(self, memo=None):\n        return self\n\n    def __str__(self):\n        return \"OpOverloadPacket(op='{}.{}')\".format(*self._qualified_op_name.split(\"::\"))\n\n    @property\n    def qualified_op_name(self):\n        return \"{}.{}\".format(*self._qualified_op_name.split(\"::\"))\n\n    @property\n    def op_name(self):\n        return self._op_name\n\n    @property\n    def op(self):\n        return self._op\n\n    def __getattr__(self, key):\n        # It is not a valid op_name when __file__ is passed in\n        if key == '__file__':\n            return 'torch.ops'\n\n        try:\n            use_key = '' if key == 'default' else key\n            # TODO: disallow access to overloads registered by JIT\n            op_ = torch._C._get_operation_overload(self._qualified_op_name, use_key)\n            schema = torch._C._get_schema(self._qualified_op_name, use_key)\n            overload = OpOverload(self, op_, schema)\n            # cache the overload object\n            setattr(self, key, overload)\n            return overload\n        except RuntimeError:\n            try:\n                # This is added to maintain bc in case the user queries an attribute that exists on `self._op`\n                # which used to be returned before instead of the OpOverloadPacket\n                out = getattr(self._op, key)\n                return out\n            except AttributeError:\n                raise AttributeError(\"'{}' object has no attribute '{}'\".format(str(self), key)) from None\n\n    def __call__(self, *args, **kwargs):\n        # overloading __call__ to ensure torch.ops.foo.bar() is still callable from JIT\n        # We save the function ptr as the `op` attribute on OpOverloadPacket to access it here.\n        return self._op(*args, **kwargs or {})\n\n# Resolution of torch.fn is different from torch.ops.aten.fn\n# torch.fn uses the Python argparser, matches with the appropriate schema, and calls into the unboxed version of the method\n# torch.ops.aten.fn resolution is done via the mechanism defined in JIT. JIT creates a stack of all the overloads and\n# then tries to match the correct one at runtime and always calls into the boxed version of the method\n# Autograd codegen creates VariableType, TracerType, inplace or view type and python bindings\n# Aten codegen generates tensor methods for the the tensor class\n\n# _OpNamespace is a subclass of ModuleType because the torch script\n# allows attribute lookups on modules only. Since we want torch.ops.foo.bar()\n# to work from script, we need to ensure ops and foo are modules\nclass _OpNamespace(types.ModuleType):\n    \"\"\"\n    An op namespace to dynamically bind Operators into Python.\n\n    Say a user has created a custom Operator called \"my_namespace::my_op\". To\n    call this op, the user will write torch.ops.my_namespace.my_op(...).\n    At startup, this operation will not yet be bound into Python. Instead, the\n    following sequence of magic tricks will occur:\n    1. `torch.ops.my_namespace` will invoke the `__getattr__` magic method\n       on the `torch.ops` object, which will create a new `_OpNamespace`\n       object called `my_namespace` and set it as an attribute on the `ops`\n       object.\n    2. `torch.ops.my_namespace.my_op` will then invoke `__getattr__` on\n       the `my_namespace` object, which will retrieve the operation via\n       `torch.get_operation`, a function bound from C++, and then in a similar\n       fashion bind this new object onto the `my_namespace` object.\n    3. `torch.ops.my_namespace.my_op(...)` then calls this new operation\n        and subsequent accesses will incur no further lookup (the namespace and\n        operation will already exist).\n    \"\"\"\n    def __init__(self, name):\n        super(_OpNamespace, self).__init__('torch.ops.' + name)\n        self.name = name\n\n    def __getattr__(self, op_name):\n        # It is not a valid op_name when __file__ is passed in\n        if op_name == '__file__':\n            return 'torch.ops'\n        # Get the op `my_namespace::my_op` if available. This will also check\n        # for overloads and raise an exception if there are more than one.\n        namespace_name = self.name\n        qualified_op_name = '{}::{}'.format(namespace_name, op_name)\n        op = torch._C._jit_get_operation(qualified_op_name)\n\n        # let the script frontend know that op is identical to the builtin op\n        # with qualified_op_name\n        torch.jit._builtins._register_builtin(op, qualified_op_name)\n        op.__module__ = self.__module__ + \".\" + namespace_name\n        # opoverloadpacket = OpOverloadPacket(qualified_op_name, op_name, op)\n        # opoverloadpacket.__module__ = self.__module__ + \".\" + namespace_name\n        # cache the opoverloadpacket to ensure that each op corresponds to\n        # a unique OpOverloadPacket object\n        # setattr(self, op_name, opoverloadpacket)\n        setattr(self, op_name, op)\n        return op\n\nclass _Ops(types.ModuleType):\n    __file__ = '_ops.py'\n\n    def __init__(self):\n        super(_Ops, self).__init__('torch.ops')\n        self.loaded_libraries = set()\n\n    def __getattr__(self, name):\n        # Here we are creating `torch.ops.my_namespace`\n        namespace = _OpNamespace(name)\n        setattr(self, name, namespace)\n        return namespace\n\n    def load_library(self, path):\n        \"\"\"\n        Loads a shared library from the given path into the current process.\n\n        The library being loaded may run global initialization code to register\n        custom operators with the PyTorch JIT runtime. This allows dynamically\n        loading custom operators. For this, you should compile your operator\n        and the static registration code into a shared library object, and then\n        call ``torch.ops.load_library('path/to/libcustom.so')`` to load the\n        shared object.\n\n        After the library is loaded, it is added to the\n        ``torch.ops.loaded_libraries`` attribute, a set that may be inspected\n        for the paths of all libraries loaded using this function.\n\n        Args:\n            path (str): A path to a shared library to load.\n        \"\"\"\n        if sys.executable == \"torch_deploy\":\n            return\n\n        path = torch._utils_internal.resolve_library_path(path)\n        with dl_open_guard():\n            # Import the shared library into the process, thus running its\n            # static (global) initialization code in order to register custom\n            # operators with the JIT.\n            ctypes.CDLL(path)\n        self.loaded_libraries.add(path)\n\n# The ops \"namespace\"\nops = _Ops()\n", 224], "/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py": ["from typing import Optional, Tuple\n\nimport torch\n\n\ndef segment_sum_csr(src: torch.Tensor, indptr: torch.Tensor,\n                    out: Optional[torch.Tensor] = None) -> torch.Tensor:\n    return torch.ops.torch_scatter.segment_sum_csr(src, indptr, out)\n\n\ndef segment_add_csr(src: torch.Tensor, indptr: torch.Tensor,\n                    out: Optional[torch.Tensor] = None) -> torch.Tensor:\n    return torch.ops.torch_scatter.segment_sum_csr(src, indptr, out)\n\n\ndef segment_mean_csr(src: torch.Tensor, indptr: torch.Tensor,\n                     out: Optional[torch.Tensor] = None) -> torch.Tensor:\n    return torch.ops.torch_scatter.segment_mean_csr(src, indptr, out)\n\n\ndef segment_min_csr(\n        src: torch.Tensor, indptr: torch.Tensor,\n        out: Optional[torch.Tensor] = None\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    return torch.ops.torch_scatter.segment_min_csr(src, indptr, out)\n\n\ndef segment_max_csr(\n        src: torch.Tensor, indptr: torch.Tensor,\n        out: Optional[torch.Tensor] = None\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    return torch.ops.torch_scatter.segment_max_csr(src, indptr, out)\n\n\ndef segment_csr(src: torch.Tensor, indptr: torch.Tensor,\n                out: Optional[torch.Tensor] = None,\n                reduce: str = \"sum\") -> torch.Tensor:\n    r\"\"\"\n    Reduces all values from the :attr:`src` tensor into :attr:`out` within the\n    ranges specified in the :attr:`indptr` tensor along the last dimension of\n    :attr:`indptr`.\n    For each value in :attr:`src`, its output index is specified by its index\n    in :attr:`src` for dimensions outside of :obj:`indptr.dim() - 1` and by the\n    corresponding range index in :attr:`indptr` for dimension\n    :obj:`indptr.dim() - 1`.\n    The applied reduction is defined via the :attr:`reduce` argument.\n\n    Formally, if :attr:`src` and :attr:`indptr` are :math:`n`-dimensional and\n    :math:`m`-dimensional tensors with\n    size :math:`(x_0, ..., x_{m-1}, x_m, x_{m+1}, ..., x_{n-1})` and\n    :math:`(x_0, ..., x_{m-2}, y)`, respectively, then :attr:`out` must be an\n    :math:`n`-dimensional tensor with size\n    :math:`(x_0, ..., x_{m-2}, y - 1, x_{m}, ..., x_{n-1})`.\n    Moreover, the values of :attr:`indptr` must be between :math:`0` and\n    :math:`x_m` in ascending order.\n    The :attr:`indptr` tensor supports broadcasting in case its dimensions do\n    not match with :attr:`src`.\n\n    For one-dimensional tensors with :obj:`reduce=\"sum\"`, the operation\n    computes\n\n    .. math::\n        \\mathrm{out}_i =\n        \\sum_{j = \\mathrm{indptr}[i]}^{\\mathrm{indptr}[i+1]-1}~\\mathrm{src}_j.\n\n    Due to the use of index pointers, :meth:`segment_csr` is the fastest\n    method to apply for grouped reductions.\n\n    .. note::\n\n        In contrast to :meth:`scatter()` and :meth:`segment_coo`, this\n        operation is **fully-deterministic**.\n\n    :param src: The source tensor.\n    :param indptr: The index pointers between elements to segment.\n        The number of dimensions of :attr:`index` needs to be less than or\n        equal to :attr:`src`.\n    :param out: The destination tensor.\n    :param reduce: The reduce operation (:obj:`\"sum\"`, :obj:`\"mean\"`,\n        :obj:`\"min\"` or :obj:`\"max\"`). (default: :obj:`\"sum\"`)\n\n    :rtype: :class:`Tensor`\n\n    .. code-block:: python\n\n        from torch_scatter import segment_csr\n\n        src = torch.randn(10, 6, 64)\n        indptr = torch.tensor([0, 2, 5, 6])\n        indptr = indptr.view(1, -1)  # Broadcasting in the first and last dim.\n\n        out = segment_csr(src, indptr, reduce=\"sum\")\n\n        print(out.size())\n\n    .. code-block::\n\n        torch.Size([10, 3, 64])\n    \"\"\"\n    if reduce == 'sum' or reduce == 'add':\n        return segment_sum_csr(src, indptr, out)\n    elif reduce == 'mean':\n        return segment_mean_csr(src, indptr, out)\n    elif reduce == 'min':\n        return segment_min_csr(src, indptr, out)[0]\n    elif reduce == 'max':\n        return segment_max_csr(src, indptr, out)[0]\n    else:\n        raise ValueError\n\n\ndef gather_csr(src: torch.Tensor, indptr: torch.Tensor,\n               out: Optional[torch.Tensor] = None) -> torch.Tensor:\n    return torch.ops.torch_scatter.gather_csr(src, indptr, out)\n", 114]}, "functions": {"_acquireLock (/root/miniconda3/lib/python3.8/logging/__init__.py:218)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 218], "disable (/root/miniconda3/lib/python3.8/logging/__init__.py:1276)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1276], "getEffectiveLevel (/root/miniconda3/lib/python3.8/logging/__init__.py:1675)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1675], "_releaseLock (/root/miniconda3/lib/python3.8/logging/__init__.py:227)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 227], "isEnabledFor (/root/miniconda3/lib/python3.8/logging/__init__.py:1689)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1689], "<lambda> (/root/miniconda3/lib/python3.8/logging/__init__.py:160)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 160], "normcase (/root/miniconda3/lib/python3.8/posixpath.py:52)": ["/root/miniconda3/lib/python3.8/posixpath.py", 52], "findCaller (/root/miniconda3/lib/python3.8/logging/__init__.py:1514)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1514], "getLevelName (/root/miniconda3/lib/python3.8/logging/__init__.py:119)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 119], "_get_sep (/root/miniconda3/lib/python3.8/posixpath.py:41)": ["/root/miniconda3/lib/python3.8/posixpath.py", 41], "basename (/root/miniconda3/lib/python3.8/posixpath.py:140)": ["/root/miniconda3/lib/python3.8/posixpath.py", 140], "_splitext (/root/miniconda3/lib/python3.8/genericpath.py:121)": ["/root/miniconda3/lib/python3.8/genericpath.py", 121], "splitext (/root/miniconda3/lib/python3.8/posixpath.py:117)": ["/root/miniconda3/lib/python3.8/posixpath.py", 117], "current_thread (/root/miniconda3/lib/python3.8/threading.py:1306)": ["/root/miniconda3/lib/python3.8/threading.py", 1306], "name (/root/miniconda3/lib/python3.8/threading.py:1031)": ["/root/miniconda3/lib/python3.8/threading.py", 1031], "current_process (/root/miniconda3/lib/python3.8/multiprocessing/process.py:37)": ["/root/miniconda3/lib/python3.8/multiprocessing/process.py", 37], "name (/root/miniconda3/lib/python3.8/multiprocessing/process.py:189)": ["/root/miniconda3/lib/python3.8/multiprocessing/process.py", 189], "__init__ (/root/miniconda3/lib/python3.8/logging/__init__.py:288)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 288], "makeRecord (/root/miniconda3/lib/python3.8/logging/__init__.py:1550)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1550], "filter (/root/miniconda3/lib/python3.8/logging/__init__.py:796)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 796], "acquire (/root/miniconda3/lib/python3.8/logging/__init__.py:898)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 898], "getMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:364)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 364], "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:427)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 427], "usesTime (/root/miniconda3/lib/python3.8/logging/__init__.py:633)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 633], "formatTime (/root/miniconda3/lib/python3.8/logging/__init__.py:588)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 588], "_format (/root/miniconda3/lib/python3.8/logging/__init__.py:435)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 435], "format (/root/miniconda3/lib/python3.8/logging/__init__.py:438)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 438], "formatMessage (/root/miniconda3/lib/python3.8/logging/__init__.py:639)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 639], "format (/root/miniconda3/lib/python3.8/logging/__init__.py:655)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 655], "format (/root/miniconda3/lib/python3.8/logging/__init__.py:918)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 918], "release (/root/miniconda3/lib/python3.8/logging/__init__.py:905)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 905], "flush (/root/miniconda3/lib/python3.8/logging/__init__.py:1062)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1062], "emit (/root/miniconda3/lib/python3.8/logging/__init__.py:1073)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1073], "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:941)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 941], "callHandlers (/root/miniconda3/lib/python3.8/logging/__init__.py:1645)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1645], "handle (/root/miniconda3/lib/python3.8/logging/__init__.py:1591)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1591], "_log (/root/miniconda3/lib/python3.8/logging/__init__.py:1565)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1565], "info (/root/miniconda3/lib/python3.8/logging/__init__.py:1436)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 1436], "info (/root/miniconda3/lib/python3.8/logging/__init__.py:2074)": ["/root/miniconda3/lib/python3.8/logging/__init__.py", 2074], "_check_single_tensor (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:330)": ["/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", 330], "_rank_not_in_group (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:267)": ["/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", 267], "all_reduce (/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:1253)": ["/root/miniconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", 1253], "all_out_nbrs_csr (/root/Project/TCRGraph/src/type/CSRGraph.py:148)": ["/root/Project/TCRGraph/src/type/CSRGraph.py", 148], "all_in_nbrs_csr (/root/Project/TCRGraph/src/type/CSCGraph.py:82)": ["/root/Project/TCRGraph/src/type/CSCGraph.py", 82], "all_in_nbrs_csr (/root/Project/TCRGraph/src/type/CSRCGraph.py:87)": ["/root/Project/TCRGraph/src/type/CSRCGraph.py", 87], "all_in_nbrs_csr (/root/Project/TCRGraph/src/type/Subgraph.py:93)": ["/root/Project/TCRGraph/src/type/Subgraph.py", 93], "gather_nbrs (/root/Project/TCRGraph/src/demo/PageRank.py:80)": ["/root/Project/TCRGraph/src/demo/PageRank.py", 80], "orig_to_sub (/root/Project/TCRGraph/src/type/Subgraph.py:25)": ["/root/Project/TCRGraph/src/type/Subgraph.py", 25], "num_vertices (/root/Project/TCRGraph/src/type/CSRGraph.py:60)": ["/root/Project/TCRGraph/src/type/CSRGraph.py", 60], "out_degree (/root/Project/TCRGraph/src/type/CSRGraph.py:81)": ["/root/Project/TCRGraph/src/type/CSRGraph.py", 81], "out_degree (/root/Project/TCRGraph/src/type/CSRCGraph.py:66)": ["/root/Project/TCRGraph/src/type/CSRCGraph.py", 66], "out_degree (/root/Project/TCRGraph/src/type/Subgraph.py:58)": ["/root/Project/TCRGraph/src/type/Subgraph.py", 58], "device (/root/Project/TCRGraph/src/framework/GASProgram.py:122)": ["/root/Project/TCRGraph/src/framework/GASProgram.py", 122], "__rdiv__ (/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:606)": ["/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py", 606], "wrapped (/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:26)": ["/root/miniconda3/lib/python3.8/site-packages/torch/_tensor.py", 26], "gather (/root/Project/TCRGraph/src/demo/PageRank.py:35)": ["/root/Project/TCRGraph/src/demo/PageRank.py", 35], "_get_builtin_table (/root/miniconda3/lib/python3.8/site-packages/torch/jit/_builtins.py:128)": ["/root/miniconda3/lib/python3.8/site-packages/torch/jit/_builtins.py", 128], "_register_builtin (/root/miniconda3/lib/python3.8/site-packages/torch/jit/_builtins.py:158)": ["/root/miniconda3/lib/python3.8/site-packages/torch/jit/_builtins.py", 158], "__getattr__ (/root/miniconda3/lib/python3.8/site-packages/torch/_ops.py:159)": ["/root/miniconda3/lib/python3.8/site-packages/torch/_ops.py", 159], "segment_sum_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:6)": ["/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py", 6], "segment_csr (/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py:35)": ["/root/miniconda3/lib/python3.8/site-packages/torch_scatter/segment_csr.py", 35], "sum (/root/Project/TCRGraph/src/demo/PageRank.py:45)": ["/root/Project/TCRGraph/src/demo/PageRank.py", 45], "apply (/root/Project/TCRGraph/src/demo/PageRank.py:48)": ["/root/Project/TCRGraph/src/demo/PageRank.py", 48], "all_out_nbrs_csr (/root/Project/TCRGraph/src/type/CSRCGraph.py:78)": ["/root/Project/TCRGraph/src/type/CSRCGraph.py", 78], "all_out_nbrs_csr (/root/Project/TCRGraph/src/type/Subgraph.py:87)": ["/root/Project/TCRGraph/src/type/Subgraph.py", 87], "scatter_nbrs (/root/Project/TCRGraph/src/demo/PageRank.py:87)": ["/root/Project/TCRGraph/src/demo/PageRank.py", 87], "not_change_activated_next_iter (/root/Project/TCRGraph/src/framework/GASProgram.py:151)": ["/root/Project/TCRGraph/src/framework/GASProgram.py", 151], "scatter (/root/Project/TCRGraph/src/demo/PageRank.py:65)": ["/root/Project/TCRGraph/src/demo/PageRank.py", 65]}}}